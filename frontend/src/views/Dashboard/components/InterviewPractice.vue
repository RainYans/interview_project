<template>
  <div class="interview-practice-container">
    <!-- æœªå¼€å§‹çŠ¶æ€ -->
    <div v-if="!hasStarted" class="start-section">
      <div class="page-header">
        <h2 class="page-title">é¢è¯•ç»ƒä¹ æ¨¡å¼</h2>
        <p class="page-subtitle">AIé™ªç»ƒæ¨¡å¼ï¼Œå¯éšæ—¶æš‚åœæ€è€ƒï¼Œè·å¾—å®æ—¶æŒ‡å¯¼</p>
      </div>

      <!-- è®¾ç½®é¢æ¿ -->
      <div class="settings-panel glass-card">
        <h3>é¢è¯•è®¾ç½®</h3>

        <el-form label-width="120px">
          <el-form-item label="é€‰æ‹©å²—ä½">
            <el-select v-model="settings.position" placeholder="è¯·é€‰æ‹©é¢è¯•å²—ä½" style="width: 100%">
              <el-option label="å‰ç«¯å¼€å‘" value="frontend" />
              <el-option label="åç«¯å¼€å‘" value="backend" />
              <el-option label="äº§å“ç»ç†" value="product" />
              <el-option label="UIè®¾è®¡å¸ˆ" value="design" />
              <el-option label="æ•°æ®åˆ†æ" value="data" />
              <el-option label="ç®—æ³•å·¥ç¨‹å¸ˆ" value="algorithm" />
            </el-select>
          </el-form-item>

          <el-form-item label="éš¾åº¦ç­‰çº§">
            <el-radio-group v-model="settings.difficulty">
              <el-radio label="junior">åˆçº§ - é€‚åˆ0-2å¹´ç»éªŒ</el-radio>
              <el-radio label="medium">ä¸­çº§ - é€‚åˆ2-5å¹´ç»éªŒ</el-radio>
              <el-radio label="senior">é«˜çº§ - é€‚åˆ5å¹´ä»¥ä¸Šç»éªŒ</el-radio>
            </el-radio-group>
          </el-form-item>

          <el-form-item label="é¢è¯•é£æ ¼">
            <el-select v-model="settings.interviewStyle" placeholder="é€‰æ‹©é¢è¯•å®˜é£æ ¼" style="width: 100%">
              <el-option label="æ¸©å’Œå‹ - äº²åˆ‡å‹å¥½ï¼Œé¼“åŠ±å¼æé—®" value="gentle" />
              <el-option label="ä¸¥è‚ƒå‹ - æ­£å¼ä¸¥è°¨ï¼Œæ³¨é‡ç»†èŠ‚" value="serious" />
              <el-option label="æŒ‘æˆ˜å‹ - æ·±å…¥è¿½é—®ï¼Œå‹åŠ›æµ‹è¯•" value="challenging" />
              <el-option label="éšæœºå‹ - ç³»ç»Ÿéšæœºé€‰æ‹©é£æ ¼" value="random" />
            </el-select>
          </el-form-item>

          <el-form-item label="è™šæ‹Ÿé¢è¯•å®˜">
            <div class="avatar-selection">
              <div
                v-for="avatar in avatarOptions"
                :key="avatar.id"
                class="avatar-option"
                :class="{ selected: settings.avatarId === avatar.id }"
                @click="settings.avatarId = avatar.id"
              >
                <el-avatar :size="60" :src="avatar.image" />
                <div class="avatar-info">
                  <h5>{{ avatar.name }}</h5>
                  <p>{{ avatar.description }}</p>
                </div>
              </div>
            </div>
          </el-form-item>

          <el-form-item label="ç»ƒä¹ æ—¶é•¿">
            <el-slider
              v-model="settings.duration"
              :min="10"
              :max="60"
              :step="5"
              show-input
              :format-tooltip="(val) => `${val}åˆ†é’Ÿ`"
            />
          </el-form-item>

          <el-form-item label="é¢˜ç›®ç±»å‹">
            <el-checkbox-group v-model="settings.questionTypes">
              <el-checkbox label="behavioral">è¡Œä¸ºé¢è¯•é¢˜</el-checkbox>
              <el-checkbox label="technical">æŠ€æœ¯é¢è¯•é¢˜</el-checkbox>
              <el-checkbox label="situational">æƒ…æ™¯é¢è¯•é¢˜</el-checkbox>
              <el-checkbox label="project">é¡¹ç›®ç»éªŒé¢˜</el-checkbox>
              <el-checkbox label="stress">å‹åŠ›é¢è¯•é¢˜</el-checkbox>
            </el-checkbox-group>
          </el-form-item>

          <el-form-item label="ç‰¹æ®Šè®¾ç½®">
            <el-checkbox-group v-model="settings.specialSettings">
              <el-checkbox label="realtime_hints">å¯ç”¨å®æ—¶æç¤º</el-checkbox>
              <el-checkbox label="expression_analysis">å¯ç”¨è¡¨æƒ…åˆ†æ</el-checkbox>
              <el-checkbox label="voice_analysis">å¯ç”¨è¯­éŸ³åˆ†æ</el-checkbox>
              <el-checkbox label="auto_feedback">è‡ªåŠ¨åé¦ˆæ¨¡å¼</el-checkbox>
            </el-checkbox-group>
          </el-form-item>
        </el-form>

        <div class="settings-actions">
          <button class="start-btn tech-button" @click="startPractice" :disabled="!canStart">
            <el-icon><VideoPlay /></el-icon>
            å¼€å§‹ç»ƒä¹ 
          </button>
        </div>
      </div>

      <!-- ç»ƒä¹ è¯´æ˜ -->
      <div class="practice-tips glass-card">
        <h3>ç»ƒä¹ æ¨¡å¼ç‰¹ç‚¹</h3>
        <div class="tips-grid">
          <div class="tip-item">
            <el-icon :size="30" color="#67c23a"><CircleCheck /></el-icon>
            <h4>éšæ—¶æš‚åœ</h4>
            <p>é‡åˆ°å›°éš¾å¯ä»¥æš‚åœæ€è€ƒï¼Œä¸è®¡å…¥è¯„åˆ†</p>
          </div>
          <div class="tip-item">
            <el-icon :size="30" color="#409eff"><Opportunity /></el-icon>
            <h4>AIæç¤º</h4>
            <p>å¯ä»¥è·å–AIçš„å›ç­”å»ºè®®å’Œæç¤º</p>
          </div>
          <div class="tip-item">
            <el-icon :size="30" color="#e6a23c"><ChatLineRound /></el-icon>
            <h4>å®æ—¶åé¦ˆ</h4>
            <p>æ¯ä¸ªé—®é¢˜ç»“æŸåç«‹å³è·å¾—åé¦ˆ</p>
          </div>
          <div class="tip-item">
            <el-icon :size="30" color="#f56c6c"><TrendCharts /></el-icon>
            <h4>è¿›æ­¥è¿½è¸ª</h4>
            <p>è®°å½•ç»ƒä¹ æ•°æ®ï¼Œè¿½è¸ªèƒ½åŠ›æå‡</p>
          </div>
        </div>
      </div>
    </div>

    <!-- é¢è¯•è¿›è¡Œä¸­ -->
    <div v-else class="interview-section">
      <!-- é¡¶éƒ¨æ§åˆ¶æ  -->
      <div class="control-bar glass-card">
        <div class="control-left">
          <el-tag type="success">ç»ƒä¹ æ¨¡å¼</el-tag>
          <span class="question-progress">
            ç¬¬ {{ currentQuestionIndex + 1 }} / {{ totalQuestions }} é¢˜
          </span>
        </div>

        <div class="control-center">
          <div class="timer" :class="{ paused: isPaused }">
            <el-icon><Timer /></el-icon>
            <span>{{ formatTime(elapsedTime) }}</span>
          </div>
        </div>

        <div class="control-right">
          <el-button
            :type="isPaused ? 'success' : 'warning'"
            @click="togglePause"
          >
            <el-icon>
              <VideoPlay v-if="isPaused" />
              <VideoPause v-else />
            </el-icon>
            {{ isPaused ? 'ç»§ç»­' : 'æš‚åœ' }}
          </el-button>
          <el-button type="danger" @click="endPractice">
            ç»“æŸç»ƒä¹ 
          </el-button>
        </div>
      </div>

      <!-- è§†é¢‘åŒºåŸŸ -->
      <div class="video-section">
        <div class="video-container glass-card">
          <video ref="videoRef" autoplay muted playsinline></video>
          <div v-if="!cameraEnabled" class="video-placeholder">
            <el-icon :size="60"><VideoCamera /></el-icon>
            <p>æ‘„åƒå¤´æœªå¼€å¯</p>
            <el-button type="primary" size="small" @click="enableCamera">
              å¼€å¯æ‘„åƒå¤´
            </el-button>
          </div>
        </div>

        <!-- AIé¢è¯•å®˜ -->
        <div class="interviewer-container glass-card">
          <div class="interviewer-avatar">
            <div class="avatar-3d" ref="avatarContainer"></div>
            <span class="interviewer-name">{{ currentAvatar.name }}</span>
            <span class="interview-style">{{ getStyleName(settings.interviewStyle) }}</span>
          </div>

          <div class="current-question">
            <h3>å½“å‰é—®é¢˜ï¼š</h3>
            <p>{{ currentQuestion.text }}</p>
            <div class="question-meta">
              <el-tag size="small" type="info">{{ currentQuestion.type }}</el-tag>
              <el-tag size="small" :type="getDifficultyType(currentQuestion.difficulty)">
                {{ currentQuestion.difficulty }}
              </el-tag>
            </div>
          </div>

          <!-- AIåŠ©æ‰‹ -->
          <div v-if="showHint" class="ai-hint animate__animated animate__fadeIn">
            <h4><el-icon><Star /></el-icon> AIæç¤º</h4>
            <p>{{ currentQuestion.hint }}</p>
          </div>

          <!-- å®æ—¶åˆ†æ -->
          <div v-if="settings.specialSettings.includes('realtime_hints') && isRecording" class="realtime-analysis">
            <h4>å®æ—¶åˆ†æ</h4>
            <div class="analysis-items">
              <div class="analysis-item" v-if="settings.specialSettings.includes('voice_analysis')">
                <span class="label">è¯­é€Ÿï¼š</span>
                <span class="value" :class="voiceAnalysis.speed">{{ voiceAnalysis.speedText }}</span>
              </div>
              <div class="analysis-item" v-if="settings.specialSettings.includes('expression_analysis')">
                <span class="label">è¡¨æƒ…ï¼š</span>
                <span class="value" :class="expressionAnalysis.mood">{{ expressionAnalysis.moodText }}</span>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- å›ç­”æ§åˆ¶ -->
      <div class="answer-controls glass-card">
        <div class="controls-main">
          <el-button
            v-if="!isRecording"
            type="primary"
            size="large"
            @click="startRecording"
          >
            <el-icon><Microphone /></el-icon>
            å¼€å§‹å›ç­”
          </el-button>
          <el-button
            v-else
            type="danger"
            size="large"
            @click="stopRecording"
          >
            <el-icon><VideoPause /></el-icon>
            ç»“æŸå›ç­”
          </el-button>

          <el-button
            type="info"
            size="large"
            @click="getHint"
            :disabled="hintUsed"
          >
            <el-icon><Star /></el-icon>
            è·å–æç¤º
          </el-button>

          <el-button
            size="large"
            @click="skipQuestion"
          >
            <el-icon><Right /></el-icon>
            è·³è¿‡é—®é¢˜
          </el-button>
        </div>

        <!-- å½•éŸ³çŠ¶æ€ -->
        <div v-if="isRecording" class="recording-status">
          <span class="recording-dot"></span>
          æ­£åœ¨å½•éŸ³...
        </div>
      </div>

      <!-- å®æ—¶åé¦ˆ -->
      <div v-if="currentFeedback" class="feedback-section glass-card animate__animated animate__fadeIn">
        <h3>AIåé¦ˆ</h3>
        <div class="feedback-content">
          <div class="feedback-score">
            <el-rate
              v-model="currentFeedback.score"
              disabled
              show-score
              text-color="#ff9900"
            />
          </div>
          <div class="feedback-text">
            <div class="feedback-item">
              <strong>ä¼˜ç‚¹ï¼š</strong>
              <p>{{ currentFeedback.pros }}</p>
            </div>
            <div class="feedback-item">
              <strong>å»ºè®®ï¼š</strong>
              <p>{{ currentFeedback.cons }}</p>
            </div>
            <div class="feedback-item">
              <strong>å‚è€ƒç­”æ¡ˆï¼š</strong>
              <p>{{ currentFeedback.reference }}</p>
            </div>
          </div>
        </div>
        <div class="feedback-actions">
          <el-button type="primary" @click="nextQuestion">
            ä¸‹ä¸€é¢˜
          </el-button>
          <el-button @click="repeatQuestion">
            é‡æ–°å›ç­”
          </el-button>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup>
import { ref, computed, onUnmounted, nextTick } from 'vue'
import { useRouter } from 'vue-router'
import { ElMessage, ElMessageBox } from 'element-plus'
import * as THREE from 'three'
import {
  CircleCheck,
  Opportunity,
  ChatLineRound,
  TrendCharts,
  Timer,
  VideoPlay,
  VideoPause,
  VideoCamera,
  User,
  Microphone,
  Right,
  Star
} from '@element-plus/icons-vue'
import apiService from '@/api/service.js'

const router = useRouter()

// ================================================================================================
// ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€çŠ¶æ€ç®¡ç†
// ================================================================================================

const hasStarted = ref(false)
const isPaused = ref(false)
const isRecording = ref(false)
const cameraEnabled = ref(false)
const showHint = ref(false)
const hintUsed = ref(false)

// é¢è¯•æ•°æ®çŠ¶æ€
const currentInterviewId = ref(null)
const currentQuestionData = ref(null)
const recordedAudioBlob = ref(null)
const recordedTranscript = ref('')
const recordingDuration = ref(0)

// åª’ä½“ç›¸å…³çŠ¶æ€
const mediaStream = ref(null)
const mediaRecorder = ref(null)
const audioChunks = ref([])

// ================================================================================================
// ğŸ® ç¬¬äºŒéƒ¨åˆ†ï¼šé¢è¯•è®¾ç½®å’Œé…ç½®
// ================================================================================================

const settings = ref({
  position: 'frontend',
  difficulty: 'medium',
  interviewStyle: 'gentle',
  avatarId: 1,
  duration: 30,
  questionTypes: ['behavioral', 'technical'],
  specialSettings: ['realtime_hints']
})

const avatarOptions = ref([
  {
    id: 1,
    name: 'æé¢è¯•å®˜',
    description: 'äº²å’ŒåŠ›å¼ºï¼Œå–„äºå¼•å¯¼',
    image: '/avatars/interviewer-1.jpg',
    model: '/models/avatar-1.glb'
  },
  {
    id: 2,
    name: 'å¼ é¢è¯•å®˜',
    description: 'ç»éªŒä¸°å¯Œï¼Œä¸“ä¸šä¸¥è°¨',
    image: '/avatars/interviewer-2.jpg',
    model: '/models/avatar-2.glb'
  },
  {
    id: 3,
    name: 'ç‹é¢è¯•å®˜',
    description: 'æŠ€æœ¯ä¸“å®¶ï¼Œæ·±åº¦æŒ–æ˜',
    image: '/avatars/interviewer-3.jpg',
    model: '/models/avatar-3.glb'
  }
])

// ================================================================================================
// ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¢è¯•è¿›åº¦å’ŒçŠ¶æ€
// ================================================================================================

const currentQuestionIndex = ref(0)
const totalQuestions = ref(5)
const currentQuestion = ref({
  text: 'è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»ï¼ŒåŒ…æ‹¬æ‚¨çš„æ•™è‚²èƒŒæ™¯ã€å·¥ä½œç»éªŒå’ŒæŠ€èƒ½ç‰¹é•¿ã€‚',
  hint: 'å»ºè®®æŒ‰ç…§"ä¸ªäººä¿¡æ¯-æ•™è‚²èƒŒæ™¯-é¡¹ç›®ç»éªŒ-æŠ€èƒ½ç‰¹é•¿-èŒä¸šè§„åˆ’"çš„ç»“æ„æ¥ç»„ç»‡å›ç­”ï¼Œæ—¶é—´æ§åˆ¶åœ¨2-3åˆ†é’Ÿã€‚',
  type: 'behavioral',
  difficulty: 'medium'
})
const currentFeedback = ref(null)

// è®¡æ—¶å™¨ç›¸å…³
const elapsedTime = ref(0)
let timerInterval = null
let realtimeInterval = null

// ================================================================================================
// ğŸ¤– ç¬¬å››éƒ¨åˆ†ï¼šAIå®æ—¶åˆ†ææ¥å£åŒºåŸŸ
// ================================================================================================

const voiceAnalysis = ref({
  speed: 'normal',
  speedText: 'é€‚ä¸­'
})

const expressionAnalysis = ref({
  mood: 'neutral',
  moodText: 'è‡ªç„¶'
})

/**
 * å®æ—¶è¯­éŸ³åˆ†æå¤„ç†
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - è¯­éŸ³è´¨é‡åˆ†æ
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œå¤„ç†å®æ—¶è¯­éŸ³åˆ†æï¼š
 * - åˆ†æè¯­é€Ÿã€éŸ³é‡ã€æµç•…åº¦
 * - è¯†åˆ«è¯­éŸ³ä¸­çš„åœé¡¿å’Œè¯­æ°”
 * - æä¾›å®æ—¶è¯­éŸ³è´¨é‡åé¦ˆ
 */
const analyzeVoiceQuality = (audioData) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const analysis = await aiService.analyzeVoiceQuality({
  //     audioData: audioData,
  //     language: 'zh-CN',
  //     analysisType: 'realtime'
  //   })
  //   return {
  //     speed: analysis.speechRate,
  //     volume: analysis.volumeLevel,
  //     fluency: analysis.fluencyScore
  //   }
  // } catch (error) {
  //   return getDefaultVoiceAnalysis()
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  const speeds = ['slow', 'normal', 'fast']
  const speedTexts = ['åæ…¢', 'é€‚ä¸­', 'åå¿«']
  const randomIndex = Math.floor(Math.random() * 3)

  return {
    speed: speeds[randomIndex],
    speedText: speedTexts[randomIndex]
  }
}

/**
 * å®æ—¶è¡¨æƒ…åˆ†æå¤„ç†
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - è¡¨æƒ…è¯†åˆ«åˆ†æ
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œå¤„ç†å®æ—¶è¡¨æƒ…åˆ†æï¼š
 * - åˆ†æé¢éƒ¨è¡¨æƒ…å’Œæƒ…ç»ªçŠ¶æ€
 * - è¯†åˆ«è‡ªä¿¡åº¦å’Œç´§å¼ ç¨‹åº¦
 * - æä¾›å®æ—¶è¡¨æƒ…åé¦ˆ
 */
const analyzeExpression = (videoFrame) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const analysis = await aiService.analyzeFacialExpression({
  //     videoFrame: videoFrame,
  //     analysisType: 'emotion',
  //     confidence: true
  //   })
  //   return {
  //     emotion: analysis.primaryEmotion,
  //     confidence: analysis.confidenceLevel
  //   }
  // } catch (error) {
  //   return getDefaultExpressionAnalysis()
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  const moods = ['confident', 'neutral', 'nervous']
  const moodTexts = ['è‡ªä¿¡', 'è‡ªç„¶', 'ç´§å¼ ']
  const randomIndex = Math.floor(Math.random() * 3)

  return {
    mood: moods[randomIndex],
    moodText: moodTexts[randomIndex]
  }
}

/**
 * è¯­éŸ³è½¬æ–‡å­—å¤„ç†
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - è¯­éŸ³è¯†åˆ«è½¬æ¢
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œå°†å½•éŸ³è½¬æ¢ä¸ºæ–‡å­—ï¼š
 * - æ”¯æŒä¸­æ–‡è¯­éŸ³è¯†åˆ«
 * - å¤„ç†ä¸åŒå£éŸ³å’Œè¯­é€Ÿ
 * - è¿”å›å‡†ç¡®çš„æ–‡å­—è½¬å½•
 */
const transcribeAudio = async (audioBlob) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const transcript = await aiService.speechToText({
  //     audioBlob: audioBlob,
  //     language: 'zh-CN',
  //     format: 'webm'
  //   })
  //   return transcript.text
  // } catch (error) {
  //   console.error('è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
  //   return ''
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  return 'è¿™æ˜¯æ¨¡æ‹Ÿçš„è¯­éŸ³è½¬æ–‡å­—ç»“æœï¼Œç”¨äºæµ‹è¯•ã€‚'
}

// ================================================================================================
// ğŸ¥ ç¬¬äº”éƒ¨åˆ†ï¼šåª’ä½“è®¾å¤‡ç®¡ç†
// ================================================================================================

const videoRef = ref(null)
const avatarContainer = ref(null)
let scene, camera, renderer, avatarMesh

const initMediaRecorder = async () => {
  try {
    if (mediaRecorder.value) {
      try {
        if (mediaRecorder.value.state === 'recording') {
          mediaRecorder.value.stop()
        }
        await new Promise(resolve => {
          const checkState = () => {
            if (mediaRecorder.value.state === 'inactive') {
              resolve()
            } else {
              setTimeout(checkState, 100)
            }
          }
          checkState()
        })
      } catch (e) {
        console.warn('æ¸…ç†å½•éŸ³å™¨å¤±è´¥:', e)
      }
      mediaRecorder.value = null
    }

    let audioStream
    try {
      audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })
    } catch (error) {
      throw error
    }

    let mimeType = null
    const supportedTypes = [
      'audio/webm',
      'audio/mp4',
      'audio/ogg',
      'audio/wav'
    ]

    for (const type of supportedTypes) {
      if (MediaRecorder.isTypeSupported(type)) {
        mimeType = type
        break
      }
    }

    const options = mimeType ? { mimeType } : {}
    mediaRecorder.value = new MediaRecorder(audioStream, options)

    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        audioChunks.value.push(event.data)
      }
    }

    mediaRecorder.value.onstop = async () => {
      if (audioChunks.value.length > 0) {
        const audioBlob = new Blob(audioChunks.value, {
          type: mimeType || 'audio/webm'
        })
        recordedAudioBlob.value = audioBlob

        // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šè¯­éŸ³è½¬æ–‡å­—
        recordedTranscript.value = await transcribeAudio(audioBlob)
      }
      audioChunks.value = []

      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop())
      }
    }

    mediaRecorder.value.onerror = (event) => {
      isRecording.value = false
      ElMessage.error('å½•éŸ³è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š' + event.error.message)
    }

    return true

  } catch (error) {
    ElMessage.error('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
    return false
  }
}

const enableCamera = async () => {
  try {
    const videoStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: 'user'
      },
      audio: false
    })

    mediaStream.value = videoStream

    if (videoRef.value) {
      videoRef.value.srcObject = videoStream
      videoRef.value.onloadedmetadata = () => {
        cameraEnabled.value = true
      }
    }

    cameraEnabled.value = true
    ElMessage.success('æ‘„åƒå¤´å·²å¼€å¯')

  } catch (error) {
    cameraEnabled.value = false

    if (error.name === 'NotAllowedError') {
      ElMessage.error('æ‘„åƒå¤´æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®æ‘„åƒå¤´')
    } else if (error.name === 'NotFoundError') {
      ElMessage.error('æœªæ‰¾åˆ°æ‘„åƒå¤´è®¾å¤‡')
    } else {
      ElMessage.error('æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼š' + error.message)
    }
  }
}

// ================================================================================================
// ğŸ¬ ç¬¬å…­éƒ¨åˆ†ï¼š3Dè™šæ‹Ÿäººæ¸²æŸ“
// ================================================================================================

const init3DAvatar = () => {
  if (!avatarContainer.value) return

  try {
    scene = new THREE.Scene()
    camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000)
    renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true })

    const container = avatarContainer.value
    const size = Math.min(container.clientWidth, container.clientHeight)
    renderer.setSize(size, size)
    container.appendChild(renderer.domElement)

    const ambientLight = new THREE.AmbientLight(0xffffff, 0.6)
    scene.add(ambientLight)

    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8)
    directionalLight.position.set(0, 1, 1)
    scene.add(directionalLight)

    const geometry = new THREE.CylinderGeometry(0.6, 0.8, 2, 8)
    const material = new THREE.MeshPhongMaterial({
      color: 0x4a90e2,
      transparent: true,
      opacity: 0.8
    })
    avatarMesh = new THREE.Mesh(geometry, material)
    scene.add(avatarMesh)

    camera.position.set(0, 0, 4)

    const animate = () => {
      requestAnimationFrame(animate)

      if (avatarMesh) {
        if (isRecording.value) {
          avatarMesh.scale.y = 1 + Math.sin(Date.now() * 0.01) * 0.05
          avatarMesh.rotation.y += 0.005
        } else {
          avatarMesh.scale.y = 1
          avatarMesh.rotation.y += 0.002
        }
      }

      renderer.render(scene, camera)
    }
    animate()

  } catch (error) {
    console.error('3D Avatar initialization failed:', error)
  }
}

// ================================================================================================
// ğŸ¤ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå½•éŸ³æ§åˆ¶åŠŸèƒ½
// ================================================================================================

const startRecording = async () => {
  try {
    if (isRecording.value) {
      return
    }

    const success = await initMediaRecorder()
    if (!success) {
      throw new Error('å½•éŸ³å™¨åˆå§‹åŒ–å¤±è´¥')
    }

    await new Promise(resolve => setTimeout(resolve, 100))

    if (mediaRecorder.value.state !== 'inactive') {
      throw new Error(`å½•éŸ³å™¨çŠ¶æ€å¼‚å¸¸: ${mediaRecorder.value.state}`)
    }

    recordedAudioBlob.value = null
    recordingDuration.value = 0
    audioChunks.value = []

    try {
      mediaRecorder.value.start(1000)
      isRecording.value = true
    } catch (startError) {
      throw startError
    }

    const recordingStartTime = Date.now()
    const recordingTimer = setInterval(() => {
      if (!isRecording.value) {
        clearInterval(recordingTimer)
        return
      }
      recordingDuration.value = Math.floor((Date.now() - recordingStartTime) / 1000)
    }, 1000)

    if (settings.value.specialSettings.includes('realtime_hints')) {
      startRealtimeAnalysis()
    }

    ElMessage.success('å¼€å§‹å½•éŸ³ï¼Œè¯·å›ç­”é—®é¢˜')

  } catch (error) {
    isRecording.value = false
    ElMessage.error('å¼€å§‹å½•éŸ³å¤±è´¥ï¼š' + error.message)
  }
}

const stopRecording = async () => {
  try {
    if (!isRecording.value) {
      return
    }

    if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
      mediaRecorder.value.stop()
    }

    isRecording.value = false
    stopRealtimeAnalysis()

    setTimeout(async () => {
      if (recordedAudioBlob.value && currentQuestionData.value) {
        await submitAnswer()
      }
    }, 500)

  } catch (error) {
    isRecording.value = false
    ElMessage.error('åœæ­¢å½•éŸ³å¤±è´¥ï¼š' + error.message)
  }
}

// ================================================================================================
// ğŸ¤– ç¬¬å…«éƒ¨åˆ†ï¼šå®æ—¶åˆ†æå¤„ç†æ¥å£åŒºåŸŸ
// ================================================================================================

/**
 * å¼€å§‹å®æ—¶åˆ†æ
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - å®æ—¶éŸ³è§†é¢‘åˆ†æ
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œå®æ—¶åˆ†æï¼š
 * - å®æ—¶è¯­éŸ³è´¨é‡åˆ†æ
 * - å®æ—¶è¡¨æƒ…è¯†åˆ«åˆ†æ
 * - å°†åˆ†æç»“æœå‘é€åˆ°åç«¯ä¿å­˜
 */
const startRealtimeAnalysis = () => {
  realtimeInterval = setInterval(async () => {
    if (isRecording.value) {
      try {
        // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šè·å–å®æ—¶éŸ³é¢‘æ•°æ®è¿›è¡Œåˆ†æ
        const audioData = getCurrentAudioData()
        const voiceResult = analyzeVoiceQuality(audioData)
        voiceAnalysis.value = voiceResult

        // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šè·å–å®æ—¶è§†é¢‘å¸§è¿›è¡Œåˆ†æ
        if (settings.value.specialSettings.includes('expression_analysis')) {
          const videoFrame = getCurrentVideoFrame()
          const expressionResult = analyzeExpression(videoFrame)
          expressionAnalysis.value = expressionResult
        }

        // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šå‘é€å®æ—¶åˆ†ææ•°æ®åˆ°åç«¯
        if (currentInterviewId.value) {
          await apiService.interview.submitRealtimeAnalysis(currentInterviewId.value, {
            audioLevel: getAudioLevel(),
            emotionType: expressionAnalysis.value.mood,
            eyeContactScore: getEyeContactScore(),
            speechSpeed: getSpeechSpeed(),
            voiceQuality: voiceResult,
            facialExpression: expressionAnalysis.value,
            timestamp: new Date().toISOString()
          })
        }

      } catch (error) {
        console.error('å®æ—¶åˆ†æå¤„ç†å¤±è´¥:', error)
      }
    }
  }, 2000)
}

const stopRealtimeAnalysis = () => {
  if (realtimeInterval) {
    clearInterval(realtimeInterval)
    realtimeInterval = null
  }
  voiceAnalysis.value = { speed: 'normal', speedText: 'é€‚ä¸­' }
  expressionAnalysis.value = { mood: 'neutral', moodText: 'è‡ªç„¶' }
}

// è¾…åŠ©æ–¹æ³•ï¼šè·å–å½“å‰éŸ³é¢‘æ•°æ®
const getCurrentAudioData = () => {
  // TODO: å®ç°è·å–å½“å‰éŸ³é¢‘æ•°æ®çš„é€»è¾‘
  return null
}

// è¾…åŠ©æ–¹æ³•ï¼šè·å–å½“å‰è§†é¢‘å¸§
const getCurrentVideoFrame = () => {
  // TODO: å®ç°è·å–å½“å‰è§†é¢‘å¸§çš„é€»è¾‘
  return null
}

const getAudioLevel = () => {
  return Math.random() * 100
}

const getCurrentEmotion = () => {
  return Math.random() > 0.5 ? 'confident' : 'neutral'
}

const getEyeContactScore = () => {
  return Math.random() * 100
}

const getSpeechSpeed = () => {
  return Math.random() * 200 + 100
}

// ================================================================================================
// ğŸ“‹ ç¬¬ä¹éƒ¨åˆ†ï¼šé¢è¯•æµç¨‹æ§åˆ¶
// ================================================================================================

const startPractice = async () => {
  try {
    const hasResume = localStorage.getItem('userResume')
    if (!hasResume) {
      const confirm = await ElMessageBox.confirm(
        'æ£€æµ‹åˆ°æ‚¨è¿˜æœªä¸Šä¼ ç®€å†ï¼Œå»ºè®®å…ˆä¸Šä¼ ç®€å†ä»¥è·å¾—ä¸ªæ€§åŒ–çš„é¢è¯•é¢˜ç›®ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ',
        'æç¤º',
        {
          confirmButtonText: 'ç»§ç»­ç»ƒä¹ ',
          cancelButtonText: 'å»ä¸Šä¼ ç®€å†',
          type: 'warning'
        }
      ).catch(() => false)

      if (!confirm) {
        router.push('/dashboard/resume-manage')
        return
      }
    }

    const response = await apiService.interview.start({
      position: settings.value.position,
      difficulty: settings.value.difficulty,
      interviewStyle: settings.value.interviewStyle,
      avatarId: settings.value.avatarId,
      duration: settings.value.duration,
      questionTypes: settings.value.questionTypes,
      specialSettings: settings.value.specialSettings
    })

    currentInterviewId.value = response.data.interview_id
    currentQuestionData.value = response.data.first_question
    totalQuestions.value = response.data.total_questions

    if (currentQuestionData.value) {
      currentQuestion.value = {
        text: currentQuestionData.value.text,
        type: currentQuestionData.value.type,
        difficulty: currentQuestionData.value.difficulty,
        hint: currentQuestionData.value.hint || 'å»ºè®®æŒ‰ç…§ç»“æ„åŒ–çš„æ–¹å¼æ¥ç»„ç»‡å›ç­”'
      }
    }

    hasStarted.value = true
    startTimer()

    nextTick(async () => {
      init3DAvatar()
      try {
        await enableCamera()
      } catch (error) {
        ElMessage.warning('åª’ä½“è®¾å¤‡åˆå§‹åŒ–å¤±è´¥ï¼Œä½†é¢è¯•å¯ä»¥ç»§ç»­')
      }
    })

    ElMessage.success('é¢è¯•ç»ƒä¹ å¼€å§‹ï¼')

  } catch (error) {
    ElMessage.error('å¼€å§‹ç»ƒä¹ å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const submitAnswer = async () => {
  try {
    const answerData = {
      answerText: recordedTranscript.value || '',
      timeSpent: recordingDuration.value,
      usedHint: hintUsed.value
    }

    if (recordedAudioBlob.value && currentInterviewId.value && currentQuestionData.value) {
      const uploadResponse = await apiService.interview.uploadAudio(
        currentInterviewId.value,
        currentQuestionData.value.id,
        recordedAudioBlob.value
      )
      answerData.audioPath = uploadResponse.data.file_path
    }

    const answerResponse = await apiService.interview.submitAnswer(
      currentQuestionData.value.id,
      answerData
    )

    currentFeedback.value = {
      score: answerResponse.data.score,
      pros: answerResponse.data.ai_feedback,
      cons: answerResponse.data.improvement_tips?.join('ï¼›') || '',
      reference: 'ç»§ç»­ä¿æŒè¿™ç§çŠ¶æ€'
    }

    ElMessage.success('å›ç­”å·²æäº¤ï¼Œæ­£åœ¨åˆ†æ...')

  } catch (error) {
    ElMessage.error('æäº¤ç­”æ¡ˆå¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const togglePause = async () => {
  if (!currentInterviewId.value) return

  try {
    if (isPaused.value) {
      await apiService.interview.resumeInterview(currentInterviewId.value)
      isPaused.value = false
      ElMessage.success('é¢è¯•å·²ç»§ç»­')
    } else {
      await apiService.interview.pauseInterview(currentInterviewId.value)
      isPaused.value = true
      ElMessage.info('é¢è¯•å·²æš‚åœï¼Œç‚¹å‡»ç»§ç»­æŒ‰é’®æ¢å¤')
    }
  } catch (error) {
    ElMessage.error('æ“ä½œå¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const getHint = async () => {
  if (!currentQuestionData.value) return

  try {
    const hintResponse = await apiService.interview.getQuestionHint(currentQuestionData.value.id)

    currentQuestion.value.hint = hintResponse.data.hint
    showHint.value = true
    hintUsed.value = true

    await apiService.interview.markHintUsed(currentQuestionData.value.id)

    ElMessage.info('å·²æ˜¾ç¤ºAIæç¤ºï¼Œæœ¬é¢˜å°†ä¸è®¡å…¥ç»¼åˆè¯„åˆ†')
  } catch (error) {
    ElMessage.error('è·å–æç¤ºå¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const skipQuestion = async () => {
  if (!currentInterviewId.value || !currentQuestionData.value) {
    ElMessage.error('ç¼ºå°‘é¢è¯•æˆ–é¢˜ç›®æ•°æ®')
    return
  }

  try {
    const response = await apiService.interview.skipQuestion(
      currentInterviewId.value,
      currentQuestionData.value.id
    )

    if (response.data && response.data.next_question) {
      currentQuestionData.value = response.data.next_question

      currentQuestion.value = {
        text: response.data.next_question.text,
        type: response.data.next_question.type,
        difficulty: response.data.next_question.difficulty,
        hint: response.data.next_question.hint || 'å»ºè®®æŒ‰ç…§ç»“æ„åŒ–çš„æ–¹å¼æ¥ç»„ç»‡å›ç­”'
      }

      currentQuestionIndex.value++
      resetQuestionState()

      ElMessage.success('å·²è·³è¿‡å½“å‰é—®é¢˜')
    } else {
      ElMessage.info('å·²æ˜¯æœ€åä¸€é¢˜ï¼Œé¢è¯•å³å°†ç»“æŸ')
      await endPractice()
    }
  } catch (error) {
    let errorMessage = 'è·³è¿‡é—®é¢˜å¤±è´¥'
    if (error.response?.data?.detail) {
      errorMessage += 'ï¼š' + error.response.data.detail
    } else if (error.message) {
      errorMessage += 'ï¼š' + error.message
    }
    ElMessage.error(errorMessage)
  }
}

const nextQuestion = async () => {
  if (!currentQuestionData.value) return

  try {
    const response = await apiService.interview.getNextQuestion(currentQuestionData.value.id)

    if (response.data) {
      currentQuestionData.value = response.data
      currentQuestionIndex.value++
      resetQuestionState()
      ElMessage.success('ä¸‹ä¸€é¢˜å·²å‡†å¤‡å¥½')
    } else {
      await endPractice()
    }
  } catch (error) {
    ElMessage.error('è·å–ä¸‹ä¸€é¢˜å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const repeatQuestion = () => {
  resetQuestionState()
  ElMessage.info('å¯ä»¥é‡æ–°å›ç­”å½“å‰é—®é¢˜')
}

const endPractice = async () => {
  const confirm = await ElMessageBox.confirm(
    'ç¡®å®šè¦ç»“æŸæœ¬æ¬¡ç»ƒä¹ å—ï¼Ÿ',
    'æç¤º',
    {
      confirmButtonText: 'ç¡®å®š',
      cancelButtonText: 'å–æ¶ˆ',
      type: 'warning'
    }
  ).catch(() => false)

  if (confirm) {
    try {
      if (currentInterviewId.value) {
        let response = null

        try {
          response = await apiService.interview.completeInterview(
            currentInterviewId.value,
            'normal'
          )
        } catch (primaryError) {
          try {
            response = await apiService.interview.endInterview(currentInterviewId.value)
          } catch (fallbackError) {
            throw primaryError
          }
        }

        ElMessage.success('ç»ƒä¹ ç»“æŸï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...')
        cleanupResources()
        router.push('/dashboard/interview-performance')
      } else {
        cleanupResources()
        router.push('/dashboard/interview-performance')
      }
    } catch (error) {
      cleanupResources()
      ElMessage.error('ç»“æŸç»ƒä¹ å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
    }
  }
}

// ================================================================================================
// ğŸ› ï¸ ç¬¬åéƒ¨åˆ†ï¼šå·¥å…·å‡½æ•°å’Œèµ„æºç®¡ç†
// ================================================================================================

const resetQuestionState = () => {
  currentFeedback.value = null
  showHint.value = false
  hintUsed.value = false
  recordedAudioBlob.value = null
  recordingDuration.value = 0

  if (isRecording.value) {
    stopRecording()
  }
}

const cleanupResources = () => {
  if (mediaRecorder.value) {
    if (mediaRecorder.value.state === 'recording') {
      try {
        mediaRecorder.value.stop()
      } catch (error) {
        console.error('åœæ­¢å½•éŸ³å™¨å¤±è´¥:', error)
      }
    }
    mediaRecorder.value = null
  }

  if (mediaStream.value) {
    try {
      mediaStream.value.getTracks().forEach(track => {
        track.stop()
      })
    } catch (error) {
      console.error('åœæ­¢åª’ä½“è½¨é“å¤±è´¥:', error)
    }
    mediaStream.value = null
  }

  if (videoRef.value) {
    videoRef.value.srcObject = null
  }

  cameraEnabled.value = false
  isRecording.value = false

  if (timerInterval) {
    clearInterval(timerInterval)
    timerInterval = null
  }
  if (realtimeInterval) {
    clearInterval(realtimeInterval)
    realtimeInterval = null
  }

  if (renderer) {
    renderer.dispose()
    renderer = null
  }
}

const startTimer = () => {
  timerInterval = setInterval(() => {
    if (!isPaused.value) {
      elapsedTime.value++
    }
  }, 1000)
}

const formatTime = (seconds) => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// ================================================================================================
// ğŸ’« ç¬¬åä¸€éƒ¨åˆ†ï¼šè®¡ç®—å±æ€§å’Œè¾…åŠ©å‡½æ•°
// ================================================================================================

const canStart = computed(() => {
  return settings.value.position &&
         settings.value.questionTypes.length > 0 &&
         settings.value.avatarId
})

const currentAvatar = computed(() => {
  return avatarOptions.value.find(avatar => avatar.id === settings.value.avatarId) || avatarOptions.value[0]
})

const getStyleName = (style) => {
  const styleMap = {
    gentle: 'æ¸©å’Œå‹',
    serious: 'ä¸¥è‚ƒå‹',
    challenging: 'æŒ‘æˆ˜å‹',
    random: 'éšæœºå‹'
  }
  return styleMap[style] || 'æ¸©å’Œå‹'
}

const getDifficultyType = (difficulty) => {
  const difficultyMap = {
    easy: 'success',
    medium: 'warning',
    hard: 'danger'
  }
  return difficultyMap[difficulty] || 'info'
}

// ================================================================================================
// ğŸ”„ ç¬¬åäºŒéƒ¨åˆ†ï¼šç”Ÿå‘½å‘¨æœŸç®¡ç†
// ================================================================================================

onUnmounted(() => {
  if (mediaStream.value) {
    mediaStream.value.getTracks().forEach(track => track.stop())
  }
  if (timerInterval) {
    clearInterval(timerInterval)
  }
  if (renderer) {
    renderer.dispose()
  }
})
</script>

<style scoped>
.interview-practice-container {
  max-width: 1400px;
  margin: 0 auto;
}

/* å¼€å§‹é¡µé¢æ ·å¼ */
.start-section {
  max-width: 800px;
  margin: 0 auto;
}

.settings-panel {
  padding: 30px;
  margin-bottom: 30px;
}

.settings-panel h3 {
  font-size: 1.3rem;
  margin-bottom: 25px;
  color: var(--text-primary);
}

.avatar-selection {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 15px;
}

.avatar-option {
  display: flex;
  align-items: center;
  gap: 15px;
  padding: 15px;
  background: rgba(255, 255, 255, 0.05);
  border: 2px solid transparent;
  border-radius: 12px;
  cursor: pointer;
  transition: all 0.3s ease;
}

.avatar-option:hover {
  background: rgba(255, 255, 255, 0.08);
}

.avatar-option.selected {
  border-color: var(--primary-color);
  background: rgba(64, 158, 255, 0.1);
}

.avatar-info h5 {
  color: var(--text-primary);
  margin: 0 0 5px 0;
}

.avatar-info p {
  color: var(--text-secondary);
  margin: 0;
  font-size: 13px;
}

.settings-actions {
  text-align: center;
  margin-top: 30px;
}

.start-btn {
  padding: 15px 50px;
  font-size: 1.1rem;
  background: var(--gradient-tech);
  color: white;
  border: none;
  border-radius: 30px;
  cursor: pointer;
  display: inline-flex;
  align-items: center;
  gap: 10px;
  transition: all 0.3s ease;
}

.start-btn:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 8px 25px rgba(64, 158, 255, 0.3);
}

.start-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* ç»ƒä¹ è¯´æ˜ */
.practice-tips {
  padding: 30px;
}

.practice-tips h3 {
  font-size: 1.3rem;
  margin-bottom: 25px;
  color: var(--text-primary);
}

.tips-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 30px;
}

.tip-item {
  text-align: center;
}

.tip-item h4 {
  margin: 15px 0 10px;
  color: var(--text-primary);
}

.tip-item p {
  color: var(--text-secondary);
  line-height: 1.6;
}

/* é¢è¯•è¿›è¡Œä¸­æ ·å¼ */
.interview-section {
  display: flex;
  flex-direction: column;
  gap: 20px;
}

/* æ§åˆ¶æ  */
.control-bar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 15px 25px;
}

.control-left,
.control-right {
  display: flex;
  align-items: center;
  gap: 15px;
}

.question-progress {
  color: var(--text-secondary);
}

.timer {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 1.2rem;
  color: var(--text-primary);
}

.timer.paused {
  color: var(--warning-color);
}

/* è§†é¢‘åŒºåŸŸ */
.video-section {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 20px;
  height: 400px;
}

.video-container,
.interviewer-container {
  position: relative;
  overflow: hidden;
}

.video-container video {
  width: 100%;
  height: 100%;
  object-fit: cover;
  border-radius: 12px;
}

.video-placeholder {
  height: 100%;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--text-secondary);
}

.video-placeholder p {
  margin: 15px 0;
}

/* AIé¢è¯•å®˜ */
.interviewer-container {
  padding: 20px;
  display: flex;
  flex-direction: column;
}

.interviewer-avatar {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 10px;
  margin-bottom: 25px;
}

.avatar-3d {
  width: 120px;
  height: 120px;
  border-radius: 50%;
  overflow: hidden;
}

.interviewer-name {
  font-size: 1.1rem;
  color: var(--text-primary);
  font-weight: 600;
}

.interview-style {
  font-size: 0.9rem;
  color: var(--text-secondary);
}

.current-question h3 {
  font-size: 1rem;
  color: var(--text-secondary);
  margin-bottom: 10px;
}

.current-question p {
  font-size: 1.1rem;
  color: var(--text-primary);
  line-height: 1.6;
  margin-bottom: 10px;
}

.question-meta {
  display: flex;
  gap: 8px;
  margin-bottom: 15px;
}

.ai-hint {
  margin-top: 20px;
  padding: 15px;
  background: rgba(103, 194, 58, 0.1);
  border-radius: 8px;
  border: 1px solid rgba(103, 194, 58, 0.3);
}

.ai-hint h4 {
  display: flex;
  align-items: center;
  gap: 8px;
  color: var(--secondary-color);
  margin-bottom: 10px;
}

.ai-hint p {
  color: var(--text-primary);
  line-height: 1.6;
}

.realtime-analysis {
  margin-top: 20px;
  padding: 15px;
  background: rgba(64, 158, 255, 0.1);
  border-radius: 8px;
  border: 1px solid rgba(64, 158, 255, 0.3);
}

.realtime-analysis h4 {
  color: var(--primary-color);
  margin-bottom: 10px;
  font-size: 0.9rem;
}

.analysis-items {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.analysis-item {
  display: flex;
  justify-content: space-between;
  font-size: 0.8rem;
}

.analysis-item .label {
  color: var(--text-secondary);
}

.analysis-item .value {
  font-weight: 600;
}

.analysis-item .value.normal,
.analysis-item .value.neutral {
  color: var(--success-color);
}

.analysis-item .value.fast,
.analysis-item .value.slow,
.analysis-item .value.nervous {
  color: var(--warning-color);
}

.analysis-item .value.confident {
  color: var(--primary-color);
}

/* å›ç­”æ§åˆ¶ */
.answer-controls {
  padding: 25px;
  text-align: center;
}

.controls-main {
  display: flex;
  justify-content: center;
  gap: 15px;
  margin-bottom: 20px;
}

.recording-status {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 10px;
  color: var(--danger-color);
}

.recording-dot {
  width: 10px;
  height: 10px;
  background: var(--danger-color);
  border-radius: 50%;
  animation: pulse 1.5s ease-in-out infinite;
}

@keyframes pulse {
  0% {
    opacity: 1;
    transform: scale(1);
  }
  50% {
    opacity: 0.5;
    transform: scale(1.2);
  }
  100% {
    opacity: 1;
    transform: scale(1);
  }
}

/* åé¦ˆåŒºåŸŸ */
.feedback-section {
  padding: 30px;
}

.feedback-section h3 {
  font-size: 1.3rem;
  margin-bottom: 20px;
  color: var(--text-primary);
}

.feedback-content {
  margin-bottom: 25px;
}

.feedback-score {
  margin-bottom: 20px;
}

.feedback-item {
  margin-bottom: 20px;
}

.feedback-item strong {
  color: var(--primary-color);
  display: block;
  margin-bottom: 8px;
}

.feedback-item p {
  color: var(--text-secondary);
  line-height: 1.6;
  margin: 0;
}

.feedback-actions {
  display: flex;
  justify-content: center;
  gap: 15px;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 992px) {
  .video-section {
    grid-template-columns: 1fr;
    height: auto;
  }

  .tips-grid {
    grid-template-columns: repeat(2, 1fr);
  }

  .avatar-selection {
    grid-template-columns: 1fr;
  }
}

@media (max-width: 768px) {
  .control-bar {
    flex-wrap: wrap;
    gap: 15px;
  }

  .controls-main {
    flex-wrap: wrap;
  }

  .tips-grid {
    grid-template-columns: 1fr;
  }

  .feedback-actions {
    flex-direction: column;
  }
}
</style>
