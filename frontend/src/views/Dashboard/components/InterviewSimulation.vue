<template>
  <div class="interview-simulation-container">
    <!-- æœªå¼€å§‹çŠ¶æ€ -->
    <div v-if="!hasStarted" class="start-section">
      <div class="page-header">
        <h2 class="page-title">é¢è¯•æ¨¡æ‹Ÿæ¨¡å¼</h2>
        <p class="page-subtitle">å®Œå…¨æ¨¡æ‹ŸçœŸå®é¢è¯•åœºæ™¯ï¼Œå…¨ç¨‹æ— ä¸­æ–­ï¼Œè·å¾—ç»¼åˆè¯„æµ‹æŠ¥å‘Š</p>
      </div>

      <!-- è®¾ç½®é¢æ¿ -->
      <div class="settings-panel glass-card">
        <h3>é¢è¯•è®¾ç½®</h3>

        <el-form label-width="120px">
          <el-form-item label="é¢è¯•å…¬å¸">
            <el-select v-model="settings.company" placeholder="é€‰æ‹©æ¨¡æ‹Ÿçš„å…¬å¸ç±»å‹" style="width: 100%">
              <el-option label="äº’è”ç½‘å¤§å‚" value="tech">
                <span style="float: left">äº’è”ç½‘å¤§å‚</span>
                <span style="float: right; color: var(--text-secondary); font-size: 13px">
                  åæŠ€æœ¯æ·±åº¦ï¼ŒèŠ‚å¥è¾ƒå¿«
                </span>
              </el-option>
              <el-option label="å¤–ä¼" value="foreign">
                <span style="float: left">å¤–ä¼</span>
                <span style="float: right; color: var(--text-secondary); font-size: 13px">
                  é‡è§†è‹±è¯­è¡¨è¾¾ï¼Œæ³¨é‡è½¯æŠ€èƒ½
                </span>
              </el-option>
              <el-option label="å›½ä¼/äº‹ä¸šå•ä½" value="state">
                <span style="float: left">å›½ä¼/äº‹ä¸šå•ä½</span>
                <span style="float: right; color: var(--text-secondary); font-size: 13px">
                  åç»¼åˆç´ è´¨ï¼Œç¨³é‡ä¸ºä¸»
                </span>
              </el-option>
              <el-option label="åˆ›ä¸šå…¬å¸" value="startup">
                <span style="float: left">åˆ›ä¸šå…¬å¸</span>
                <span style="float: right; color: var(--text-secondary); font-size: 13px">
                  çœ‹é‡æ½œåŠ›ï¼Œçµæ´»å¤šå˜
                </span>
              </el-option>
            </el-select>
          </el-form-item>

          <el-form-item label="é¢è¯•å²—ä½">
            <el-select v-model="settings.position" placeholder="è¯·é€‰æ‹©é¢è¯•å²—ä½" style="width: 100%">
              <el-option label="å‰ç«¯å¼€å‘" value="frontend" />
              <el-option label="åç«¯å¼€å‘" value="backend" />
              <el-option label="ç®—æ³•å·¥ç¨‹å¸ˆ" value="algorithm" />
              <el-option label="äº§å“ç»ç†" value="product" />
              <el-option label="UIè®¾è®¡å¸ˆ" value="design" />
              <el-option label="æ•°æ®åˆ†æå¸ˆ" value="data" />
            </el-select>
          </el-form-item>

          <el-form-item label="é¢è¯•è½®æ¬¡">
            <el-radio-group v-model="settings.round">
              <el-radio label="first">åˆè¯• - åŸºç¡€èƒ½åŠ›è€ƒå¯Ÿ</el-radio>
              <el-radio label="second">å¤è¯• - æ·±åº¦æŠ€æœ¯é¢è¯•</el-radio>
              <el-radio label="final">ç»ˆé¢ - ç»¼åˆç´ è´¨è¯„ä¼°</el-radio>
            </el-radio-group>
          </el-form-item>

          <el-form-item label="é¢è¯•é£æ ¼">
            <el-select v-model="settings.interviewStyle" placeholder="é€‰æ‹©é¢è¯•é£æ ¼" style="width: 100%">
              <el-option label="æ ‡å‡†æ¨¡å¼ - æŒ‰å…¬å¸æƒ¯ä¾‹è¿›è¡Œ" value="standard" />
              <el-option label="å‹åŠ›æ¨¡å¼ - é«˜å¼ºåº¦å¿«èŠ‚å¥" value="stress" />
              <el-option label="å‹å¥½æ¨¡å¼ - è½»æ¾æ„‰å¿«æ°›å›´" value="friendly" />
              <el-option label="æŠ€æœ¯æ·±æŒ– - ä¸“æ³¨æŠ€æœ¯ç»†èŠ‚" value="technical" />
              <el-option label="è¡Œä¸ºé¢è¯• - é‡ç‚¹è€ƒå¯Ÿè½¯æŠ€èƒ½" value="behavioral" />
            </el-select>
          </el-form-item>

          <el-form-item label="é¢è¯•å®˜é…ç½®">
            <div class="interviewer-config">
              <div
                v-for="interviewer in interviewerOptions"
                :key="interviewer.id"
                class="interviewer-option"
                :class="{ selected: settings.interviewerId === interviewer.id }"
                @click="settings.interviewerId = interviewer.id"
              >
                <el-avatar :size="50" :src="interviewer.avatar" />
                <div class="interviewer-details">
                  <h5>{{ interviewer.name }}</h5>
                  <p>{{ interviewer.role }}</p>
                  <div class="interviewer-tags">
                    <el-tag
                      v-for="tag in interviewer.specialties"
                      :key="tag"
                      size="small"
                      type="info"
                    >
                      {{ tag }}
                    </el-tag>
                  </div>
                </div>
              </div>
            </div>
          </el-form-item>

          <el-form-item label="é¢è¯•æ—¶é•¿">
            <el-select v-model="settings.duration" style="width: 100%">
              <el-option :label="'30åˆ†é’Ÿ - å¿«é€Ÿè¯„ä¼°'" :value="30" />
              <el-option :label="'45åˆ†é’Ÿ - æ ‡å‡†é¢è¯•'" :value="45" />
              <el-option :label="'60åˆ†é’Ÿ - æ·±åº¦é¢è¯•'" :value="60" />
              <el-option :label="'90åˆ†é’Ÿ - å…¨é¢è¯„ä¼°'" :value="90" />
            </el-select>
          </el-form-item>

          <el-form-item label="è¯„ä¼°é‡ç‚¹">
            <el-checkbox-group v-model="settings.evaluationFocus">
              <el-checkbox label="technical">æŠ€æœ¯èƒ½åŠ›</el-checkbox>
              <el-checkbox label="communication">æ²Ÿé€šè¡¨è¾¾</el-checkbox>
              <el-checkbox label="problem_solving">é—®é¢˜è§£å†³</el-checkbox>
              <el-checkbox label="leadership">é¢†å¯¼åŠ›</el-checkbox>
              <el-checkbox label="cultural_fit">æ–‡åŒ–åŒ¹é…</el-checkbox>
            </el-checkbox-group>
          </el-form-item>
        </el-form>

        <div class="simulation-warning">
          <el-alert type="warning" :closable="false" show-icon>
            <template #title>
              æ¨¡æ‹Ÿæ¨¡å¼æ³¨æ„äº‹é¡¹
            </template>
            <template #default>
              <ul>
                <li>é¢è¯•è¿‡ç¨‹ä¸å¯æš‚åœï¼Œè¯·ç¡®ä¿æœ‰å……è¶³æ—¶é—´å’Œè‰¯å¥½ç¯å¢ƒ</li>
                <li>å…¨ç¨‹å½•éŸ³å½•åƒï¼Œç”¨äºåç»­è¯¦ç»†åˆ†æ</li>
                <li>ç³»ç»Ÿå°†ä¸¥æ ¼æŒ‰ç…§çœŸå®é¢è¯•æ ‡å‡†è¿›è¡Œè¯„ä¼°</li>
                <li>ç»“æŸåç”Ÿæˆä¸“ä¸šçš„é¢è¯•è¯„æµ‹æŠ¥å‘Š</li>
              </ul>
            </template>
          </el-alert>
        </div>

        <div class="settings-actions">
          <button
            class="start-btn tech-button"
            @click="startSimulation"
            :disabled="!canStart"
          >
            <el-icon><VideoPlay /></el-icon>
            å¼€å§‹æ¨¡æ‹Ÿé¢è¯•
          </button>
        </div>
      </div>
    </div>

    <!-- é¢è¯•è¿›è¡Œä¸­ -->
    <div v-else class="interview-main">
      <!-- é¡¶éƒ¨çŠ¶æ€æ  -->
      <div class="status-bar glass-card">
        <div class="interview-info">
          <el-tag type="danger">æ¨¡æ‹Ÿé¢è¯•</el-tag>
          <span class="company-info">{{ getCompanyName(settings.company) }} - {{ settings.position }}</span>
          <span class="round-info">{{ getRoundName(settings.round) }}</span>
        </div>

        <div class="time-display">
          <el-icon><Timer /></el-icon>
          <span class="time-text">{{ formatTime(elapsedTime) }} / {{ formatTime(totalTime) }}</span>
          <el-progress
            :percentage="timeProgress"
            :color="getTimeColor(timeProgress)"
            :show-text="false"
            style="width: 200px; margin-left: 15px;"
          />
        </div>

        <div class="emergency-controls">
          <el-button type="danger" size="small" @click="emergencyExit">
            ç´§æ€¥é€€å‡º
          </el-button>
        </div>
      </div>

      <!-- ä¸»è¦é¢è¯•åŒºåŸŸ -->
      <div class="interview-area">
        <!-- å·¦ä¾§ï¼šè™šæ‹Ÿé¢è¯•å®˜ -->
        <div class="interviewer-section">
          <!-- 3Dè™šæ‹Ÿäººå®¹å™¨ -->
          <div class="virtual-interviewer glass-card">
            <div ref="virtualHumanContainer" class="virtual-human-canvas"></div>
            <div class="interviewer-info-bar">
              <div class="interviewer-status">
                <div class="status-indicator" :class="{ speaking: isSpeaking, listening: isListening }"></div>
                <span>{{ currentInterviewer.name }}</span>
              </div>
              <div class="interview-phase">
                <el-tag size="small" :type="getPhaseType(currentPhase)">
                  {{ getPhaseTitle(currentPhase) }}
                </el-tag>
              </div>
            </div>
          </div>

          <!-- å½“å‰é—®é¢˜æ˜¾ç¤º -->
          <div class="question-display glass-card">
            <div class="question-header">
              <el-icon><QuestionFilled /></el-icon>
              <span>é¢è¯•é—®é¢˜ {{ currentQuestionIndex + 1 }}/{{ totalQuestions }}</span>
            </div>
            <div class="question-content">
              <p class="question-text">{{ currentQuestion.text }}</p>
              <div class="question-context" v-if="currentQuestion.context">
                <el-tag size="small" type="info">{{ currentQuestion.context }}</el-tag>
              </div>
            </div>
          </div>
        </div>

        <!-- å³ä¾§ï¼šç”¨æˆ·è§†é¢‘å’Œæ§åˆ¶ -->
        <div class="candidate-section">
          <!-- ç”¨æˆ·è§†é¢‘ -->
          <div class="user-video-container glass-card">
            <video ref="userVideoRef" autoplay muted playsinline></video>
            <div v-if="!cameraReady" class="video-setup">
              <el-icon :size="60"><VideoCamera /></el-icon>
              <p>è¯·å¼€å¯æ‘„åƒå¤´å’Œéº¦å…‹é£</p>
              <el-button type="primary" @click="setupCamera">
                è®¾ç½®è®¾å¤‡
              </el-button>
            </div>

            <!-- å½•åˆ¶çŠ¶æ€æŒ‡ç¤º -->
            <div v-if="isRecording" class="recording-indicator">
              <div class="rec-dot"></div>
              <span>REC</span>
            </div>
          </div>

          <!-- å›ç­”æ§åˆ¶åŒº -->
          <div class="answer-control glass-card">
            <div v-if="!isAnswering" class="waiting-state">
              <h4>{{ waitingMessage }}</h4>
              <p>{{ waitingDescription }}</p>
              <el-button
                v-if="canStartAnswer"
                type="primary"
                size="large"
                @click="startAnswer"
              >
                <el-icon><Microphone /></el-icon>
                å¼€å§‹å›ç­”
              </el-button>
            </div>

            <div v-else class="answering-state">
              <div class="answer-timer">
                <el-progress
                  type="circle"
                  :percentage="answerProgress"
                  :width="80"
                  :stroke-width="6"
                  :color="getAnswerProgressColor(answerProgress)"
                >
                  <template #default="{ percentage }">
                    <span class="timer-text">{{ formatTime(answerTime) }}</span>
                  </template>
                </el-progress>
              </div>

              <div class="answer-controls">
                <el-button
                  type="success"
                  @click="finishAnswer"
                  :disabled="answerTime < 10"
                >
                  <el-icon><Check /></el-icon>
                  å®Œæˆå›ç­”
                </el-button>
                <p class="answer-hint">
                  {{ answerTime < 10 ? 'è¯·è‡³å°‘å›ç­”10ç§’' : 'ç‚¹å‡»å®Œæˆå›ç­”æˆ–ç»§ç»­è¡¨è¾¾' }}
                </p>
              </div>
            </div>
          </div>

          <!-- å®æ—¶åé¦ˆ -->
          <div class="realtime-feedback glass-card">
            <h4>å®æ—¶çŠ¶æ€</h4>
            <div class="feedback-items">
              <div class="feedback-item">
                <span class="label">è¯­éŸ³éŸ³é‡ï¼š</span>
                <el-progress
                  :percentage="audioLevel"
                  :show-text="false"
                  :stroke-width="8"
                  :color="audioLevel > 20 ? '#67c23a' : '#f56c6c'"
                />
              </div>
              <div class="feedback-item">
                <span class="label">è¡¨æƒ…çŠ¶æ€ï¼š</span>
                <span class="status-text" :class="emotionAnalysis.type">
                  {{ emotionAnalysis.text }}
                </span>
              </div>
              <div class="feedback-item">
                <span class="label">çœ¼ç¥æ¥è§¦ï¼š</span>
                <span class="status-text" :class="eyeContactStatus.type">
                  {{ eyeContactStatus.text }}
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- é¢è¯•è¿›åº¦æ¡ -->
      <div class="progress-tracker glass-card">
        <div class="progress-steps">
          <div
            v-for="(phase, index) in interviewPhases"
            :key="phase.id"
            class="progress-step"
            :class="{
              completed: index < currentPhaseIndex,
              active: index === currentPhaseIndex,
              upcoming: index > currentPhaseIndex
            }"
          >
            <div class="step-circle">
              <el-icon v-if="index < currentPhaseIndex"><Check /></el-icon>
              <span v-else>{{ index + 1 }}</span>
            </div>
            <span class="step-label">{{ phase.title }}</span>
          </div>
        </div>
      </div>
    </div>

    <!-- é¢è¯•ç»“æŸå¼¹çª— -->
    <el-dialog
      v-model="showEndDialog"
      title="é¢è¯•å·²ç»“æŸ"
      width="600px"
      :close-on-click-modal="false"
      :show-close="false"
    >
      <div class="end-dialog-content">
        <el-result icon="success">
          <template #title>
            <p>æ­å–œæ‚¨å®Œæˆæœ¬æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼</p>
          </template>
          <template #sub-title>
            <div class="interview-summary">
              <p>é¢è¯•æ—¶é•¿ï¼š{{ formatTime(elapsedTime) }}</p>
              <p>å›ç­”é—®é¢˜ï¼š{{ answeredQuestions }}/{{ totalQuestions }} ä¸ª</p>
              <p>AIæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†çš„é¢è¯•è¯„æµ‹æŠ¥å‘Š...</p>
            </div>
          </template>
          <template #extra>
            <div class="end-actions">
              <el-button type="primary" @click="viewReport" :loading="generatingReport">
                {{ generatingReport ? 'ç”ŸæˆæŠ¥å‘Šä¸­...' : 'æŸ¥çœ‹æŠ¥å‘Š' }}
              </el-button>
              <el-button @click="backToSettings">
                é‡æ–°è®¾ç½®
              </el-button>
              <el-button @click="backToList">
                è¿”å›ä¸»é¡µ
              </el-button>
            </div>
          </template>
        </el-result>
      </div>
    </el-dialog>
  </div>
</template>

<script setup>
import { ref, computed, onUnmounted, nextTick } from 'vue'
import { useRouter } from 'vue-router'
import { ElMessage, ElMessageBox } from 'element-plus'
import * as THREE from 'three'
import {
  VideoPlay, Timer, VideoCamera, QuestionFilled,
  Microphone, Check
} from '@element-plus/icons-vue'

import apiService from '@/api/service.js'

const router = useRouter()

// ================================================================================================
// ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€çŠ¶æ€ç®¡ç†
// ================================================================================================

const hasStarted = ref(false)
const isRecording = ref(false)
const isAnswering = ref(false)
const isSpeaking = ref(false)
const isListening = ref(false)
const cameraReady = ref(false)
const showEndDialog = ref(false)
const generatingReport = ref(false)
const isEmergencyExiting = ref(false)

// é¢è¯•æ•°æ®çŠ¶æ€
const currentInterviewId = ref(null)
const currentQuestionData = ref(null)
const recordedTranscript = ref('')
const recordedAudioBlob = ref(null)
const answerTime = ref(0)

// åª’ä½“ç›¸å…³çŠ¶æ€
const mediaStream = ref(null)
const mediaRecorder = ref(null)

// å®šæ—¶å™¨ç®¡ç†å™¨
const timeoutManager = {
  timeouts: new Set(),
  intervals: new Set(),

  addTimeout(timeoutId) {
    this.timeouts.add(timeoutId)
    return timeoutId
  },

  addInterval(intervalId) {
    this.intervals.add(intervalId)
    return intervalId
  },

  clearTimeout(timeoutId) {
    if (timeoutId) {
      clearTimeout(timeoutId)
      this.timeouts.delete(timeoutId)
    }
  },

  clearInterval(intervalId) {
    if (intervalId) {
      clearInterval(intervalId)
      this.intervals.delete(intervalId)
    }
  },

  clearAll() {
    this.timeouts.forEach(timeoutId => {
      try {
        clearTimeout(timeoutId)
      } catch (e) {
        console.warn('æ¸…é™¤è¶…æ—¶å¤±è´¥:', e)
      }
    })
    this.timeouts.clear()

    this.intervals.forEach(intervalId => {
      try {
        clearInterval(intervalId)
      } catch (e) {
        console.warn('æ¸…é™¤å®šæ—¶å™¨å¤±è´¥:', e)
      }
    })
    this.intervals.clear()
  }
}

// ================================================================================================
// ğŸ® ç¬¬äºŒéƒ¨åˆ†ï¼šé¢è¯•è®¾ç½®å’Œé…ç½®
// ================================================================================================

const settings = ref({
  company: 'tech',
  position: 'frontend',
  round: 'first',
  interviewStyle: 'standard',
  interviewerId: 1,
  duration: 45,
  evaluationFocus: ['technical', 'communication']
})

const interviewerOptions = ref([
  {
    id: 1,
    name: 'å¼ æŠ€æœ¯æ€»ç›‘',
    role: 'æŠ€æœ¯æ€»ç›‘',
    avatar: '/avatars/tech-director.jpg',
    specialties: ['æŠ€æœ¯æ·±åº¦', 'æ¶æ„è®¾è®¡', 'å›¢é˜Ÿç®¡ç†'],
    model: '/models/tech-director.glb'
  },
  {
    id: 2,
    name: 'æHRç»ç†',
    role: 'HRç»ç†',
    avatar: '/avatars/hr-manager.jpg',
    specialties: ['è¡Œä¸ºé¢è¯•', 'æ–‡åŒ–åŒ¹é…', 'ç»¼åˆç´ è´¨'],
    model: '/models/hr-manager.glb'
  },
  {
    id: 3,
    name: 'ç‹äº§å“æ€»ç›‘',
    role: 'äº§å“æ€»ç›‘',
    avatar: '/avatars/product-director.jpg',
    specialties: ['äº§å“æ€ç»´', 'ç”¨æˆ·ä½“éªŒ', 'å•†ä¸šé€»è¾‘'],
    model: '/models/product-director.glb'
  }
])

const interviewPhases = ref([
  { id: 'intro', title: 'å¼€åœºä»‹ç»' },
  { id: 'self', title: 'è‡ªæˆ‘ä»‹ç»' },
  { id: 'technical', title: 'æŠ€æœ¯é—®ç­”' },
  { id: 'project', title: 'é¡¹ç›®ç»å†' },
  { id: 'behavioral', title: 'è¡Œä¸ºé¢è¯•' },
  { id: 'questions', title: 'æé—®ç¯èŠ‚' }
])

// ================================================================================================
// ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¢è¯•è¿›åº¦å’ŒçŠ¶æ€
// ================================================================================================

const elapsedTime = ref(0)
const totalTime = computed(() => {
  const duration = settings.value?.duration
  return (duration && typeof duration === 'number') ? duration * 60 : 1800
})

const timeProgress = computed(() => {
  const elapsed = elapsedTime.value || 0
  const total = totalTime.value || 1
  const progress = Math.round((elapsed / total) * 100)
  return Math.max(0, Math.min(100, progress))
})

const currentPhaseIndex = ref(0)
const currentPhase = computed(() => {
  const phases = interviewPhases.value
  const index = currentPhaseIndex.value
  if (phases && Array.isArray(phases) && phases[index]) {
    return phases[index].id || 'intro'
  }
  return 'intro'
})

const currentQuestionIndex = ref(0)
const totalQuestions = ref(8)
const answeredQuestions = ref(0)

const currentQuestion = ref({
  text: 'æ‚¨å¥½ï¼Œæ¬¢è¿å‚åŠ æˆ‘ä»¬çš„é¢è¯•ã€‚è¯·å…ˆåšä¸€ä¸ªç®€å•çš„è‡ªæˆ‘ä»‹ç»ã€‚',
  context: 'è¯·åœ¨2-3åˆ†é’Ÿå†…å®Œæˆ',
  type: 'self-introduction',
  expectedDuration: 180
})

const currentInterviewer = computed(() => {
  try {
    const options = interviewerOptions.value
    const id = settings.value?.interviewerId

    if (!options || !Array.isArray(options) || options.length === 0) {
      return {
        id: 1,
        name: 'é»˜è®¤é¢è¯•å®˜',
        role: 'é¢è¯•å®˜',
        avatar: '/avatars/default.jpg',
        specialties: ['é€šç”¨']
      }
    }

    if (id && typeof id === 'number') {
      const found = options.find(i => i && i.id === id)
      if (found) return found
    }

    return options[0] || {
      id: 1,
      name: 'é»˜è®¤é¢è¯•å®˜',
      role: 'é¢è¯•å®˜',
      avatar: '/avatars/default.jpg',
      specialties: ['é€šç”¨']
    }
  } catch (error) {
    return {
      id: 1,
      name: 'é»˜è®¤é¢è¯•å®˜',
      role: 'é¢è¯•å®˜',
      avatar: '/avatars/default.jpg',
      specialties: ['é€šç”¨']
    }
  }
})

// ================================================================================================
// ğŸ¤– ç¬¬å››éƒ¨åˆ†ï¼šAIå®æ—¶åˆ†ææ¥å£åŒºåŸŸ
// ================================================================================================

const audioLevel = ref(0)
const emotionAnalysis = ref({ type: 'neutral', text: 'è‡ªç„¶' })
const eyeContactStatus = ref({ type: 'good', text: 'è‰¯å¥½' })

/**
 * æ¨¡æ‹Ÿé¢è¯•è¯­éŸ³è½¬æ–‡å­—å¤„ç†ï¼ˆä¸¥æ ¼æ ‡å‡†ï¼‰
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œæ¨¡æ‹Ÿé¢è¯•éœ€è¦æ›´é«˜ç²¾åº¦ï¼š
 * - æ”¯æŒä¸“ä¸šæœ¯è¯­è¯†åˆ«
 * - æ›´ä¸¥æ ¼çš„è¯­éŸ³è´¨é‡è¯„ä¼°
 * - è¯†åˆ«è¯­è¨€è¡¨è¾¾çš„ä¸“ä¸šæ€§
 * - åˆ†æå›ç­”çš„é€»è¾‘ç»“æ„
 */
const transcribeAudioForSimulation = async (audioBlob) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const transcript = await aiService.speechToTextAdvanced({
  //     audioBlob: audioBlob,
  //     language: 'zh-CN',
  //     mode: 'interview_simulation',
  //     analysisLevel: 'professional',
  //     includeQualityMetrics: true
  //   })
  //   return {
  //     text: transcript.text,
  //     quality: transcript.qualityScore,
  //     professionalism: transcript.professionalismScore
  //   }
  // } catch (error) {
  //   console.error('é«˜ç²¾åº¦è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
  //   return { text: '', quality: 0, professionalism: 0 }
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  return {
    text: 'è¿™æ˜¯æ¨¡æ‹Ÿé¢è¯•çš„è¯­éŸ³è½¬æ–‡å­—ç»“æœï¼Œç²¾åº¦æ›´é«˜ã€‚',
    quality: 85,
    professionalism: 78
  }
}

/**
 * æ¨¡æ‹Ÿé¢è¯•å‹åŠ›æµ‹è¯•åˆ†æ
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - å‹åŠ›ç¯å¢ƒè¡¨ç°åˆ†æ
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œåˆ†æå‹åŠ›ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼š
 * - åˆ†æåœ¨å‹åŠ›é—®é¢˜ä¸‹çš„ååº”é€Ÿåº¦
 * - è¯„ä¼°é€»è¾‘æ€ç»´çš„æ¸…æ™°åº¦
 * - è¯†åˆ«ç´§å¼ æƒ…ç»ªå¯¹è¡¨ç°çš„å½±å“
 * - æä¾›æŠ—å‹èƒ½åŠ›è¯„ä¼°
 */
const analyzeStressPerformance = (behaviorData) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const analysis = await aiService.analyzeStressResponse({
  //     audioData: behaviorData.audio,
  //     videoData: behaviorData.video,
  //     responseTime: behaviorData.responseTime,
  //     questionDifficulty: behaviorData.difficulty,
  //     stressLevel: behaviorData.stressLevel
  //   })
  //   return {
  //     stressResistance: analysis.stressResistanceScore,
  //     logicalClarity: analysis.logicalClarityScore,
  //     emotionalControl: analysis.emotionalControlScore
  //   }
  // } catch (error) {
  //   return getDefaultStressAnalysis()
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  return {
    stressResistance: Math.random() * 40 + 60,
    logicalClarity: Math.random() * 30 + 70,
    emotionalControl: Math.random() * 35 + 65
  }
}

/**
 * ç»¼åˆè¡¨ç°è¯„ä¼°åˆ†æ
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - å¤šç»´åº¦ç»¼åˆè¯„ä¼°
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œç»¼åˆè¡¨ç°åˆ†æï¼š
 * - æŠ€æœ¯èƒ½åŠ›æ·±åº¦è¯„ä¼°
 * - æ²Ÿé€šè¡¨è¾¾ä¸“ä¸šæ€§åˆ†æ
 * - é—®é¢˜è§£å†³æ€è·¯è¯„ä¼°
 * - æ–‡åŒ–åŒ¹é…åº¦åˆ†æ
 * - é¢†å¯¼åŠ›æ½œè´¨è¯„ä¼°
 */
const analyzeComprehensivePerformance = async (interviewData) => {
  // ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
  // try {
  //   const analysis = await aiService.comprehensivePerformanceAnalysis({
  //     interviewType: 'simulation',
  //     company: interviewData.company,
  //     position: interviewData.position,
  //     round: interviewData.round,
  //     answers: interviewData.answers,
  //     behaviorMetrics: interviewData.behaviorMetrics,
  //     evaluationFocus: interviewData.evaluationFocus
  //   })
  //   return {
  //     technicalScore: analysis.technical,
  //     communicationScore: analysis.communication,
  //     problemSolvingScore: analysis.problemSolving,
  //     culturalFitScore: analysis.culturalFit,
  //     leadershipScore: analysis.leadership,
  //     overallRecommendation: analysis.recommendation
  //   }
  // } catch (error) {
  //   return getDefaultComprehensiveAnalysis()
  // }

  // å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
  return {
    technicalScore: Math.random() * 30 + 70,
    communicationScore: Math.random() * 25 + 75,
    problemSolvingScore: Math.random() * 30 + 70,
    culturalFitScore: Math.random() * 20 + 80,
    leadershipScore: Math.random() * 40 + 60,
    overallRecommendation: 'qualified'
  }
}

/**
 * å®æ—¶è¡¨ç°ç›‘æ§å’Œåˆ†æ
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•å®æ—¶ç›‘æ§
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œæ›´ä¸¥æ ¼çš„å®æ—¶ç›‘æ§ï¼š
 * - ä¸“ä¸šè¡¨è¾¾ç”¨è¯åˆ†æ
 * - å›ç­”é€»è¾‘ç»“æ„æ£€æµ‹
 * - è‡ªä¿¡åº¦å®æ—¶è¯„ä¼°
 * - é¢è¯•ç¤¼ä»ªç›‘æ§
 */
const updateLocalAnalysisDisplay = () => {
  if (isEmergencyExiting.value) {
    return
  }

  try {
    if (isAnswering.value) {
      // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šå®æ—¶ä¸“ä¸šè¡¨ç°åˆ†æ
      const professionalAnalysis = analyzeProfessionalExpression()
      emotionAnalysis.value = Object.assign({}, professionalAnalysis.emotion)

      // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šå®æ—¶é¢è¯•ç¤¼ä»ªåˆ†æ
      const etiquetteAnalysis = analyzeInterviewEtiquette()
      eyeContactStatus.value = Object.assign({}, etiquetteAnalysis.eyeContact)

      audioLevel.value = Math.random() * 80 + 20
    } else {
      audioLevel.value = Math.random() * 20
    }
  } catch (error) {
    if (!isEmergencyExiting.value) {
      emotionAnalysis.value = Object.assign({}, { type: 'neutral', text: 'è‡ªç„¶' })
      eyeContactStatus.value = Object.assign({}, { type: 'good', text: 'è‰¯å¥½' })
      audioLevel.value = 0
    }
  }
}

// è¾…åŠ©AIåˆ†ææ–¹æ³•
const analyzeProfessionalExpression = () => {
  // TODO: å®ç°ä¸“ä¸šè¡¨è¾¾åˆ†æ
  const emotions = ['confident', 'professional', 'thoughtful']
  const emotionTexts = { confident: 'è‡ªä¿¡', professional: 'ä¸“ä¸š', thoughtful: 'æ·±æ€' }
  const emotion = emotions[Math.floor(Math.random() * 3)]

  return {
    emotion: { type: emotion, text: emotionTexts[emotion] }
  }
}

const analyzeInterviewEtiquette = () => {
  // TODO: å®ç°é¢è¯•ç¤¼ä»ªåˆ†æ
  const etiquetteTypes = ['excellent', 'good', 'needs_improvement']
  const etiquetteTexts = { excellent: 'ä¼˜ç§€', good: 'è‰¯å¥½', needs_improvement: 'å¾…æ”¹å–„' }
  const type = etiquetteTypes[Math.floor(Math.random() * 3)]

  return {
    eyeContact: { type: type, text: etiquetteTexts[type] }
  }
}

// ================================================================================================
// ğŸ¥ ç¬¬äº”éƒ¨åˆ†ï¼šåª’ä½“è®¾å¤‡å’Œ3Dæ¸²æŸ“
// ================================================================================================

const waitingMessage = ref('è¯·è®¤çœŸå¬é¢˜')
const waitingDescription = ref('é¢è¯•å®˜æ­£åœ¨æé—®ï¼Œè¯·ä»”ç»†å¬å®Œé—®é¢˜åå¼€å§‹å›ç­”')
const canStartAnswer = ref(false)

let scene, camera, renderer, avatarMesh
const virtualHumanContainer = ref(null)
const userVideoRef = ref(null)

const answerProgress = computed(() => {
  try {
    const expectedDuration = currentQuestion.value?.expectedDuration || 120
    const currentTime = answerTime.value || 0
    if (expectedDuration <= 0) return 0
    const progress = Math.min(100, (currentTime / expectedDuration) * 100)
    return Math.max(0, Math.round(progress))
  } catch (error) {
    return 0
  }
})

const initVirtualHuman = () => {
  if (!virtualHumanContainer.value) return

  try {
    scene = new THREE.Scene()
    scene.background = new THREE.Color(0x0a0e27)

    camera = new THREE.PerspectiveCamera(
      45,
      virtualHumanContainer.value.clientWidth / virtualHumanContainer.value.clientHeight,
      0.1,
      1000
    )
    camera.position.set(0, 0, 5)

    renderer = new THREE.WebGLRenderer({ antialias: true })
    renderer.setSize(
      virtualHumanContainer.value.clientWidth,
      virtualHumanContainer.value.clientHeight
    )
    virtualHumanContainer.value.appendChild(renderer.domElement)

    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5)
    scene.add(ambientLight)

    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5)
    directionalLight.position.set(0, 1, 1)
    scene.add(directionalLight)

    const geometry = new THREE.CylinderGeometry(0.4, 0.5, 1.5, 8)
    const material = new THREE.MeshPhongMaterial({
      color: 0x4a90e2,
      transparent: true,
      opacity: 0.8
    })
    avatarMesh = new THREE.Mesh(geometry, material)
    scene.add(avatarMesh)

    animate()

  } catch (error) {
    createSimplePlaceholder()
  }
}

const createSimplePlaceholder = () => {
  try {
    if (!virtualHumanContainer.value) return

    virtualHumanContainer.value.innerHTML = `
      <div style="
        width: 100%;
        height: 100%;
        display: flex;
        align-items: center;
        justify-content: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 12px;
        color: white;
        font-size: 48px;
      ">
        <div style="text-align: center;">
          <div style="font-size: 64px; margin-bottom: 10px;">ğŸ‘¨â€ğŸ’¼</div>
          <div style="font-size: 16px;">${currentInterviewer.value.name}</div>
        </div>
      </div>
    `
  } catch (error) {
    console.error('åˆ›å»ºå ä½ç¬¦å¤±è´¥:', error)
  }
}

const animate = () => {
  requestAnimationFrame(animate)

  if (avatarMesh) {
    avatarMesh.rotation.y += 0.005
    if (isSpeaking.value) {
      avatarMesh.scale.y = 1 + Math.sin(Date.now() * 0.005) * 0.05
    }
  }

  renderer?.render(scene, camera)
}

const setupCamera = async () => {
  try {
    if (!mediaStream.value) {
      mediaStream.value = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true
      })
    }

    if (userVideoRef.value && mediaStream.value) {
      userVideoRef.value.srcObject = mediaStream.value
    }

    cameraReady.value = true
    startAudioMonitoring()
    ElMessage.success('è®¾å¤‡è®¾ç½®å®Œæˆ')

  } catch (error) {
    ElMessage.error('æ— æ³•è®¿é—®æ‘„åƒå¤´æˆ–éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
    cameraReady.value = false
    mediaStream.value = null
  }
}

// ================================================================================================
// ğŸ¤ ç¬¬å…­éƒ¨åˆ†ï¼šå½•éŸ³å’Œå›ç­”æ§åˆ¶
// ================================================================================================

const initMediaRecorder = async () => {
  try {
    if (!mediaStream.value) {
      mediaStream.value = await navigator.mediaDevices.getUserMedia({
        audio: true,
        video: false
      })
    }

    if (!mediaStream.value || typeof mediaStream.value.getAudioTracks !== 'function') {
      throw new Error('æ— æ•ˆçš„åª’ä½“æµ')
    }

    mediaRecorder.value = new MediaRecorder(mediaStream.value, {
      mimeType: 'audio/webm;codecs=opus'
    })

    let audioChunks = []

    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        audioChunks.push(event.data)
      }
    }

    mediaRecorder.value.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
      recordedAudioBlob.value = audioBlob
      audioChunks = []

      // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šæ¨¡æ‹Ÿé¢è¯•é«˜ç²¾åº¦è¯­éŸ³è½¬æ–‡å­—
      const transcriptionResult = await transcribeAudioForSimulation(audioBlob)
      recordedTranscript.value = transcriptionResult.text
    }

    return true

  } catch (error) {
    ElMessage.error('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
    mediaRecorder.value = null
    return false
  }
}

const startRecording = async () => {
  try {
    if (!mediaRecorder.value) {
      const success = await initMediaRecorder()
      if (!success) return false
    }

    recordedAudioBlob.value = null
    recordedTranscript.value = ''

    if (mediaRecorder.value.state === 'inactive') {
      mediaRecorder.value.start(1000)
      isRecording.value = true
      return true
    }

  } catch (error) {
    ElMessage.error('å¼€å§‹å½•éŸ³å¤±è´¥ï¼š' + error.message)
    return false
  }
}

const stopRecording = async () => {
  try {
    if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
      mediaRecorder.value.stop()
    }

    isRecording.value = false

    return new Promise((resolve) => {
      setTimeout(() => {
        resolve(recordedAudioBlob.value)
      }, 500)
    })

  } catch (error) {
    ElMessage.error('åœæ­¢å½•éŸ³å¤±è´¥ï¼š' + error.message)
    return null
  }
}

// ================================================================================================
// ğŸ“‹ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šé¢è¯•æµç¨‹æ§åˆ¶
// ================================================================================================

const startSimulation = async () => {
  try {
    const hasResume = localStorage.getItem('userResume')
    if (!hasResume) {
      const confirm = await ElMessageBox.confirm(
        'æ£€æµ‹åˆ°æ‚¨è¿˜æœªä¸Šä¼ ç®€å†ï¼Œå»ºè®®å…ˆä¸Šä¼ ç®€å†ä»¥è·å¾—ä¸ªæ€§åŒ–çš„é¢è¯•é¢˜ç›®ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ',
        'æç¤º',
        {
          confirmButtonText: 'ç»§ç»­æ¨¡æ‹Ÿ',
          cancelButtonText: 'å»ä¸Šä¼ ç®€å†',
          type: 'warning'
        }
      ).catch(() => false)

      if (!confirm) {
        router.push('/dashboard/resume-manage')
        return
      }
    }

    const response = await apiService.interview.startSimulation({
      company: settings.value.company,
      position: settings.value.position,
      round: settings.value.round,
      interviewStyle: settings.value.interviewStyle,
      interviewerId: settings.value.interviewerId,
      duration: settings.value.duration,
      evaluationFocus: settings.value.evaluationFocus
    })

    currentInterviewId.value = response.data.interview_id
    currentQuestionData.value = response.data.first_question
    totalQuestions.value = response.data.total_questions

    if (currentQuestionData.value) {
      currentQuestion.value = {
        text: currentQuestionData.value.text,
        type: currentQuestionData.value.type,
        difficulty: currentQuestionData.value.difficulty,
        context: `è¯·åœ¨${Math.floor(currentQuestionData.value.time_limit / 60)}åˆ†é’Ÿå†…å®Œæˆ`,
        expectedDuration: currentQuestionData.value.time_limit
      }
    }

    hasStarted.value = true

    nextTick(() => {
      initVirtualHuman()
      setupCamera()
    })

    startTimer()

    setTimeout(() => {
      startInterviewFlow()
    }, 2000)

    ElMessage.success('æ¨¡æ‹Ÿé¢è¯•å¼€å§‹ï¼')

  } catch (error) {
    ElMessage.error('å¼€å§‹æ¨¡æ‹Ÿé¢è¯•å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const startInterviewFlow = async () => {
  try {
    if (isEmergencyExiting.value) {
      return
    }

    await apiService.interview.updateInterviewerStatus(currentInterviewId.value, {
      isSpeaking: true,
      isListening: false,
      currentPhase: 'intro'
    })

    isSpeaking.value = true
    waitingMessage.value = 'é¢è¯•å®˜æ­£åœ¨ä»‹ç»'
    waitingDescription.value = `æ¬¢è¿å‚åŠ ${getCompanyName(settings.value.company)}çš„é¢è¯•`

    const speakingTimeoutId = setTimeout(async () => {
      try {
        if (isEmergencyExiting.value) {
          return
        }

        if (!currentInterviewId.value) {
          return
        }

        if (!currentQuestion.value) {
          return
        }

        await apiService.interview.updateInterviewerStatus(currentInterviewId.value, {
          isSpeaking: false,
          isListening: true,
          currentPhase: 'self'
        })

        if (!isEmergencyExiting.value) {
          isSpeaking.value = false
          isListening.value = true
          waitingMessage.value = 'è¯·å¼€å§‹å›ç­”'

          const context = currentQuestion.value?.context || 'è¯·å¼€å§‹æ‚¨çš„å›ç­”'
          waitingDescription.value = context
          canStartAnswer.value = true
        }

        timeoutManager.clearTimeout(speakingTimeoutId)

      } catch (error) {
        timeoutManager.clearTimeout(speakingTimeoutId)
      }
    }, 5000)

    timeoutManager.addTimeout(speakingTimeoutId)

  } catch (error) {
    console.error('å¯åŠ¨é¢è¯•æµç¨‹å¤±è´¥:', error)
  }
}

const startAnswer = async () => {
  try {
    await apiService.interview.startAnswerSimulation(
      currentInterviewId.value,
      currentQuestionData.value.id
    )

    isAnswering.value = true
    answerTime.value = 0
    canStartAnswer.value = false

    let answerTimer = setInterval(() => {
      answerTime.value++
    }, 1000)

    timeoutManager.addInterval(answerTimer)
    startRealtimeAnalysis()

    ElMessage.success('å¼€å§‹å›ç­”ï¼Œè¯·è‡ªç„¶è¡¨è¾¾')

  } catch (error) {
    ElMessage.error('å¼€å§‹å›ç­”å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const finishAnswer = async () => {
  try {
    const response = await apiService.interview.finishAnswerSimulation(
      currentInterviewId.value,
      currentQuestionData.value.id,
      {
        answerText: recordedTranscript.value || '',
        audioPath: recordedAudioBlob.value ? 'temp_audio_path' : null,
        videoPath: null,
        timeSpent: answerTime.value
      }
    )

    isAnswering.value = false
    answeredQuestions.value++

    stopRealtimeAnalysis()

    ElMessage.success(`å›ç­”å·²æäº¤ï¼Œè¯„åˆ†ï¼š${response.data.score}`)

    if (response.data.next_question) {
      currentQuestionData.value = response.data.next_question
      currentQuestionIndex.value++

      currentQuestion.value = {
        text: response.data.next_question.text,
        type: response.data.next_question.type,
        difficulty: response.data.next_question.difficulty,
        context: `è¯·åœ¨${Math.floor(response.data.next_question.time_limit / 60)}åˆ†é’Ÿå†…å®Œæˆ`,
        expectedDuration: response.data.next_question.time_limit
      }

      setTimeout(() => {
        nextQuestion()
      }, 2000)
    } else {
      setTimeout(() => {
        endInterview()
      }, 3000)
    }

  } catch (error) {
    ElMessage.error('å®Œæˆå›ç­”å¤±è´¥ï¼š' + (error.response?.data?.detail || error.message))
  }
}

const nextQuestion = async () => {
  try {
    if (isEmergencyExiting.value) {
      return
    }

    const phaseIndex = currentQuestionIndex.value
    let currentPhase = 'general'

    if (phaseIndex <= 1) currentPhase = 'self'
    else if (phaseIndex <= 3) currentPhase = 'technical'
    else if (phaseIndex <= 5) currentPhase = 'project'
    else if (phaseIndex <= 6) currentPhase = 'behavioral'
    else currentPhase = 'questions'

    await apiService.interview.updateInterviewPhase(currentInterviewId.value, {
      currentPhase: currentPhase,
      phaseIndex: phaseIndex
    })

    currentPhaseIndex.value = phaseIndex

    await apiService.interview.updateInterviewerStatus(currentInterviewId.value, {
      isSpeaking: true,
      isListening: false,
      currentPhase: currentPhase
    })

    isSpeaking.value = true
    waitingMessage.value = 'é¢è¯•å®˜æ­£åœ¨æé—®'
    waitingDescription.value = 'è¯·è®¤çœŸå¬é¢˜ï¼Œå‡†å¤‡å›ç­”'
    canStartAnswer.value = false

    const questionTimeoutId = setTimeout(async () => {
      try {
        if (isEmergencyExiting.value) {
          return
        }

        if (!currentInterviewId.value) {
          return
        }

        await apiService.interview.updateInterviewerStatus(currentInterviewId.value, {
          isSpeaking: false,
          isListening: true,
          currentPhase: currentPhase
        })

        if (!isEmergencyExiting.value) {
          isSpeaking.value = false
          isListening.value = true
          waitingMessage.value = 'è¯·å¼€å§‹å›ç­”'

          const context = currentQuestion.value?.context || 'è¯·å¼€å§‹æ‚¨çš„å›ç­”'
          waitingDescription.value = context
          canStartAnswer.value = true
        }

        timeoutManager.clearTimeout(questionTimeoutId)

      } catch (error) {
        timeoutManager.clearTimeout(questionTimeoutId)
      }
    }, 3000)

    timeoutManager.addTimeout(questionTimeoutId)

  } catch (error) {
    console.error('åˆ‡æ¢ä¸‹ä¸€é¢˜å¤±è´¥:', error)
  }
}

// ================================================================================================
// ğŸ¤– ç¬¬å…«éƒ¨åˆ†ï¼šå®æ—¶åˆ†æå¤„ç†æ¥å£åŒºåŸŸ
// ================================================================================================

/**
 * å¼€å§‹æ¨¡æ‹Ÿé¢è¯•å®æ—¶åˆ†æ
 *
 * ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•å®æ—¶ç›‘æ§
 * TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œæ›´ä¸¥æ ¼çš„å®æ—¶åˆ†æï¼š
 * - ä¸“ä¸šè¡¨ç°å®æ—¶ç›‘æ§
 * - å‹åŠ›æµ‹è¯•ååº”åˆ†æ
 * - é¢è¯•ç¤¼ä»ªå®æ—¶è¯„ä¼°
 * - ç»¼åˆè¡¨ç°åŠ¨æ€è·Ÿè¸ª
 */
const startRealtimeAnalysis = () => {
  const analysisId = setInterval(async () => {
    if (isEmergencyExiting.value) {
      timeoutManager.clearInterval(analysisId)
      return
    }

    if (isAnswering.value && currentInterviewId.value) {
      try {
        // ğŸ¤– AIæ¥å£è°ƒç”¨ï¼šæ¨¡æ‹Ÿé¢è¯•å®æ—¶åˆ†æ
        const realtimeData = {
          audioLevel: Math.random() * 100,
          emotionType: ['confident', 'professional', 'thoughtful'][Math.floor(Math.random() * 3)],
          eyeContactScore: Math.random() * 100,
          speechSpeed: Math.random() * 200 + 100,
          professionalismScore: Math.random() * 40 + 60,
          stressLevel: settings.value.interviewStyle === 'stress' ? Math.random() * 30 + 70 : Math.random() * 20 + 40,
          timestamp: new Date().toISOString()
        }

        await apiService.interview.submitSimulationAnalysis(currentInterviewId.value, realtimeData)

        if (!isEmergencyExiting.value) {
          updateLocalAnalysisDisplay()
        }

      } catch (error) {
        console.error('æäº¤å®æ—¶åˆ†ææ•°æ®å¤±è´¥:', error)
      }
    }
  }, 2000)

  timeoutManager.addInterval(analysisId)
}

const stopRealtimeAnalysis = () => {
  if (!isEmergencyExiting.value) {
    try {
      emotionAnalysis.value = Object.assign({}, { type: 'neutral', text: 'è‡ªç„¶' })
      eyeContactStatus.value = Object.assign({}, { type: 'good', text: 'è‰¯å¥½' })
      audioLevel.value = 0
    } catch (error) {
      console.error('é‡ç½®åˆ†æçŠ¶æ€å¤±è´¥:', error)
    }
  }
}

const startAudioMonitoring = () => {
  const audioMonitorInterval = setInterval(() => {
    if (isAnswering.value) {
      audioLevel.value = Math.random() * 100
    } else {
      audioLevel.value = Math.random() * 20
    }

    if (!isRecording.value && !isAnswering.value) {
      clearInterval(audioMonitorInterval)
    }
  }, 100)
}

// ================================================================================================
// ğŸš¨ ç¬¬ä¹éƒ¨åˆ†ï¼šç´§æ€¥é€€å‡ºå’Œèµ„æºç®¡ç†
// ================================================================================================

const emergencyExit = async () => {
  if (isEmergencyExiting.value) {
    return
  }

  isEmergencyExiting.value = true

  try {
    timeoutManager.clearAll()

    await nextTick()

    try {
      if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
        mediaRecorder.value.stop()
      }
      mediaRecorder.value = null

      if (mediaStream.value && typeof mediaStream.value.getTracks === 'function') {
        mediaStream.value.getTracks().forEach(track => {
          try { track.stop() } catch (e) { /* å¿½ç•¥ */ }
        })
      }
      mediaStream.value = null
    } catch (mediaError) {
      console.warn('åœæ­¢åª’ä½“è®¾å¤‡å¤±è´¥:', mediaError)
    }

    await nextTick()

    try {
      emotionAnalysis.value = Object.assign({}, { type: 'neutral', text: 'è‡ªç„¶' })
      eyeContactStatus.value = Object.assign({}, { type: 'good', text: 'è‰¯å¥½' })
    } catch (objError) {
      emotionAnalysis.value = { type: 'neutral', text: 'è‡ªç„¶' }
      eyeContactStatus.value = { type: 'good', text: 'è‰¯å¥½' }
    }

    await nextTick()

    isRecording.value = false
    isAnswering.value = false
    isSpeaking.value = false
    isListening.value = false
    cameraReady.value = false

    audioLevel.value = 0
    answerTime.value = 0
    elapsedTime.value = 0

    currentInterviewId.value = null
    currentQuestionData.value = null
    recordedAudioBlob.value = null
    recordedTranscript.value = ''

    const confirmed = await ElMessageBox.confirm(
      'ç¡®å®šè¦ç´§æ€¥é€€å‡ºé¢è¯•å—ï¼Ÿè¿™å°†ç»“æŸå½“å‰é¢è¯•å¹¶ç”Ÿæˆéƒ¨åˆ†æŠ¥å‘Šã€‚',
      'ç´§æ€¥é€€å‡º',
      {
        confirmButtonText: 'ç¡®å®šé€€å‡º',
        cancelButtonText: 'ç»§ç»­é¢è¯•',
        type: 'warning'
      }
    ).catch(() => false)

    if (!confirmed) {
      isEmergencyExiting.value = false
      return
    }

    try {
      if (currentInterviewId.value) {
        await apiService.interview.completeSimulation(currentInterviewId.value, {
          completionType: 'emergency',
          emergencyReason: 'ç”¨æˆ·ä¸»åŠ¨é€€å‡º'
        })
      }
    } catch (apiError) {
      console.warn('APIè°ƒç”¨å¤±è´¥:', apiError)
    }

    const endTimeoutId = setTimeout(() => {
      if (isEmergencyExiting.value) {
        showEndDialog.value = true
        generatingReport.value = false
      }
      timeoutManager.clearTimeout(endTimeoutId)
    }, 300)

    timeoutManager.addTimeout(endTimeoutId)

  } catch (error) {
    timeoutManager.clearAll()
    isEmergencyExiting.value = false

    ElMessage.error('é€€å‡ºè¿‡ç¨‹å‡ºç°é—®é¢˜ï¼Œæ­£åœ¨è¿”å›ä¸»é¡µ')

    const emergencyTimeoutId = setTimeout(() => {
      router.push('/dashboard')
      timeoutManager.clearTimeout(emergencyTimeoutId)
    }, 1000)

    timeoutManager.addTimeout(emergencyTimeoutId)
  }
}

const startTimer = () => {
  const timerId = setInterval(() => {
    if (isEmergencyExiting.value) {
      timeoutManager.clearInterval(timerId)
      return
    }

    elapsedTime.value++

    if (elapsedTime.value >= totalTime.value) {
      timeoutManager.clearInterval(timerId)
      endInterview()
    }
  }, 1000)

  timeoutManager.addInterval(timerId)
}

const endInterview = async (isEmergency = false) => {
  try {
    cleanupResources()

    if (!isEmergency && currentInterviewId.value) {
      try {
        await apiService.interview.completeSimulation(currentInterviewId.value, {
          completionType: 'normal'
        })
        ElMessage.success('æ¨¡æ‹Ÿé¢è¯•å·²å®Œæˆ')
      } catch (error) {
        ElMessage.warning('é¢è¯•æ•°æ®ä¿å­˜å¯èƒ½å¤±è´¥ï¼Œä½†æœ¬åœ°å·²æ¸…ç†')
      }
    } else if (isEmergency) {
      ElMessage.warning('é¢è¯•å·²ä¸­æ–­')
    }

    nextTick(() => {
      showEndDialog.value = true

      generatingReport.value = true
      setTimeout(() => {
        generatingReport.value = false
      }, 3000)
    })

  } catch (error) {
    ElMessage.error('ç»“æŸé¢è¯•å¤±è´¥ï¼š' + (error.message || 'æœªçŸ¥é”™è¯¯'))

    nextTick(() => {
      showEndDialog.value = true
    })
  }
}

const cleanupResources = () => {
  try {
    if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
      try {
        mediaRecorder.value.stop()
      } catch (error) {
        console.warn('åœæ­¢å½•éŸ³å™¨å¤±è´¥:', error)
      }
    }
    mediaRecorder.value = null

    if (mediaStream.value && typeof mediaStream.value.getTracks === 'function') {
      try {
        mediaStream.value.getTracks().forEach(track => {
          try {
            track.stop()
          } catch (error) {
            console.warn('åœæ­¢åª’ä½“è½¨é“å¤±è´¥:', error)
          }
        })
      } catch (error) {
        console.warn('æ¸…ç†åª’ä½“æµå¤±è´¥:', error)
      }
    }
    mediaStream.value = null

  } catch (error) {
    console.error('æ¸…ç†åª’ä½“èµ„æºå¤±è´¥:', error)
  }

  try {
    if (renderer) {
      renderer.dispose()
      renderer = null
    }
    if (scene) {
      scene = null
    }
    if (camera) {
      camera = null
    }
    if (avatarMesh) {
      avatarMesh = null
    }

  } catch (error) {
    console.error('æ¸…ç†3Dèµ„æºå¤±è´¥:', error)
  }

  try {
    isRecording.value = false
    isAnswering.value = false
    isSpeaking.value = false
    isListening.value = false
    cameraReady.value = false

    currentInterviewId.value = null
    currentQuestionData.value = null
    recordedAudioBlob.value = null
    recordedTranscript.value = ''
    answerTime.value = 0
    audioLevel.value = 0

    emotionAnalysis.value = { type: 'neutral', text: 'è‡ªç„¶' }
    eyeContactStatus.value = { type: 'good', text: 'è‰¯å¥½' }

  } catch (error) {
    console.error('é‡ç½®çŠ¶æ€å¤±è´¥:', error)
  }
}

// ================================================================================================
// ğŸ“Š ç¬¬åéƒ¨åˆ†ï¼šç»“æœå¤„ç†å’Œå¯¼èˆª
// ================================================================================================

const viewReport = () => {
  router.push('/dashboard/interview-performance')
}

const backToSettings = () => {
  hasStarted.value = false
  showEndDialog.value = false
  elapsedTime.value = 0
  currentQuestionIndex.value = 0
  currentPhaseIndex.value = 0
  answeredQuestions.value = 0
}

const backToList = () => {
  router.push('/dashboard')
}

// ================================================================================================
// ğŸ’« ç¬¬åä¸€éƒ¨åˆ†ï¼šè®¡ç®—å±æ€§å’Œè¾…åŠ©å‡½æ•°
// ================================================================================================

const canStart = computed(() => {
  try {
    const settingsValue = settings.value
    if (!settingsValue) return false

    return !!(
      settingsValue.company &&
      settingsValue.position &&
      settingsValue.interviewerId &&
      Array.isArray(settingsValue.evaluationFocus) &&
      settingsValue.evaluationFocus.length > 0
    )
  } catch (error) {
    return false
  }
})

const getCompanyName = (type) => {
  const names = {
    tech: 'ç§‘æŠ€æœ‰é™å…¬å¸',
    foreign: 'å¤–èµ„ä¼ä¸š',
    state: 'å›½æœ‰ä¼ä¸š',
    startup: 'åˆ›ä¸šå…¬å¸'
  }
  return names[type] || 'å…¬å¸'
}

const getRoundName = (round) => {
  const names = {
    first: 'åˆè¯•',
    second: 'å¤è¯•',
    final: 'ç»ˆé¢'
  }
  return names[round] || 'é¢è¯•'
}

const getPhaseType = (phase) => {
  const types = {
    intro: 'info',
    self: 'primary',
    technical: 'warning',
    project: 'success',
    behavioral: 'danger',
    questions: 'info'
  }
  return types[phase] || 'info'
}

const getPhaseTitle = (phase) => {
  const titles = {
    intro: 'å¼€åœºé˜¶æ®µ',
    self: 'è‡ªæˆ‘ä»‹ç»',
    technical: 'æŠ€æœ¯é—®ç­”',
    project: 'é¡¹ç›®ç»å†',
    behavioral: 'è¡Œä¸ºé¢è¯•',
    questions: 'æé—®ç¯èŠ‚'
  }
  return titles[phase] || 'é¢è¯•ä¸­'
}

const getTimeColor = (percentage) => {
  if (percentage >= 90) return '#f56c6c'
  if (percentage >= 70) return '#e6a23c'
  return '#409eff'
}

const getAnswerProgressColor = (percentage) => {
  if (percentage >= 80) return '#67c23a'
  if (percentage >= 50) return '#409eff'
  return '#e6a23c'
}

const formatTime = (seconds) => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// ================================================================================================
// ğŸ”„ ç¬¬åäºŒéƒ¨åˆ†ï¼šç”Ÿå‘½å‘¨æœŸç®¡ç†
// ================================================================================================

onUnmounted(() => {
  isEmergencyExiting.value = true

  timeoutManager.clearAll()

  try {
    if (mediaRecorder.value) {
      if (mediaRecorder.value.state === 'recording') {
        mediaRecorder.value.stop()
      }
      mediaRecorder.value = null
    }

    if (mediaStream.value && typeof mediaStream.value.getTracks === 'function') {
      mediaStream.value.getTracks().forEach(track => {
        try { track.stop() } catch (e) { /* å¿½ç•¥ */ }
      })
      mediaStream.value = null
    }
  } catch (error) {
    console.error('æ¸…ç†åª’ä½“èµ„æºå¤±è´¥:', error)
  }

  try {
    emotionAnalysis.value = { type: 'neutral', text: 'è‡ªç„¶' }
    eyeContactStatus.value = { type: 'good', text: 'è‰¯å¥½' }
  } catch (error) {
    console.error('æœ€ç»ˆçŠ¶æ€é‡ç½®å¤±è´¥:', error)
  }
})

</script>

<style scoped>
.interview-simulation-container {
  height: calc(100vh - 100px);
  display: flex;
  flex-direction: column;
}

/* å¼€å§‹é¡µé¢æ ·å¼ */
.start-section {
  max-width: 900px;
  margin: 0 auto;
  width: 100%;
}

.settings-panel {
  padding: 30px;
  margin-bottom: 30px;
}

.settings-panel h3 {
  font-size: 1.3rem;
  margin-bottom: 25px;
  color: var(--text-primary);
}

.interviewer-config {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 15px;
}

.interviewer-option {
  display: flex;
  gap: 15px;
  padding: 15px;
  background: rgba(255, 255, 255, 0.05);
  border: 2px solid transparent;
  border-radius: 12px;
  cursor: pointer;
  transition: all 0.3s ease;
}

.interviewer-option:hover {
  background: rgba(255, 255, 255, 0.08);
}

.interviewer-option.selected {
  border-color: var(--primary-color);
  background: rgba(64, 158, 255, 0.1);
}

.interviewer-details h5 {
  color: var(--text-primary);
  margin: 0 0 5px 0;
}

.interviewer-details p {
  color: var(--text-secondary);
  margin: 0 0 10px 0;
  font-size: 13px;
}

.interviewer-tags {
  display: flex;
  gap: 5px;
  flex-wrap: wrap;
}

.simulation-warning {
  margin: 25px 0;
}

.simulation-warning ul {
  margin: 0;
  padding-left: 20px;
  line-height: 1.8;
}

.settings-actions {
  text-align: center;
  margin-top: 30px;
}

.start-btn {
  padding: 15px 50px;
  font-size: 1.1rem;
  background: var(--gradient-tech);
  color: white;
  border: none;
  border-radius: 30px;
  cursor: pointer;
  display: inline-flex;
  align-items: center;
  gap: 10px;
  transition: all 0.3s ease;
}

.start-btn:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 8px 25px rgba(64, 158, 255, 0.3);
}

.start-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* é¢è¯•ä¸»ç•Œé¢ */
.interview-main {
  flex: 1;
  display: flex;
  flex-direction: column;
  gap: 15px;
}

/* çŠ¶æ€æ  */
.status-bar {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 15px 25px;
}

.interview-info {
  display: flex;
  align-items: center;
  gap: 15px;
}

.company-info,
.round-info {
  color: var(--text-secondary);
  font-size: 14px;
}

.time-display {
  display: flex;
  align-items: center;
  gap: 10px;
  color: var(--text-primary);
}

.time-text {
  font-family: monospace;
  font-size: 1.1rem;
  font-weight: bold;
}

/* é¢è¯•åŒºåŸŸ */
.interview-area {
  flex: 1;
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 20px;
}

/* é¢è¯•å®˜åŒºåŸŸ */
.interviewer-section {
  display: flex;
  flex-direction: column;
  gap: 15px;
}

.virtual-interviewer {
  flex: 1;
  position: relative;
  min-height: 300px;
}

.virtual-human-canvas {
  width: 100%;
  height: calc(100% - 60px);
}

.interviewer-info-bar {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  height: 60px;
  background: rgba(0, 0, 0, 0.7);
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 0 20px;
}

.interviewer-status {
  display: flex;
  align-items: center;
  gap: 10px;
  color: var(--text-primary);
}

.status-indicator {
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background: #666;
  transition: all 0.3s ease;
}

.status-indicator.speaking {
  background: #67c23a;
  animation: pulse 1s ease-in-out infinite;
}

.status-indicator.listening {
  background: #409eff;
}

.question-display {
  padding: 20px;
  min-height: 120px;
}

.question-header {
  display: flex;
  align-items: center;
  gap: 8px;
  margin-bottom: 15px;
  color: var(--text-secondary);
  font-size: 14px;
}

.question-text {
  font-size: 1.1rem;
  color: var(--text-primary);
  line-height: 1.6;
  margin-bottom: 10px;
}

.question-context {
  margin-top: 10px;
}

/* å€™é€‰äººåŒºåŸŸ */
.candidate-section {
  display: flex;
  flex-direction: column;
  gap: 15px;
}

.user-video-container {
  flex: 1;
  position: relative;
  min-height: 250px;
}

.user-video-container video {
  width: 100%;
  height: 100%;
  object-fit: cover;
  border-radius: 12px;
}

.video-setup {
  height: 100%;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--text-secondary);
}

.video-setup p {
  margin: 15px 0;
}

.recording-indicator {
  position: absolute;
  top: 15px;
  right: 15px;
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  background: rgba(245, 108, 108, 0.9);
  color: white;
  border-radius: 20px;
  font-size: 14px;
  font-weight: bold;
}

.rec-dot {
  width: 8px;
  height: 8px;
  background: white;
  border-radius: 50%;
  animation: pulse 1s ease-in-out infinite;
}

.answer-control {
  padding: 20px;
  text-align: center;
}

.waiting-state h4 {
  color: var(--text-primary);
  margin-bottom: 10px;
}

.waiting-state p {
  color: var(--text-secondary);
  margin-bottom: 20px;
}

.answering-state {
  display: flex;
  align-items: center;
  gap: 30px;
}

.answer-timer {
  flex-shrink: 0;
}

.timer-text {
  font-size: 14px;
  font-weight: bold;
  color: var(--text-primary);
}

.answer-controls {
  flex: 1;
}

.answer-hint {
  margin-top: 10px;
  color: var(--text-secondary);
  font-size: 13px;
}

.realtime-feedback {
  padding: 15px;
}

.realtime-feedback h4 {
  color: var(--text-primary);
  margin-bottom: 15px;
  font-size: 1rem;
}

.feedback-items {
  display: flex;
  flex-direction: column;
  gap: 10px;
}

.feedback-item {
  display: flex;
  align-items: center;
  gap: 10px;
  font-size: 13px;
}

.feedback-item .label {
  width: 70px;
  color: var(--text-secondary);
}

.status-text {
  font-weight: 600;
}

.status-text.confident,
.status-text.professional,
.status-text.excellent,
.status-text.good {
  color: #67c23a;
}

.status-text.thoughtful,
.status-text.neutral,
.status-text.average {
  color: #409eff;
}

.status-text.nervous,
.status-text.needs_improvement,
.status-text.poor {
  color: #f56c6c;
}

/* è¿›åº¦è¿½è¸ª */
.progress-tracker {
  padding: 20px;
}

.progress-steps {
  display: flex;
  justify-content: space-between;
  align-items: center;
  max-width: 800px;
  margin: 0 auto;
}

.progress-step {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 8px;
  opacity: 0.5;
  transition: all 0.3s ease;
}

.progress-step.active {
  opacity: 1;
  color: var(--primary-color);
}

.progress-step.completed {
  opacity: 1;
  color: var(--success-color);
}

.step-circle {
  width: 30px;
  height: 30px;
  border-radius: 50%;
  background: rgba(255, 255, 255, 0.1);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 14px;
  font-weight: bold;
}

.progress-step.active .step-circle {
  background: var(--primary-color);
  color: white;
}

.progress-step.completed .step-circle {
  background: var(--success-color);
  color: white;
}

.step-label {
  font-size: 12px;
  text-align: center;
}

/* ç»“æŸå¯¹è¯æ¡† */
.end-dialog-content {
  text-align: center;
}

.interview-summary {
  margin: 20px 0;
}

.interview-summary p {
  margin: 8px 0;
  color: var(--text-secondary);
}

.end-actions {
  display: flex;
  gap: 15px;
  justify-content: center;
  flex-wrap: wrap;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 1200px) {
  .interview-area {
    grid-template-columns: 1fr;
    gap: 15px;
  }

  .answering-state {
    flex-direction: column;
    gap: 20px;
  }
}

@media (max-width: 768px) {
  .status-bar {
    flex-wrap: wrap;
    gap: 15px;
  }

  .time-display {
    order: 3;
    width: 100%;
    justify-content: center;
  }

  .progress-steps {
    flex-wrap: wrap;
    gap: 20px;
  }

  .interviewer-config {
    grid-template-columns: 1fr;
  }
}

@keyframes pulse {
  0%, 100% {
    opacity: 1;
    transform: scale(1);
  }
  50% {
    opacity: 0.5;
    transform: scale(1.1);
  }
}
</style>
