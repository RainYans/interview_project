# app/services/interview_service.py - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä¸ºAIæ¥å£é¢„ç•™ä½ç½®
from sqlalchemy.orm import Session
from sqlalchemy import desc, and_, func
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
import os
import uuid
import random
from fastapi import UploadFile

from app.models.interview import (
    Interview, InterviewQuestion, InterviewAnswer, 
    InterviewStatistics, InterviewTrendData
)
from app.models.question import Question
from app.schemas.interview import (
    InterviewStartRequest, AbilityScores, 
    PerformanceResponse, TrendDataResponse, InterviewHistoryItem
)

# ================================================================================================
# ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šé¢è¯•å¼€å§‹å’Œç®¡ç†
# ================================================================================================

def start_interview(db: Session, user_id: int, request: InterviewStartRequest) -> Tuple[Interview, List[Dict]]:
    """å¼€å§‹æ–°é¢è¯• - ç»ƒä¹ æ¨¡å¼"""
    interview = Interview(
        user_id=user_id,
        type=request.type,
        status='in_progress',
        position=request.position,
        company=request.company,
        difficulty=request.difficulty,
        interview_style=request.interview_style,
        interviewer_id=request.interviewer_id,
        round_type=request.round_type,
        scheduled_duration=request.duration,
        started_at=datetime.utcnow(),
        settings=json.dumps({
            "question_types": request.question_types,
            "special_settings": request.special_settings,
            "evaluation_focus": request.evaluation_focus
        }),
        is_paused=False,
        pause_count=0,
        current_phase='intro',
        is_recording=False,
        last_activity=datetime.utcnow()
    )
    
    db.add(interview)
    db.commit()
    db.refresh(interview)
    
    # ç”Ÿæˆé¢è¯•é¢˜ç›®
    questions = generate_interview_questions(db, interview, request)
    
    return interview, questions

def start_simulation_interview(db: Session, user_id: int, request: InterviewStartRequest) -> Tuple[Interview, List[Dict]]:
    """å¼€å§‹æ¨¡æ‹Ÿé¢è¯• - æ¨¡æ‹Ÿæ¨¡å¼"""
    interview = Interview(
        user_id=user_id,
        type='simulation',
        status='in_progress',
        position=request.position,
        company=request.company,
        difficulty=request.difficulty,
        interview_style=request.interview_style,
        interviewer_id=request.interviewer_id,
        round_type=request.round_type,
        scheduled_duration=request.duration,
        started_at=datetime.utcnow(),
        settings=json.dumps({
            "company": request.company,
            "round_type": request.round_type,
            "evaluation_focus": request.evaluation_focus,
            "is_simulation": True,
            "allow_pause": False,
            "allow_hints": False,
            "strict_timing": True
        }),
        is_paused=False,
        pause_count=0,
        current_phase='intro',
        is_recording=False,
        last_activity=datetime.utcnow()
    )
    
    db.add(interview)
    db.commit()
    db.refresh(interview)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•é¢˜ç›®
    questions = generate_simulation_questions(db, interview, request)
    
    return interview, questions

# ================================================================================================
# ğŸ¤– ç¬¬äºŒéƒ¨åˆ†ï¼šAIé¢˜ç›®ç”Ÿæˆæ¥å£åŒºåŸŸ
# ================================================================================================

def generate_interview_questions(db: Session, interview: Interview, request: InterviewStartRequest) -> List[Dict]:
    """
    ç”Ÿæˆç»ƒä¹ é¢è¯•é¢˜ç›®
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - ç»ƒä¹ æ¨¡å¼é¢˜ç›®ç”Ÿæˆ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œæ ¹æ®ä»¥ä¸‹å‚æ•°ç”Ÿæˆä¸ªæ€§åŒ–é¢˜ç›®ï¼š
    - interview.position: é¢è¯•å²—ä½
    - interview.difficulty: éš¾åº¦ç­‰çº§  
    - request.question_types: é¢˜ç›®ç±»å‹åå¥½
    - request.special_settings: ç‰¹æ®Šè®¾ç½®
    - interview.scheduled_duration: é¢è¯•æ—¶é•¿
    
    å½“å‰ä½¿ç”¨ç¡¬ç¼–ç é¢˜ç›®åº“ï¼Œéœ€è¦æ›¿æ¢ä¸ºAIç”Ÿæˆçš„é¢˜ç›®
    """
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     ai_questions = ai_service.generate_practice_questions(
    #         position=interview.position,
    #         difficulty=interview.difficulty,
    #         question_types=request.question_types,
    #         duration=interview.scheduled_duration,
    #         user_profile=get_user_profile(interview.user_id)
    #     )
    # except Exception as e:
    #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨é¢˜ç›®åº“
    #     ai_questions = get_fallback_questions()
    
    # å½“å‰ä½¿ç”¨çš„ç¡¬ç¼–ç é¢˜ç›®åº“ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
    preset_questions = [
        {
            'text': 'è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»ï¼ŒåŒ…æ‹¬æ‚¨çš„æ•™è‚²èƒŒæ™¯ã€å·¥ä½œç»éªŒå’ŒæŠ€èƒ½ç‰¹é•¿ã€‚',
            'type': 'behavioral',
            'difficulty': 'easy',
            'category': 'è¡Œä¸ºé¢è¯•',
            'time_limit': 180,
            'hints': 'å»ºè®®æŒ‰ç…§ä¸ªäººä¿¡æ¯-æ•™è‚²èƒŒæ™¯-å·¥ä½œç»éªŒ-æŠ€èƒ½ç‰¹é•¿çš„ç»“æ„æ¥ç»„ç»‡å›ç­”'
        },
        {
            'text': 'ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸ï¼Ÿæ‚¨å¯¹è¿™ä¸ªèŒä½æœ‰ä»€ä¹ˆäº†è§£ï¼Ÿ',
            'type': 'behavioral',
            'difficulty': 'easy',
            'category': 'æ±‚èŒåŠ¨æœº',
            'time_limit': 180,
            'hints': 'å¯ä»¥ä»å…¬å¸æ–‡åŒ–ã€å‘å±•å‰æ™¯ã€ä¸ªäººæˆé•¿ç­‰è§’åº¦å›ç­”'
        },
        {
            'text': 'è¯·ä»‹ç»ä¸€ä¸ªæ‚¨æœ€è¿‘å‚ä¸çš„é¡¹ç›®ï¼ŒåŒ…æ‹¬æ‚¨çš„è§’è‰²ã€æŠ€æœ¯æ ˆå’Œä¸»è¦è´¡çŒ®ã€‚',
            'type': 'project',
            'difficulty': 'medium',
            'category': 'é¡¹ç›®ç»éªŒ',
            'time_limit': 300,
            'hints': 'ä½¿ç”¨STARæ³•åˆ™ï¼šæƒ…å†µ-ä»»åŠ¡-è¡ŒåŠ¨-ç»“æœæ¥ç»„ç»‡å›ç­”'
        },
        {
            'text': 'æè¿°ä¸€æ¬¡æ‚¨é‡åˆ°æŠ€æœ¯éš¾é¢˜å¹¶æˆåŠŸè§£å†³çš„ç»å†ã€‚',
            'type': 'technical',
            'difficulty': 'medium',
            'category': 'é—®é¢˜è§£å†³',
            'time_limit': 300,
            'hints': 'é‡ç‚¹è¯´æ˜é—®é¢˜åˆ†æè¿‡ç¨‹ã€è§£å†³æ€è·¯å’Œæœ€ç»ˆæ•ˆæœ'
        },
        {
            'text': 'åœ¨å›¢é˜Ÿåä½œä¸­ï¼Œå¦‚ä½•å¤„ç†ä¸åŒäº‹çš„æ„è§åˆ†æ­§ï¼Ÿ',
            'type': 'situational',
            'difficulty': 'medium',
            'category': 'å›¢é˜Ÿåä½œ',
            'time_limit': 240,
            'hints': 'å¯ä»¥ç»“åˆå…·ä½“ä¾‹å­ï¼Œå±•ç°æ²Ÿé€šæŠ€å·§å’Œè§£å†³é—®é¢˜çš„èƒ½åŠ›'
        }
    ]
    
    # æ ¹æ®é¢è¯•æ—¶é•¿ç¡®å®šé¢˜ç›®æ•°é‡
    duration = interview.scheduled_duration or 30
    if interview.type == 'practice':
        total_questions = min(duration // 5, 6)
    else:
        total_questions = min(duration // 6, 8)
    
    total_questions = max(3, min(total_questions, len(preset_questions)))
    
    # é€‰æ‹©é¢˜ç›®
    question_types = request.question_types or ['behavioral', 'technical', 'project', 'situational']
    selected_questions = []
    
    for q_type in question_types:
        type_questions = [q for q in preset_questions if q['type'] == q_type]
        if type_questions and len(selected_questions) < total_questions:
            selected_questions.extend(type_questions[:2])
    
    if len(selected_questions) < total_questions:
        remaining_questions = [q for q in preset_questions if q not in selected_questions]
        selected_questions.extend(remaining_questions[:total_questions - len(selected_questions)])
    
    selected_questions = selected_questions[:total_questions]
    
    # åˆ›å»ºé¢˜ç›®è®°å½•
    questions_data = []
    for i, question_data in enumerate(selected_questions, 1):
        interview_question = InterviewQuestion(
            interview_id=interview.id,
            question_id=None,
            question_text=question_data['text'],
            question_type=question_data['type'],
            difficulty=question_data['difficulty'],
            category=question_data['category'],
            sequence_number=i,
            status='pending',
            time_limit=question_data['time_limit'],
            allow_hints='realtime_hints' in (request.special_settings or []),
            hint_text=question_data.get('hints', ''),
            is_skipped=False
        )
        
        db.add(interview_question)
        db.commit()
        db.refresh(interview_question)
        
        question_response = {
            'id': interview_question.id,
            'text': question_data['text'],
            'type': question_data['type'],
            'difficulty': question_data['difficulty'],
            'category': question_data['category'],
            'time_limit': question_data['time_limit'],
            'allow_hints': interview_question.allow_hints,
            'sequence_number': i
        }
        
        if interview_question.allow_hints:
            question_response['hint'] = question_data.get('hints', '')
        
        questions_data.append(question_response)
    
    interview.total_questions = len(questions_data)
    db.commit()
    
    return questions_data

def generate_simulation_questions(db: Session, interview: Interview, request: InterviewStartRequest) -> List[Dict]:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•é¢˜ç›®
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•é¢˜ç›®ç”Ÿæˆ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œæ ¹æ®ä»¥ä¸‹å‚æ•°ç”Ÿæˆæ›´æœ‰æŒ‘æˆ˜æ€§çš„é¢è¯•é¢˜ç›®ï¼š
    - interview.company: å…¬å¸ç±»å‹
    - interview.position: é¢è¯•å²—ä½
    - interview.round_type: é¢è¯•è½®æ¬¡
    - interview.difficulty: éš¾åº¦ç­‰çº§
    - request.evaluation_focus: è¯„ä¼°é‡ç‚¹
    - interview.scheduled_duration: é¢è¯•æ—¶é•¿
    
    æ¨¡æ‹Ÿé¢è¯•é¢˜ç›®åº”è¯¥æ¯”ç»ƒä¹ æ¨¡å¼æ›´å…·æŒ‘æˆ˜æ€§å’ŒçœŸå®æ€§
    """
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     ai_questions = ai_service.generate_simulation_questions(
    #         company_type=interview.company,
    #         position=interview.position,
    #         round_type=interview.round_type,
    #         difficulty=interview.difficulty,
    #         evaluation_focus=request.evaluation_focus,
    #         duration=interview.scheduled_duration,
    #         interview_style=interview.interview_style
    #     )
    # except Exception as e:
    #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨é¢˜ç›®åº“
    #     ai_questions = get_fallback_simulation_questions()
    
    # å½“å‰ä½¿ç”¨çš„ç¡¬ç¼–ç é¢˜ç›®åº“ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
    simulation_questions = [
        {
            'text': f'æ‚¨å¥½ï¼Œæ¬¢è¿å‚åŠ {get_company_full_name(request.company)}çš„{get_round_name(request.round_type)}ã€‚è¯·å…ˆåšä¸€ä¸ªè¯¦ç»†çš„è‡ªæˆ‘ä»‹ç»ã€‚',
            'type': 'behavioral',
            'difficulty': 'easy',
            'category': 'å¼€åœºä»‹ç»',
            'time_limit': 240,
            'phase': 'intro'
        },
        {
            'text': f'ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬{get_company_full_name(request.company)}ï¼Ÿæ‚¨å¯¹è¿™ä¸ª{request.position}èŒä½æœ‰ä»€ä¹ˆäº†è§£ï¼Ÿ',
            'type': 'behavioral',
            'difficulty': 'medium',
            'category': 'æ±‚èŒåŠ¨æœº',
            'time_limit': 180,
            'phase': 'self'
        },
        {
            'text': 'è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸ªæ‚¨æœ€æœ‰æˆå°±æ„Ÿçš„æŠ€æœ¯é¡¹ç›®ï¼ŒåŒ…æ‹¬æŠ€æœ¯æ¶æ„ã€é‡åˆ°çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆã€‚',
            'type': 'technical',
            'difficulty': 'medium',
            'category': 'æŠ€æœ¯é¡¹ç›®',
            'time_limit': 360,
            'phase': 'technical'
        },
        {
            'text': 'æè¿°ä¸€æ¬¡æ‚¨åœ¨å·¥ä½œä¸­é‡åˆ°é‡å¤§æŠ€æœ¯éš¾é¢˜çš„ç»å†ï¼Œæ‚¨æ˜¯å¦‚ä½•åˆ†æå’Œè§£å†³çš„ï¼Ÿ',
            'type': 'technical',
            'difficulty': 'hard',
            'category': 'é—®é¢˜è§£å†³',
            'time_limit': 300,
            'phase': 'technical'
        },
        {
            'text': 'åœ¨å›¢é˜Ÿé¡¹ç›®ä¸­ï¼Œå¦‚æœæ‚¨ä¸åŒäº‹åœ¨æŠ€æœ¯æ–¹æ¡ˆä¸Šäº§ç”Ÿåˆ†æ­§ï¼Œæ‚¨ä¼šå¦‚ä½•å¤„ç†ï¼Ÿ',
            'type': 'situational',
            'difficulty': 'medium',
            'category': 'å›¢é˜Ÿåä½œ',
            'time_limit': 240,
            'phase': 'behavioral'
        }
    ]
    
    # æ ¹æ®é¢è¯•æ—¶é•¿ç¡®å®šé¢˜ç›®æ•°é‡
    duration = interview.scheduled_duration or 45
    if duration <= 30:
        total_questions = 5
    elif duration <= 45:
        total_questions = 6
    elif duration <= 60:
        total_questions = 7
    else:
        total_questions = 8
    
    selected_questions = simulation_questions[:total_questions]
    
    # æ ¹æ®å…¬å¸ç±»å‹è°ƒæ•´é¢˜ç›®
    if request.company == 'tech':
        for q in selected_questions:
            if q['type'] == 'technical':
                q['difficulty'] = 'hard'
                q['time_limit'] += 60
    elif request.company == 'foreign':
        for q in selected_questions:
            if q['type'] == 'behavioral':
                q['time_limit'] += 30
                q['text'] += 'ï¼ˆè¯·æ³¨æ„è¡¨è¾¾çš„é€»è¾‘æ€§å’Œæ¡ç†æ€§ï¼‰'
    
    # åˆ›å»ºé¢˜ç›®è®°å½•
    questions_data = []
    for i, question_data in enumerate(selected_questions, 1):
        interview_question = InterviewQuestion(
            interview_id=interview.id,
            question_id=None,
            question_text=question_data['text'],
            question_type=question_data['type'],
            difficulty=question_data['difficulty'],
            category=question_data['category'],
            sequence_number=i,
            status='pending',
            time_limit=question_data['time_limit'],
            allow_hints=False,
            is_followup=False,
            hint_text=None,
            is_skipped=False
        )
        
        db.add(interview_question)
        db.commit()
        db.refresh(interview_question)
        
        question_response = {
            'id': interview_question.id,
            'text': question_data['text'],
            'type': question_data['type'],
            'difficulty': question_data['difficulty'],
            'category': question_data['category'],
            'time_limit': question_data['time_limit'],
            'allow_hints': False,
            'sequence_number': i,
            'phase': question_data.get('phase', 'general')
        }
        
        questions_data.append(question_response)
    
    interview.total_questions = len(questions_data)
    db.commit()
    
    return questions_data

# ================================================================================================
# ğŸ® ç¬¬ä¸‰éƒ¨åˆ†ï¼šé¢è¯•æ§åˆ¶åŠŸèƒ½
# ================================================================================================

def pause_interview(db: Session, interview_id: int, user_id: int) -> Dict:
    """æš‚åœé¢è¯•ï¼ˆä»…ç»ƒä¹ æ¨¡å¼ï¼‰"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if interview.type != 'practice':
        raise ValueError("åªæœ‰ç»ƒä¹ æ¨¡å¼å¯ä»¥æš‚åœ")
    
    if interview.status != 'in_progress':
        raise ValueError("é¢è¯•æœªåœ¨è¿›è¡Œä¸­")
    
    interview.is_paused = True
    interview.pause_count = (interview.pause_count or 0) + 1
    interview.last_activity = datetime.utcnow()
    
    db.commit()
    
    return {
        "interview_id": interview_id,
        "is_paused": True,
        "pause_count": interview.pause_count,
        "message": "é¢è¯•å·²æš‚åœï¼Œå¯ä»¥éšæ—¶ç»§ç»­"
    }

def resume_interview(db: Session, interview_id: int, user_id: int) -> Dict:
    """ç»§ç»­é¢è¯•"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if not interview.is_paused:
        raise ValueError("é¢è¯•æœªæš‚åœ")
    
    interview.is_paused = False
    interview.last_activity = datetime.utcnow()
    
    db.commit()
    
    return {
        "interview_id": interview_id,
        "is_paused": False,
        "message": "é¢è¯•å·²ç»§ç»­"
    }

def skip_question(db: Session, interview_id: int, question_id: int, user_id: int) -> Dict:
    """è·³è¿‡é—®é¢˜"""
    try:
        interview = db.query(Interview).filter(
            Interview.id == interview_id,
            Interview.user_id == user_id
        ).first()
        
        if not interview:
            raise ValueError("é¢è¯•ä¸å­˜åœ¨")
        
        if interview.type == 'simulation':
            raise ValueError("æ¨¡æ‹Ÿé¢è¯•ä¸å…è®¸è·³è¿‡é—®é¢˜")
        
        question = db.query(InterviewQuestion).filter(
            InterviewQuestion.id == question_id,
            InterviewQuestion.interview_id == interview_id
        ).first()
        
        if not question:
            raise ValueError("é¢˜ç›®ä¸å­˜åœ¨")
        
        # æ ‡è®°é¢˜ç›®ä¸ºè·³è¿‡çŠ¶æ€
        question.status = 'skipped'
        question.answered_at = datetime.utcnow()
        question.is_skipped = True
        question.skip_reason = 'ç”¨æˆ·ä¸»åŠ¨è·³è¿‡'
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç­”æ¡ˆè®°å½•
        existing_answer = db.query(InterviewAnswer).filter(
            InterviewAnswer.question_id == question_id
        ).first()
        
        if existing_answer:
            existing_answer.answer_text = "[å·²è·³è¿‡]"
            existing_answer.is_complete = False
            existing_answer.skip_reason = "ç”¨æˆ·ä¸»åŠ¨è·³è¿‡"
            existing_answer.submitted_at = datetime.utcnow()
        else:
            skip_answer = InterviewAnswer(
                interview_id=interview_id,
                question_id=question_id,
                answer_text="[å·²è·³è¿‡]",
                is_complete=False,
                skip_reason="ç”¨æˆ·ä¸»åŠ¨è·³è¿‡",
                submitted_at=datetime.utcnow()
            )
            db.add(skip_answer)
        
        db.commit()
        
        # è·å–ä¸‹ä¸€é¢˜
        next_question = get_next_question_for_skip(db, interview_id, question.sequence_number)
        
        return {
            "skipped_question_id": question_id,
            "next_question": next_question,
            "message": "é—®é¢˜å·²è·³è¿‡"
        }
        
    except Exception as e:
        db.rollback()
        raise e

def get_interview_status(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–é¢è¯•å®æ—¶çŠ¶æ€"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    current_question = db.query(InterviewQuestion).filter(
        InterviewQuestion.interview_id == interview_id,
        InterviewQuestion.status.in_(['current', 'pending'])
    ).order_by(InterviewQuestion.sequence_number).first()
    
    elapsed_time = 0
    if interview.started_at:
        elapsed_time = int((datetime.utcnow() - interview.started_at).total_seconds())
    
    current_phase = determine_current_phase(db, interview_id)
    
    return {
        "interview_id": interview_id,
        "status": interview.status,
        "is_paused": interview.is_paused or False,
        "is_recording": interview.is_recording or False,
        "current_phase": current_phase,
        "current_question_index": current_question.sequence_number - 1 if current_question else 0,
        "total_questions": interview.total_questions,
        "elapsed_time": elapsed_time,
        "answered_questions": interview.answered_questions,
        "pause_count": interview.pause_count or 0,
        "last_activity": interview.last_activity.isoformat() if interview.last_activity else None
    }

def emergency_exit_interview(db: Session, interview_id: int, exit_reason: str, user_id: int) -> Dict:
    """ç´§æ€¥é€€å‡ºé¢è¯•"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if interview.status == 'completed':
        raise ValueError("é¢è¯•å·²å®Œæˆï¼Œæ— æ³•é€€å‡º")
    
    interview.status = 'interrupted'
    interview.completed_at = datetime.utcnow()
    interview.is_emergency_exit = True
    interview.exit_reason = exit_reason or 'ç”¨æˆ·ç´§æ€¥é€€å‡º'
    
    if interview.started_at:
        duration = (interview.completed_at - interview.started_at).seconds // 60
        interview.actual_duration = duration
    
    interview.key_feedback = f"ç´§æ€¥é€€å‡º: {exit_reason or 'ç”¨æˆ·ä¸»åŠ¨é€€å‡º'}"
    
    if interview.answered_questions > 0:
        try:
            scores = calculate_interview_scores_safe(db, interview_id)
            interview.overall_score = scores['overall']
            interview.professional_score = scores['professional']
            interview.skill_match_score = scores['skill_match']
            interview.language_expression_score = scores['language_expression']
            interview.logical_thinking_score = scores['logical_thinking']
            interview.comprehensive_quality_score = scores['comprehensive_quality']
        except:
            interview.overall_score = 0.0
    
    db.commit()
    
    try:
        update_user_statistics_safe(db, interview.user_id, interview)
    except:
        pass
    
    return {
        "interview_id": interview_id,
        "exit_reason": exit_reason,
        "duration": interview.actual_duration,
        "answered_questions": interview.answered_questions,
        "partial_score": interview.overall_score,
        "report_available": interview.answered_questions > 0,
        "message": "é¢è¯•å·²ç´§æ€¥é€€å‡ºï¼Œå·²ä¿å­˜éƒ¨åˆ†æ•°æ®"
    }

# ================================================================================================
# ğŸ¤– ç¬¬å››éƒ¨åˆ†ï¼šAIæç¤ºåŠŸèƒ½æ¥å£åŒºåŸŸ
# ================================================================================================

def get_question_hint(db: Session, question_id: int, user_id: int) -> Dict:
    """è·å–é¢˜ç›®æç¤º"""
    question = db.query(InterviewQuestion).filter(
        InterviewQuestion.id == question_id
    ).first()
    
    if not question:
        raise ValueError("é¢˜ç›®ä¸å­˜åœ¨")
    
    interview = db.query(Interview).filter(
        Interview.id == question.interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("æ— æƒé™è®¿é—®")
    
    if interview.type == 'simulation':
        raise ValueError("æ¨¡æ‹Ÿé¢è¯•ä¸æä¾›æç¤º")
    
    if not question.allow_hints:
        raise ValueError("è¯¥é¢˜ç›®ä¸å…è®¸æç¤º")
    
    # ç”Ÿæˆæç¤ºå†…å®¹
    hint_content = question.hint_text or generate_question_hint(question)
    
    return {
        "question_id": question_id,
        "hint": hint_content,
        "warning": "ä½¿ç”¨æç¤ºåè¯¥é¢˜ä¸è®¡å…¥ç»¼åˆè¯„åˆ†",
        "can_use": True
    }

def generate_question_hint(question: InterviewQuestion) -> str:
    """
    ç”Ÿæˆé¢˜ç›®æç¤ºå†…å®¹
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - AIæç¤ºç”Ÿæˆ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œæ ¹æ®ä»¥ä¸‹å‚æ•°ç”Ÿæˆæ™ºèƒ½æç¤ºï¼š
    - question.question_text: é¢˜ç›®å†…å®¹
    - question.question_type: é¢˜ç›®ç±»å‹
    - question.difficulty: é¢˜ç›®éš¾åº¦
    - question.category: é¢˜ç›®åˆ†ç±»
    
    åº”è¯¥è¿”å›é’ˆå¯¹æ€§çš„å›ç­”å»ºè®®å’Œæ¡†æ¶
    """
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     ai_hint = ai_service.generate_question_hint(
    #         question_text=question.question_text,
    #         question_type=question.question_type,
    #         difficulty=question.difficulty,
    #         category=question.category
    #     )
    #     return ai_hint
    # except Exception as e:
    #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨æç¤º
    #     return get_fallback_hint(question.question_type)
    
    # å½“å‰ä½¿ç”¨çš„ç¡¬ç¼–ç æç¤ºï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
    hints = {
        'behavioral': 'å»ºè®®ä½¿ç”¨STARæ³•åˆ™å›ç­”ï¼šSituation(æƒ…å¢ƒ)ã€Task(ä»»åŠ¡)ã€Action(è¡ŒåŠ¨)ã€Result(ç»“æœ)',
        'technical': 'å¯ä»¥ä»åŸç†ã€å®è·µã€ä¼˜ç¼ºç‚¹ã€åº”ç”¨åœºæ™¯ç­‰è§’åº¦æ¥å›ç­”',
        'situational': 'å…ˆåˆ†ææƒ…å†µï¼Œå†æå‡ºè§£å†³æ–¹æ¡ˆï¼Œæœ€åè¯´æ˜é¢„æœŸæ•ˆæœ',
        'project': 'æŒ‰ç…§é¡¹ç›®èƒŒæ™¯ã€æŠ€æœ¯é€‰å‹ã€ä¸ªäººè´¡çŒ®ã€é‡åˆ°æŒ‘æˆ˜ã€è§£å†³æ–¹æ¡ˆã€é¡¹ç›®æˆæœçš„é¡ºåºæ¥ä»‹ç»',
        'stress': 'ä¿æŒå†·é™ï¼Œç®€æ´æ˜äº†åœ°å›ç­”è¦ç‚¹å³å¯'
    }
    
    question_type = question.question_type or 'behavioral'
    return hints.get(question_type, 'å»ºè®®æ€è€ƒåå†å›ç­”ï¼Œæ³¨æ„é€»è¾‘æ¸…æ™°ã€è¡¨è¾¾æµç•…')

def mark_hint_used(db: Session, question_id: int, user_id: int) -> Dict:
    """æ ‡è®°ä½¿ç”¨äº†æç¤º"""
    question = db.query(InterviewQuestion).filter(
        InterviewQuestion.id == question_id
    ).first()
    
    if not question:
        raise ValueError("é¢˜ç›®ä¸å­˜åœ¨")
    
    interview = db.query(Interview).filter(
        Interview.id == question.interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("æ— æƒé™è®¿é—®")
    
    question.hint_used_count = (question.hint_used_count or 0) + 1
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if not answer:
        answer = InterviewAnswer(
            interview_id=question.interview_id,
            question_id=question_id,
            used_hint=True,
            hint_view_time=datetime.utcnow(),
            hint_content=question.hint_text
        )
        db.add(answer)
    else:
        answer.used_hint = True
        answer.hint_view_time = datetime.utcnow()
        answer.hint_content = question.hint_text
    
    interview.hints_used = (interview.hints_used or 0) + 1
    
    db.commit()
    
    return {
        "question_id": question_id,
        "hint_used": True,
        "total_hints_used": interview.hints_used,
        "message": "æç¤ºä½¿ç”¨å·²è®°å½•"
    }

# ================================================================================================
# ğŸ¤– ç¬¬äº”éƒ¨åˆ†ï¼šå®æ—¶åˆ†æåŠŸèƒ½æ¥å£åŒºåŸŸ
# ================================================================================================

def save_realtime_analysis(db: Session, interview_id: int, analysis_data: Dict, user_id: int) -> Dict:
    """
    ä¿å­˜å®æ—¶åˆ†ææ•°æ®
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - å®æ—¶åˆ†æå¤„ç†
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œå¤„ç†å®æ—¶éŸ³è§†é¢‘åˆ†æï¼š
    - analysis_data.audio_level: éŸ³é¢‘éŸ³é‡
    - analysis_data.emotion_type: æƒ…ç»ªç±»å‹
    - analysis_data.eye_contact_score: çœ¼ç¥æ¥è§¦è¯„åˆ†
    - analysis_data.speech_speed: è¯­é€Ÿ
    - analysis_data.facial_expression: é¢éƒ¨è¡¨æƒ…æ•°æ®
    
    å¯ä»¥è°ƒç”¨AIæœåŠ¡è¿›è¡Œå®æ—¶æƒ…ç»ªè¯†åˆ«ã€è¯­éŸ³åˆ†æç­‰
    """
    
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     # è°ƒç”¨AIåˆ†ææœåŠ¡
    #     ai_analysis = ai_service.analyze_realtime_data(
    #         audio_level=analysis_data.get('audio_level'),
    #         video_frame=analysis_data.get('video_frame'),
    #         emotion_data=analysis_data.get('emotion_data'),
    #         speech_data=analysis_data.get('speech_data')
    #     )
    #     
    #     # ä¿å­˜AIåˆ†æç»“æœ
    #     enhanced_analysis_data = {
    #         **analysis_data,
    #         'ai_emotion_score': ai_analysis.emotion_score,
    #         'ai_confidence_level': ai_analysis.confidence_level,
    #         'ai_speech_quality': ai_analysis.speech_quality
    #     }
    # except Exception as e:
    #     # AIåˆ†æå¤±è´¥æ—¶ä½¿ç”¨åŸå§‹æ•°æ®
    #     enhanced_analysis_data = analysis_data
    
    # ä¿å­˜åˆ°å½“å‰é¢˜ç›®çš„å®æ—¶æ•°æ®å­—æ®µ
    current_question = db.query(InterviewQuestion).filter(
        InterviewQuestion.interview_id == interview_id,
        InterviewQuestion.status == 'current'
    ).first()
    
    if current_question:
        if current_question.real_time_data:
            existing_data = json.loads(current_question.real_time_data)
            existing_data.append({
                "timestamp": datetime.utcnow().isoformat(),
                "data": analysis_data
            })
        else:
            existing_data = [{
                "timestamp": datetime.utcnow().isoformat(),
                "data": analysis_data
            }]
        
        current_question.real_time_data = json.dumps(existing_data)
        db.commit()
    
    return {
        "interview_id": interview_id,
        "analysis_saved": True,
        "timestamp": datetime.utcnow().isoformat()
    }

def get_realtime_status(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–å®æ—¶åˆ†æçŠ¶æ€"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    # æ¨¡æ‹Ÿå®æ—¶çŠ¶æ€æ•°æ®ï¼ˆAIå¯¹æ¥åæ›¿æ¢ä¸ºçœŸå®åˆ†æç»“æœï¼‰
    return {
        "audio_level": random.randint(0, 100),
        "emotion_analysis": {
            "type": random.choice(['confident', 'neutral', 'nervous']),
            "text": random.choice(['è‡ªä¿¡', 'è‡ªç„¶', 'ç´§å¼ '])
        },
        "eye_contact_status": {
            "type": random.choice(['good', 'average', 'poor']),
            "text": random.choice(['è‰¯å¥½', 'ä¸€èˆ¬', 'è¾ƒå°‘'])
        },
        "voice_analysis": {
            "speed": random.choice(['normal', 'fast', 'slow']),
            "speed_text": random.choice(['é€‚ä¸­', 'åå¿«', 'åæ…¢'])
        }
    }

def save_simulation_analysis(db: Session, interview_id: int, analysis_data: Dict, user_id: int) -> Dict:
    """
    ä¿å­˜æ¨¡æ‹Ÿé¢è¯•å®æ—¶åˆ†ææ•°æ®
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•å®æ—¶åˆ†æ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œæ›´ä¸¥æ ¼çš„å®æ—¶åˆ†æï¼š
    - æ¨¡æ‹Ÿé¢è¯•çš„åˆ†æåº”è¯¥æ›´åŠ ä¸¥æ ¼å’Œè¯¦ç»†
    - åŒ…æ‹¬ä¸“ä¸šè¡¨ç°ã€å‹åŠ›å¤„ç†ç­‰é«˜çº§åˆ†æ
    """
    
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     # æ¨¡æ‹Ÿé¢è¯•çš„AIåˆ†ææ›´ä¸¥æ ¼
    #     ai_analysis = ai_service.analyze_simulation_performance(
    #         analysis_data=analysis_data,
    #         interview_context={
    #             'company_type': interview.company,
    #             'position': interview.position,
    #             'round_type': interview.round_type,
    #             'current_phase': interview.current_phase
    #         }
    #     )
    # except Exception as e:
    #     ai_analysis = None
    
    # ä¿å­˜åˆ†ææ•°æ®ï¼ˆå¯é€‰ï¼šä¿å­˜åˆ°ä¸“é—¨çš„å®æ—¶åˆ†æè¡¨ï¼‰
    try:
        from app.models.interview import RealtimeAnalysisData
        
        realtime_data = RealtimeAnalysisData(
            interview_id=interview_id,
            question_id=interview.current_question_id,
            user_id=user_id,
            timestamp=datetime.utcnow(),
            audio_level=analysis_data.get('audio_level'),
            emotion_type=analysis_data.get('emotion_type'),
            eye_contact_score=analysis_data.get('eye_contact_score'),
            speech_speed=analysis_data.get('speech_speed')
        )
        
        db.add(realtime_data)
        db.commit()
        
    except Exception:
        pass
    
    return {
        "interview_id": interview_id,
        "timestamp": datetime.utcnow().isoformat(),
        "data_saved": True
    }

# ================================================================================================
# ğŸ“ ç¬¬å…­éƒ¨åˆ†ï¼šæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
# ================================================================================================

async def upload_audio_file(db: Session, interview_id: int, question_id: int, 
                           audio_file: UploadFile, user_id: int) -> Dict:
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if not audio_file.content_type.startswith('audio/'):
        raise ValueError("æ–‡ä»¶ç±»å‹é”™è¯¯ï¼Œè¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
    
    file_extension = audio_file.filename.split('.')[-1]
    unique_filename = f"audio_{interview_id}_{question_id}_{uuid.uuid4().hex}.{file_extension}"
    
    upload_dir = "uploads/audio"
    os.makedirs(upload_dir, exist_ok=True)
    file_path = os.path.join(upload_dir, unique_filename)
    
    with open(file_path, "wb") as buffer:
        content = await audio_file.read()
        buffer.write(content)
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if answer:
        answer.audio_file_path = file_path
        answer.audio_file_size = len(content)
        answer.file_upload_time = datetime.utcnow()
    else:
        answer = InterviewAnswer(
            interview_id=interview_id,
            question_id=question_id,
            audio_file_path=file_path,
            audio_file_size=len(content),
            file_upload_time=datetime.utcnow()
        )
        db.add(answer)
    
    db.commit()
    
    return {
        "file_id": unique_filename,
        "file_path": file_path,
        "file_size": len(content),
        "upload_time": datetime.utcnow().isoformat(),
        "message": "éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ æˆåŠŸ"
    }

async def upload_video_file(db: Session, interview_id: int, question_id: int, 
                           video_file: UploadFile, user_id: int) -> Dict:
    """ä¸Šä¼ è§†é¢‘æ–‡ä»¶"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if not video_file.content_type.startswith('video/'):
        raise ValueError("æ–‡ä»¶ç±»å‹é”™è¯¯ï¼Œè¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
    
    file_extension = video_file.filename.split('.')[-1]
    unique_filename = f"video_{interview_id}_{question_id}_{uuid.uuid4().hex}.{file_extension}"
    
    upload_dir = "uploads/video"
    os.makedirs(upload_dir, exist_ok=True)
    file_path = os.path.join(upload_dir, unique_filename)
    
    with open(file_path, "wb") as buffer:
        content = await video_file.read()
        buffer.write(content)
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if answer:
        answer.video_file_path = file_path
        answer.video_file_size = len(content)
        answer.file_upload_time = datetime.utcnow()
    else:
        answer = InterviewAnswer(
            interview_id=interview_id,
            question_id=question_id,
            video_file_path=file_path,
            video_file_size=len(content),
            file_upload_time=datetime.utcnow()
        )
        db.add(answer)
    
    db.commit()
    
    return {
        "file_id": unique_filename,
        "file_path": file_path,
        "file_size": len(content),
        "upload_time": datetime.utcnow().isoformat(),
        "message": "è§†é¢‘æ–‡ä»¶ä¸Šä¼ æˆåŠŸ"
    }

# ================================================================================================
# ğŸ‘¤ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šè™šæ‹Ÿé¢è¯•å®˜åŠŸèƒ½
# ================================================================================================

def get_interviewer_list(db: Session) -> List[Dict]:
    """è·å–è™šæ‹Ÿé¢è¯•å®˜åˆ—è¡¨"""
    interviewers = [
        {
            "id": 1,
            "name": "æé¢è¯•å®˜",
            "description": "äº²å’ŒåŠ›å¼ºï¼Œå–„äºå¼•å¯¼",
            "avatar": "/avatars/interviewer-1.jpg",
            "model": "/models/avatar-1.glb",
            "specialties": ["æ¸©å’Œå‹", "é¼“åŠ±å¼", "æ–°äººå‹å¥½"],
            "experience": "5å¹´HRç»éªŒ",
            "style": "gentle"
        },
        {
            "id": 2,
            "name": "å¼ é¢è¯•å®˜",
            "description": "ç»éªŒä¸°å¯Œï¼Œä¸“ä¸šä¸¥è°¨",
            "avatar": "/avatars/interviewer-2.jpg",
            "model": "/models/avatar-2.glb",
            "specialties": ["æŠ€æœ¯æ·±åº¦", "ä¸¥è°¨ç»†è‡´", "æ ‡å‡†åŒ–"],
            "experience": "10å¹´æŠ€æœ¯æ€»ç›‘",
            "style": "serious"
        },
        {
            "id": 3,
            "name": "ç‹é¢è¯•å®˜",
            "description": "æŠ€æœ¯ä¸“å®¶ï¼Œæ·±åº¦æŒ–æ˜",
            "avatar": "/avatars/interviewer-3.jpg",
            "model": "/models/avatar-3.glb",
            "specialties": ["æŠ€æœ¯æŒ‘æˆ˜", "å‹åŠ›æµ‹è¯•", "æ·±åº¦è¿½é—®"],
            "experience": "15å¹´æ¶æ„å¸ˆ",
            "style": "challenging"
        }
    ]
    
    return interviewers

def get_interviewer_config(db: Session, interviewer_id: int) -> Dict:
    """è·å–é¢è¯•å®˜é…ç½®"""
    interviewers = get_interviewer_list(db)
    
    interviewer = next((i for i in interviewers if i['id'] == interviewer_id), None)
    
    if not interviewer:
        raise ValueError("é¢è¯•å®˜ä¸å­˜åœ¨")
    
    config = interviewer.copy()
    config.update({
        "voice_settings": {
            "speed": 1.0,
            "pitch": 1.0,
            "volume": 0.8
        },
        "behavior_settings": {
            "question_interval": 3,
            "patience_level": 5,
            "follow_up_probability": 0.3
        },
        "question_style": {
            "formal_level": 0.7 if interviewer_id == 2 else 0.5,
            "detail_focus": 0.8 if interviewer_id == 3 else 0.6,
            "encouragement": 0.9 if interviewer_id == 1 else 0.5
        }
    })
    
    return config

def get_interviewer_detailed_config(db: Session, interviewer_id: int) -> Dict:
    """è·å–é¢è¯•å®˜è¯¦ç»†é…ç½®ï¼ˆæ¨¡æ‹Ÿé¢è¯•å¢å¼ºç‰ˆï¼‰"""
    basic_config = get_interviewer_config(db, interviewer_id)
    
    simulation_config = {
        "interaction_style": {
            "question_pace": 1.0,
            "patience_level": 0.8,
            "follow_up_rate": 0.3,
            "encouragement_level": 0.6
        },
        "evaluation_focus": {
            "technical_weight": 0.4,
            "communication_weight": 0.3,
            "attitude_weight": 0.3
        },
        "simulation_features": {
            "supports_phase_control": True,
            "supports_real_time_feedback": True,
            "supports_stress_testing": interviewer_id == 3
        }
    }
    
    enhanced_config = basic_config.copy()
    enhanced_config.update(simulation_config)
    
    return enhanced_config

# ================================================================================================
# ğŸ“Š ç¬¬å…«éƒ¨åˆ†ï¼šé¢è¯•é˜¶æ®µç®¡ç†
# ================================================================================================

def get_interview_phases(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–é¢è¯•é˜¶æ®µä¿¡æ¯"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    phases = [
        {"id": "intro", "title": "å¼€åœºä»‹ç»", "description": "é¢è¯•å®˜ä»‹ç»å’Œæ°›å›´è¥é€ "},
        {"id": "self", "title": "è‡ªæˆ‘ä»‹ç»", "description": "å€™é€‰äººè‡ªæˆ‘å±•ç¤º"},
        {"id": "technical", "title": "æŠ€æœ¯é—®ç­”", "description": "ä¸“ä¸šæŠ€èƒ½è€ƒå¯Ÿ"},
        {"id": "project", "title": "é¡¹ç›®ç»å†", "description": "å®è·µç»éªŒåˆ†äº«"},
        {"id": "behavioral", "title": "è¡Œä¸ºé¢è¯•", "description": "è½¯æŠ€èƒ½è¯„ä¼°"},
        {"id": "questions", "title": "æé—®ç¯èŠ‚", "description": "å€™é€‰äººæé—®"}
    ]
    
    current_phase = determine_current_phase(db, interview_id)
    current_phase_index = next((i for i, p in enumerate(phases) if p['id'] == current_phase), 0)
    
    return {
        "phases": phases,
        "current_phase": current_phase,
        "current_phase_index": current_phase_index,
        "total_phases": len(phases),
        "progress_percentage": round((current_phase_index + 1) / len(phases) * 100, 1)
    }

def advance_interview_phase(db: Session, interview_id: int, user_id: int) -> Dict:
    """è¿›å…¥ä¸‹ä¸€ä¸ªé¢è¯•é˜¶æ®µ"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    phases_data = get_interview_phases(db, interview_id, user_id)
    
    if phases_data['current_phase_index'] >= phases_data['total_phases'] - 1:
        raise ValueError("å·²æ˜¯æœ€åé˜¶æ®µ")
    
    return {
        "previous_phase": phases_data['current_phase'],
        "next_phase_index": phases_data['current_phase_index'] + 1,
        "message": "é˜¶æ®µåˆ‡æ¢æˆåŠŸ"
    }

def update_interviewer_status(db: Session, interview_id: int, status_data: Dict, user_id: int) -> Dict:
    """æ›´æ–°é¢è¯•å®˜çŠ¶æ€"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if interview.type != 'simulation':
        raise ValueError("åªæœ‰æ¨¡æ‹Ÿé¢è¯•æ”¯æŒé¢è¯•å®˜çŠ¶æ€æ§åˆ¶")
    
    current_settings = {}
    if interview.settings:
        try:
            current_settings = json.loads(interview.settings)
        except:
            current_settings = {}
    
    interviewer_status = current_settings.get('interviewer_status', {})
    interviewer_status.update({
        'is_speaking': status_data.get('is_speaking', False),
        'is_listening': status_data.get('is_listening', False),
        'current_phase': status_data.get('current_phase'),
        'last_update': datetime.utcnow().isoformat()
    })
    
    current_settings['interviewer_status'] = interviewer_status
    interview.settings = json.dumps(current_settings)
    
    if status_data.get('current_phase'):
        interview.current_phase = status_data['current_phase']
    
    interview.last_activity = datetime.utcnow()
    db.commit()
    
    return {
        "interview_id": interview_id,
        "interviewer_status": interviewer_status,
        "updated_at": datetime.utcnow().isoformat()
    }

def update_interview_phase(db: Session, interview_id: int, phase_data: Dict, user_id: int) -> Dict:
    """æ›´æ–°é¢è¯•é˜¶æ®µ"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    phases = ['intro', 'self', 'technical', 'project', 'behavioral', 'questions']
    
    current_phase = phase_data.get('current_phase')
    phase_index = phase_data.get('phase_index')
    
    if current_phase and current_phase in phases:
        interview.current_phase = current_phase
        
        current_settings = {}
        if interview.settings:
            try:
                current_settings = json.loads(interview.settings)
            except:
                current_settings = {}
        
        phase_info = current_settings.get('phase_info', {})
        phase_info.update({
            'current_phase': current_phase,
            'phase_index': phase_index or phases.index(current_phase),
            'total_phases': len(phases),
            'updated_at': datetime.utcnow().isoformat()
        })
        
        current_settings['phase_info'] = phase_info
        interview.settings = json.dumps(current_settings)
        
        interview.last_activity = datetime.utcnow()
        db.commit()
        
        return {
            "interview_id": interview_id,
            "current_phase": current_phase,
            "phase_index": phase_index,
            "total_phases": len(phases),
            "progress_percentage": ((phase_index + 1) / len(phases)) * 100 if phase_index is not None else 0
        }
    else:
        raise ValueError(f"æ— æ•ˆçš„é¢è¯•é˜¶æ®µ: {current_phase}")

# ================================================================================================
# ğŸ¤– ç¬¬ä¹éƒ¨åˆ†ï¼šå›ç­”å¤„ç†å’ŒAIè¯„åˆ†æ¥å£åŒºåŸŸ
# ================================================================================================

def submit_answer(db: Session, question_id: int, answer_data: Dict) -> Dict:
    """æäº¤ç­”æ¡ˆå¹¶è·å–AIåé¦ˆ"""
    question = db.query(InterviewQuestion).filter(InterviewQuestion.id == question_id).first()
    if not question:
        raise ValueError("é¢˜ç›®ä¸å­˜åœ¨")
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if not answer:
        answer = InterviewAnswer(
            interview_id=question.interview_id,
            question_id=question_id
        )
        db.add(answer)
    
    answer.answer_text = answer_data.get('answer_text')
    answer.audio_file_path = answer_data.get('audio_file_path')
    answer.video_file_path = answer_data.get('video_file_path')
    answer.time_spent = answer_data.get('time_spent')
    answer.used_hint = answer_data.get('used_hint', False)
    answer.is_complete = True
    answer.submitted_at = datetime.utcnow()
    
    question.status = 'answered'
    question.answered_at = datetime.utcnow()
    question.time_spent = answer_data.get('time_spent')
    
    db.commit()
    
    # è°ƒç”¨AIè¯„åˆ†
    ai_feedback = generate_ai_feedback(answer, question)
    
    answer.score = ai_feedback['score']
    answer.ai_feedback = ai_feedback['feedback']
    answer.improvement_tips = json.dumps(ai_feedback['tips'])
    
    db.commit()
    
    return ai_feedback

def generate_ai_feedback(answer: InterviewAnswer, question: InterviewQuestion) -> Dict:
    """
    ç”ŸæˆAIåé¦ˆï¼ˆç»ƒä¹ æ¨¡å¼ï¼‰
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - ç»ƒä¹ æ¨¡å¼AIè¯„åˆ†
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œæ™ºèƒ½è¯„åˆ†å’Œåé¦ˆç”Ÿæˆï¼š
    - answer.answer_text: å›ç­”å†…å®¹
    - answer.audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
    - answer.video_file_path: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
    - question.question_text: é¢˜ç›®å†…å®¹
    - question.question_type: é¢˜ç›®ç±»å‹
    - question.difficulty: é¢˜ç›®éš¾åº¦
    - answer.time_spent: å›ç­”ç”¨æ—¶
    - answer.used_hint: æ˜¯å¦ä½¿ç”¨æç¤º
    
    åº”è¯¥è¿”å›åŒ…å«è¯„åˆ†ã€åé¦ˆå’Œæ”¹è¿›å»ºè®®çš„ç»“æ„
    """
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     ai_result = ai_service.evaluate_answer(
    #         answer_text=answer.answer_text,
    #         audio_file=answer.audio_file_path,
    #         video_file=answer.video_file_path,
    #         question_context={
    #             'text': question.question_text,
    #             'type': question.question_type,
    #             'difficulty': question.difficulty,
    #             'category': question.category
    #         },
    #         answer_metadata={
    #             'time_spent': answer.time_spent,
    #             'used_hint': answer.used_hint
    #         }
    #     )
    #     
    #     return {
    #         'score': ai_result.score,
    #         'feedback': ai_result.feedback,
    #         'tips': ai_result.improvement_tips,
    #         'detailed_scores': ai_result.detailed_scores
    #     }
    # except Exception as e:
    #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨è¯„åˆ†
    #     return get_fallback_feedback(question.question_type)
    
    # å½“å‰ä½¿ç”¨çš„æ¨¡æ‹Ÿè¯„åˆ†ï¼ˆAIå¯¹æ¥åå¯åˆ é™¤ï¼‰
    mock_scores = {
        'behavioral': 85.0,
        'technical': 82.0,
        'situational': 88.0,
        'project': 90.0
    }
    
    mock_feedback = {
        'behavioral': 'è‡ªæˆ‘ä»‹ç»ç»“æ„æ¸…æ™°ï¼Œè¡¨è¾¾æµç•…ï¼Œå»ºè®®å¢åŠ æ›´å¤šå…·ä½“æ¡ˆä¾‹ã€‚',
        'technical': 'æŠ€æœ¯ç†è§£æ­£ç¡®ï¼Œå¯ä»¥æ·±å…¥è¯´æ˜å®ç°ç»†èŠ‚å’Œä¼˜åŒ–æ–¹æ¡ˆã€‚',
        'situational': 'è§£å†³æ€è·¯åˆç†ï¼Œå±•ç°äº†è‰¯å¥½çš„é—®é¢˜åˆ†æèƒ½åŠ›ã€‚',
        'project': 'é¡¹ç›®æè¿°è¯¦ç»†ï¼Œä½“ç°äº†æ‰å®çš„å®è·µç»éªŒã€‚'
    }
    
    mock_tips = {
        'behavioral': ['å¢åŠ å…·ä½“æ•°æ®æ”¯æ’‘', 'çªå‡ºä¸ªäººè´¡çŒ®', 'ä¿æŒè‡ªä¿¡è¡¨è¾¾'],
        'technical': ['æ·±å…¥æŠ€æœ¯ç»†èŠ‚', 'è¯´æ˜ä¼˜åŒ–æ–¹æ¡ˆ', 'ç»“åˆå®é™…åœºæ™¯'],
        'situational': ['å¤šè§’åº¦åˆ†æ', 'æå‡ºå…·ä½“æªæ–½', 'è€ƒè™‘é£é™©å› ç´ '],
        'project': ['é‡åŒ–é¡¹ç›®æˆæœ', 'è¯´æ˜æŠ€æœ¯é€‰å‹', 'æ€»ç»“ç»éªŒæ•™è®­']
    }
    
    q_type = question.question_type or 'behavioral'
    
    return {
        'score': mock_scores.get(q_type, 80.0),
        'feedback': mock_feedback.get(q_type, 'å›ç­”åŸºæœ¬å®Œæ•´ï¼Œè¡¨è¾¾æ¸…æ™°ã€‚'),
        'tips': mock_tips.get(q_type, ['ç»§ç»­ä¿æŒ', 'å¤šåŠ ç»ƒä¹ '])
    }

def generate_simulation_ai_feedback(answer: InterviewAnswer, question: InterviewQuestion) -> Dict:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•AIåé¦ˆï¼ˆæ›´ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡†ï¼‰
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•AIè¯„åˆ†
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œè¿›è¡Œæ›´ä¸¥æ ¼çš„è¯„åˆ†ï¼š
    - æ¨¡æ‹Ÿé¢è¯•çš„è¯„åˆ†æ ‡å‡†åº”è¯¥æ›´ä¸¥æ ¼
    - éœ€è¦è€ƒè™‘çœŸå®é¢è¯•çš„è¯„åˆ¤æ ‡å‡†
    - åŒ…æ‹¬ä¸“ä¸šåº¦ã€è¡¨è¾¾èƒ½åŠ›ã€é€»è¾‘æ€ç»´ç­‰å¤šç»´åº¦è¯„åˆ†
    """
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     ai_result = ai_service.evaluate_simulation_answer(
    #         answer_text=answer.answer_text,
    #         audio_file=answer.audio_file_path,
    #         video_file=answer.video_file_path,
    #         question_context={
    #             'text': question.question_text,
    #             'type': question.question_type,
    #             'difficulty': question.difficulty,
    #             'category': question.category
    #         },
    #         simulation_context={
    #             'is_simulation': True,
    #             'stricter_evaluation': True,
    #             'real_interview_standards': True
    #         }
    #     )
    #     
    #     return {
    #         'score': ai_result.score,
    #         'feedback': ai_result.feedback,
    #         'tips': ai_result.improvement_tips
    #     }
    # except Exception as e:
    #     return get_fallback_simulation_feedback(question.question_type)
    
    # å½“å‰ä½¿ç”¨çš„æ¨¡æ‹Ÿè¯„åˆ†ï¼ˆæ¯”ç»ƒä¹ æ¨¡å¼æ›´ä¸¥æ ¼ï¼‰
    base_scores = {
        'behavioral': 78.0,
        'technical': 75.0,
        'situational': 80.0,
        'project': 82.0,
        'stress': 70.0,
        'questions': 85.0
    }
    
    feedback_templates = {
        'behavioral': 'è¡¨è¾¾è¾ƒä¸ºæ¸…æ™°ï¼Œå»ºè®®å¢åŠ æ›´å¤šå…·ä½“æ¡ˆä¾‹å’Œé‡åŒ–æ•°æ®æ¥æ”¯æ’‘è§‚ç‚¹ã€‚',
        'technical': 'æŠ€æœ¯ç†è§£åŸºæœ¬æ­£ç¡®ï¼Œä½†éœ€è¦åœ¨å®ç°ç»†èŠ‚å’Œä¼˜åŒ–æ–¹æ¡ˆæ–¹é¢æœ‰æ›´æ·±å…¥çš„é˜è¿°ã€‚',
        'situational': 'è§£å†³æ€è·¯åˆç†ï¼Œä½†å¯ä»¥è€ƒè™‘æ›´å¤šçš„é£é™©å› ç´ å’Œé¢„æ¡ˆã€‚',
        'project': 'é¡¹ç›®æè¿°å®Œæ•´ï¼Œå»ºè®®æ›´å¤šåœ°çªå‡ºä¸ªäººè´¡çŒ®å’ŒæŠ€æœ¯éš¾ç‚¹çš„è§£å†³è¿‡ç¨‹ã€‚',
        'stress': 'åœ¨å‹åŠ›ç¯å¢ƒä¸‹ä¿æŒäº†åŸºæœ¬çš„å›ç­”ç»“æ„ï¼Œå»ºè®®æå‡åº”å¯¹ç´§æ€¥æƒ…å†µçš„å†·é™åº¦ã€‚',
        'questions': 'æé—®æ˜¾ç¤ºäº†å¯¹å²—ä½çš„å…³æ³¨ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°äº†è§£å›¢é˜Ÿæ–‡åŒ–å’Œå‘å±•æœºä¼šã€‚'
    }
    
    tips_templates = {
        'behavioral': ['å¢åŠ å…·ä½“æ•°æ®', 'çªå‡ºä¸ªäººä»·å€¼', 'å®Œå–„è¡¨è¾¾é€»è¾‘'],
        'technical': ['æ·±åŒ–æŠ€æœ¯ç»†èŠ‚', 'è¯´æ˜ä¼˜åŒ–æ€è·¯', 'ç»“åˆå®é™…åœºæ™¯'],
        'situational': ['è€ƒè™‘å¤šç§æ–¹æ¡ˆ', 'è¯„ä¼°é£é™©å› ç´ ', 'åˆ¶å®šåº”æ€¥é¢„æ¡ˆ'],
        'project': ['é‡åŒ–é¡¹ç›®ä»·å€¼', 'çªå‡ºæŠ€æœ¯äº®ç‚¹', 'æ€»ç»“å…³é”®ç»éªŒ'],
        'stress': ['ä¿æŒå†·é™æ€è€ƒ', 'ç®€æ´å›ç­”è¦ç‚¹', 'å±•ç°æŠ—å‹èƒ½åŠ›'],
        'questions': ['æ·±å…¥äº†è§£å›¢é˜Ÿ', 'å…³æ³¨å‘å±•æœºä¼š', 'å±•ç°é•¿æœŸå…´è¶£']
    }
    
    q_type = question.question_type or 'behavioral'
    
    # æ¨¡æ‹Ÿé¢è¯•è¯„åˆ†æ›´ä¸¥æ ¼ï¼Œå‡å°‘5-10åˆ†
    base_score = base_scores.get(q_type, 75.0)
    final_score = max(0, min(100, base_score + random.uniform(-8, 2)))
    
    return {
        'score': final_score,
        'feedback': feedback_templates.get(q_type, 'å›ç­”åŸºæœ¬å®Œæ•´ï¼Œå»ºè®®ç»§ç»­æå‡è¡¨è¾¾çš„ä¸“ä¸šæ€§å’Œæ·±åº¦ã€‚'),
        'tips': tips_templates.get(q_type, ['ç»§ç»­ç»ƒä¹ ', 'æå‡ä¸“ä¸šåº¦'])
    }

def get_next_question(db: Session, current_question_id: int) -> Optional[Dict]:
    """è·å–ä¸‹ä¸€é¢˜"""
    current_question = db.query(InterviewQuestion).filter(
        InterviewQuestion.id == current_question_id
    ).first()
    
    if not current_question:
        return None
    
    next_question = db.query(InterviewQuestion).filter(
        and_(
            InterviewQuestion.interview_id == current_question.interview_id,
            InterviewQuestion.sequence_number > current_question.sequence_number,
            InterviewQuestion.status == 'pending'
        )
    ).order_by(InterviewQuestion.sequence_number).first()
    
    if not next_question:
        return None
    
    next_question.status = 'current'
    next_question.asked_at = datetime.utcnow()
    db.commit()
    
    return {
        'id': next_question.id,
        'text': next_question.question_text,
        'type': next_question.question_type,
        'time_limit': next_question.time_limit,
        'allow_hints': next_question.allow_hints
    }

def start_answer_simulation(db: Session, interview_id: int, answer_data: Dict, user_id: int) -> Dict:
    """å¼€å§‹å›ç­”ï¼ˆæ¨¡æ‹Ÿé¢è¯•ä¸“ç”¨ï¼‰"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    question_id = answer_data.get('question_id')
    if not question_id:
        raise ValueError("ç¼ºå°‘é¢˜ç›®ID")
    
    question = db.query(InterviewQuestion).filter(
        InterviewQuestion.id == question_id,
        InterviewQuestion.interview_id == interview_id
    ).first()
    
    if not question:
        raise ValueError("é¢˜ç›®ä¸å­˜åœ¨")
    
    question.status = 'current'
    question.asked_at = datetime.utcnow()
    
    interview.is_recording = True
    interview.current_question_id = question_id
    interview.last_activity = datetime.utcnow()
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if not answer:
        answer = InterviewAnswer(
            interview_id=interview_id,
            question_id=question_id,
            started_at=datetime.utcnow()
        )
        db.add(answer)
    else:
        answer.started_at = datetime.utcnow()
    
    db.commit()
    
    return {
        "interview_id": interview_id,
        "question_id": question_id,
        "started_at": datetime.utcnow().isoformat(),
        "time_limit": question.time_limit,
        "message": "å¼€å§‹å›ç­”å·²è®°å½•"
    }

def finish_answer_simulation(db: Session, interview_id: int, answer_data: Dict, user_id: int) -> Dict:
    """å®Œæˆå›ç­”ï¼ˆæ¨¡æ‹Ÿé¢è¯•ä¸“ç”¨ï¼‰"""
    question_id = answer_data.get('question_id')
    if not question_id:
        raise ValueError("ç¼ºå°‘é¢˜ç›®ID")
    
    answer = db.query(InterviewAnswer).filter(
        InterviewAnswer.question_id == question_id
    ).first()
    
    if not answer:
        answer = InterviewAnswer(
            interview_id=interview_id,
            question_id=question_id
        )
        db.add(answer)
    
    answer.answer_text = answer_data.get('answer_text')
    answer.audio_file_path = answer_data.get('audio_file_path')
    answer.video_file_path = answer_data.get('video_file_path')
    answer.time_spent = answer_data.get('time_spent')
    answer.is_complete = True
    answer.submitted_at = datetime.utcnow()
    
    question = db.query(InterviewQuestion).filter(
        InterviewQuestion.id == question_id
    ).first()
    
    if question:
        question.status = 'answered'
        question.answered_at = datetime.utcnow()
        question.time_spent = answer_data.get('time_spent')
    
    interview = db.query(Interview).filter(
        Interview.id == interview_id
    ).first()
    
    if interview:
        interview.is_recording = False
        interview.answered_questions = (interview.answered_questions or 0) + 1
        interview.last_activity = datetime.utcnow()
    
    db.commit()
    
    # ç”ŸæˆAIè¯„åˆ†
    try:
        ai_feedback = generate_simulation_ai_feedback(answer, question)
        answer.score = ai_feedback['score']
        answer.ai_feedback = ai_feedback['feedback']
        answer.improvement_tips = json.dumps(ai_feedback['tips'])
        db.commit()
    except Exception:
        ai_feedback = {'score': 75.0, 'feedback': 'å›ç­”å·²æäº¤', 'tips': []}
    
    # è·å–ä¸‹ä¸€é¢˜
    next_question = get_next_simulation_question(db, interview_id, question.sequence_number)
    
    return {
        "interview_id": interview_id,
        "question_id": question_id,
        "score": ai_feedback['score'],
        "feedback": ai_feedback['feedback'],
        "next_question": next_question,
        "is_last_question": next_question is None
    }

# ================================================================================================
# ğŸ¤– ç¬¬åéƒ¨åˆ†ï¼šé¢è¯•å®Œæˆå’ŒæŠ¥å‘Šç”Ÿæˆæ¥å£åŒºåŸŸ
# ================================================================================================

def complete_interview(db: Session, interview_id: int, completion_data: Dict = None) -> Dict:
    """
    å®Œæˆé¢è¯•å¹¶ç”Ÿæˆè¯„åˆ†æŠ¥å‘Š
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - é¢è¯•æŠ¥å‘Šç”Ÿæˆ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œç”Ÿæˆç»¼åˆé¢è¯•æŠ¥å‘Šï¼š
    - åˆ†æç”¨æˆ·æ‰€æœ‰å›ç­”çš„è¡¨ç°
    - ç”Ÿæˆå„ç»´åº¦çš„è¯¦ç»†è¯„åˆ†
    - æä¾›ä¸ªæ€§åŒ–çš„æ”¹è¿›å»ºè®®
    - ç”Ÿæˆç»¼åˆè¯„ä»·å’Œåé¦ˆ
    """
    
    try:
        interview = db.query(Interview).filter(Interview.id == interview_id).first()
        if not interview:
            raise ValueError("é¢è¯•ä¸å­˜åœ¨")
        
        interview.status = 'completed'
        interview.completed_at = datetime.utcnow()
        
        if interview.started_at:
            duration = (interview.completed_at - interview.started_at).seconds // 60
            interview.actual_duration = duration
        else:
            interview.actual_duration = 0
        
        # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
        # try:
        #     # è·å–æ‰€æœ‰å›ç­”æ•°æ®ç”¨äºAIåˆ†æ
        #     answers = db.query(InterviewAnswer).filter(
        #         InterviewAnswer.interview_id == interview_id,
        #         InterviewAnswer.is_complete == True
        #     ).all()
        #     
        #     questions = db.query(InterviewQuestion).filter(
        #         InterviewQuestion.interview_id == interview_id
        #     ).all()
        #     
        #     # è°ƒç”¨AIç”Ÿæˆç»¼åˆæŠ¥å‘Š
        #     ai_report = ai_service.generate_interview_report(
        #         interview_data={
        #             'type': interview.type,
        #             'position': interview.position,
        #             'company': interview.company,
        #             'duration': interview.actual_duration,
        #             'difficulty': interview.difficulty
        #         },
        #         answers_data=[{
        #             'question_text': q.question_text,
        #             'question_type': q.question_type,
        #             'answer_text': a.answer_text,
        #             'time_spent': a.time_spent,
        #             'score': a.score,
        #             'used_hint': a.used_hint
        #         } for q, a in zip(questions, answers)],
        #         realtime_data=get_interview_realtime_data(interview_id)
        #     )
        #     
        #     # ä½¿ç”¨AIç”Ÿæˆçš„è¯„åˆ†å’Œåé¦ˆ
        #     scores = ai_report.detailed_scores
        #     interview.ai_feedback = ai_report.comprehensive_feedback
        #     interview.key_feedback = ai_report.key_insights
        #     interview.improvement_suggestions = ai_report.improvement_plan
        #     
        # except Exception as e:
        #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨è¯„åˆ†ç®—æ³•
        #     scores = calculate_interview_scores_safe(db, interview_id)
        #     interview.ai_feedback = generate_overall_feedback(scores)
        #     interview.key_feedback = generate_key_feedback(scores)
        #     interview.improvement_suggestions = generate_improvement_suggestions(scores)
        
        # å½“å‰ä½¿ç”¨çš„å¤‡ç”¨è¯„åˆ†ç®—æ³•ï¼ˆAIå¯¹æ¥åä½œä¸ºå¤‡ç”¨ï¼‰
        try:
            scores = calculate_interview_scores_safe(db, interview_id)
        except Exception:
            scores = {
                'overall': 0.0,
                'professional': 0.0,
                'skill_match': 0.0,
                'language_expression': 0.0,
                'logical_thinking': 0.0,
                'comprehensive_quality': 0.0
            }
        
        interview.overall_score = scores['overall']
        interview.professional_score = scores['professional']
        interview.skill_match_score = scores['skill_match']
        interview.language_expression_score = scores['language_expression']
        interview.logical_thinking_score = scores['logical_thinking']
        interview.comprehensive_quality_score = scores['comprehensive_quality']
        
        try:
            interview.ai_feedback = generate_overall_feedback(scores)
            interview.key_feedback = generate_key_feedback(scores)
            interview.improvement_suggestions = generate_improvement_suggestions(scores)
        except Exception:
            interview.ai_feedback = "é¢è¯•å·²å®Œæˆï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼"
            interview.key_feedback = "æ•´ä½“è¡¨ç°è‰¯å¥½"
            interview.improvement_suggestions = "ç»§ç»­ä¿æŒï¼Œå¤šåŠ ç»ƒä¹ "
        
        try:
            answered_count = db.query(InterviewAnswer).filter(
                InterviewAnswer.interview_id == interview_id,
                InterviewAnswer.is_complete == True
            ).count()
            interview.answered_questions = answered_count
        except Exception:
            interview.answered_questions = 0
        
        db.commit()
        
        try:
            update_user_statistics_safe(db, interview.user_id, interview)
        except Exception:
            pass
        
        try:
            save_trend_data_safe(db, interview)
        except Exception:
            pass
        
        return {
            'interview_id': interview_id,
            'overall_score': interview.overall_score or 0,
            'duration': interview.actual_duration or 0,
            'completion_message': 'é¢è¯•å®Œæˆï¼',
            'report_available': True
        }
        
    except ValueError as ve:
        raise ve
    except Exception as e:
        try:
            db.rollback()
        except:
            pass
        raise Exception(f"å®Œæˆé¢è¯•å¤±è´¥: {str(e)}")

def complete_simulation_interview(db: Session, interview_id: int, completion_data: Dict, user_id: int) -> Dict:
    """
    å®Œæˆæ¨¡æ‹Ÿé¢è¯•
    
    ğŸ¤– AIæ¥å£å¯¹æ¥ä½ç½® - æ¨¡æ‹Ÿé¢è¯•æŠ¥å‘Šç”Ÿæˆ
    TODO: é˜Ÿå‹åœ¨è¿™é‡Œå¯¹æ¥AI APIï¼Œç”Ÿæˆæ›´ä¸¥æ ¼çš„æ¨¡æ‹Ÿé¢è¯•æŠ¥å‘Šï¼š
    - ç›¸æ¯”ç»ƒä¹ æ¨¡å¼åº”è¯¥æœ‰æ›´ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡†
    - ç”Ÿæˆæ›´è¯¦ç»†çš„ç»¼åˆè¯„ä»·æŠ¥å‘Š
    - æä¾›é’ˆå¯¹çœŸå®é¢è¯•çš„å‡†å¤‡å»ºè®®
    """
    
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    if interview.type != 'simulation':
        raise ValueError("è¯¥æ¥å£ä»…ç”¨äºæ¨¡æ‹Ÿé¢è¯•")
    
    interview.status = 'completed'
    interview.completed_at = datetime.utcnow()
    
    if interview.started_at:
        duration = (interview.completed_at - interview.started_at).seconds // 60
        interview.actual_duration = duration
    
    completion_type = completion_data.get('completion_type', 'normal')
    if completion_type == 'emergency':
        interview.is_emergency_exit = True
        interview.exit_reason = completion_data.get('emergency_reason', 'ç”¨æˆ·ç´§æ€¥é€€å‡º')
    
    # ğŸ¤– AIæ¥å£è°ƒç”¨ç¤ºä¾‹ä»£ç ä½ç½®ï¼š
    # try:
    #     # æ¨¡æ‹Ÿé¢è¯•çš„AIæŠ¥å‘Šç”Ÿæˆ
    #     ai_report = ai_service.generate_simulation_report(
    #         interview_data={
    #             'company_type': interview.company,
    #             'position': interview.position,
    #             'round_type': interview.round_type,
    #             'interview_style': interview.interview_style,
    #             'duration': interview.actual_duration
    #         },
    #         performance_data=get_simulation_performance_data(interview_id),
    #         realtime_analysis=get_simulation_realtime_analysis(interview_id),
    #         completion_type=completion_type
    #     )
    #     
    #     scores = ai_report.detailed_scores
    #     interview.ai_feedback = ai_report.comprehensive_feedback
    #     interview.key_feedback = ai_report.key_insights
    #     interview.improvement_suggestions = ai_report.improvement_plan
    #     
    # except Exception as e:
    #     # AIæœåŠ¡å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨ç®—æ³•
    #     scores = calculate_simulation_scores(db, interview_id)
    #     interview.ai_feedback = generate_simulation_feedback(scores, interview)
    #     interview.key_feedback = generate_simulation_key_feedback(scores)
    #     interview.improvement_suggestions = generate_simulation_improvement_suggestions(scores)
    
    # å½“å‰ä½¿ç”¨å¤‡ç”¨ç®—æ³•
    try:
        scores = calculate_simulation_scores(db, interview_id)
        interview.overall_score = scores['overall']
        interview.professional_score = scores['professional']
        interview.skill_match_score = scores['skill_match']
        interview.language_expression_score = scores['language_expression']
        interview.logical_thinking_score = scores['logical_thinking']
        interview.comprehensive_quality_score = scores['comprehensive_quality']
        
        interview.ai_feedback = generate_simulation_feedback(scores, interview)
        interview.key_feedback = generate_simulation_key_feedback(scores)
        interview.improvement_suggestions = generate_simulation_improvement_suggestions(scores)
        
    except Exception:
        interview.overall_score = 70.0
        interview.ai_feedback = "æ¨¡æ‹Ÿé¢è¯•å·²å®Œæˆï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼"
    
    answered_count = db.query(InterviewAnswer).filter(
        InterviewAnswer.interview_id == interview_id,
        InterviewAnswer.is_complete == True
    ).count()
    interview.answered_questions = answered_count
    
    db.commit()
    
    try:
        update_user_statistics_safe(db, interview.user_id, interview)
        save_trend_data_safe(db, interview)
    except Exception:
        pass
    
    return {
        'interview_id': interview_id,
        'overall_score': interview.overall_score or 0,
        'duration': interview.actual_duration or 0,
        'completion_message': 'æ¨¡æ‹Ÿé¢è¯•å®Œæˆï¼æ‚¨çš„è¡¨ç°æŠ¥å‘Šå·²ç”Ÿæˆã€‚' if completion_type == 'normal' else 'æ¨¡æ‹Ÿé¢è¯•å·²ä¸­æ–­',
        'report_available': True,
        'completion_type': completion_type
    }

# ================================================================================================
# ğŸ“Š ç¬¬åä¸€éƒ¨åˆ†ï¼šæ•°æ®æŸ¥è¯¢å’Œåˆ†æ
# ================================================================================================

def get_user_performance(db: Session, user_id: int) -> PerformanceResponse:
    """è·å–ç”¨æˆ·é¢è¯•è¡¨ç°åˆ†ææ•°æ®"""
    try:
        stats = db.query(InterviewStatistics).filter(
            InterviewStatistics.user_id == user_id
        ).first()
        
        if not stats:
            stats = InterviewStatistics(user_id=user_id)
            db.add(stats)
            db.commit()
            db.refresh(stats)
        
        latest_interview = db.query(Interview).filter(
            Interview.user_id == user_id,
            Interview.status == 'completed',
            Interview.overall_score.isnot(None)
        ).order_by(desc(Interview.completed_at)).first()
        
        ability_scores = AbilityScores()
        overall_score = 0.0
        
        if latest_interview:
            ability_scores.professional = round(latest_interview.professional_score or 0, 1)
            ability_scores.skill_match = round(latest_interview.skill_match_score or 0, 1)
            ability_scores.language_expression = round(latest_interview.language_expression_score or 0, 1)
            ability_scores.logical_thinking = round(latest_interview.logical_thinking_score or 0, 1)
            ability_scores.comprehensive_quality = round(latest_interview.comprehensive_quality_score or 0, 1)
            overall_score = round(latest_interview.overall_score or 0, 1)
        else:
            ability_scores.professional = 60.0
            ability_scores.skill_match = 60.0
            ability_scores.language_expression = 60.0
            ability_scores.logical_thinking = 60.0
            ability_scores.comprehensive_quality = 60.0
            overall_score = 60.0
        
        better_than = calculate_rank_percentile_fixed(db, user_id, overall_score)
        improvement = calculate_improvement_rate_fixed(db, user_id)
        
        recent_interviews = db.query(Interview).filter(
            Interview.user_id == user_id,
            Interview.status == 'completed'
        ).order_by(desc(Interview.completed_at)).limit(5).all()
        
        recent_records = []
        for interview in recent_interviews:
            record = {
                'id': interview.id,
                'date': interview.completed_at.strftime('%Y-%m-%d') if interview.completed_at else interview.created_at.strftime('%Y-%m-%d'),
                'type': interview.type or 'practice',
                'position': interview.position or 'å‰ç«¯å¼€å‘',
                'duration': f"{interview.actual_duration or 30}åˆ†é’Ÿ",
                'score': round(interview.overall_score or 0, 1)
            }
            recent_records.append(record)
        
        response = PerformanceResponse(
            overall_score=overall_score,
            ability_scores=ability_scores,
            better_than=better_than,
            improvement=improvement,
            recent_records=recent_records
        )
        
        return response
        
    except Exception:
        return PerformanceResponse(
            overall_score=0.0,
            ability_scores=AbilityScores(
                professional=0.0,
                skill_match=0.0,
                language_expression=0.0,
                logical_thinking=0.0,
                comprehensive_quality=0.0
            ),
            better_than=0.0,
            improvement=0.0,
            recent_records=[]
        )

def get_trend_data(db: Session, user_id: int, dimension: str = 'overall', 
                  period: str = 'month') -> TrendDataResponse:
    """è·å–è¶‹åŠ¿æ•°æ®"""
    try:
        from datetime import datetime, timedelta
        
        now = datetime.utcnow()
        if period == 'week':
            start_date = now - timedelta(days=7)
            days_back = 7
        elif period == 'month':
            start_date = now - timedelta(days=30)
            days_back = 30
        elif period == 'quarter':
            start_date = now - timedelta(days=90)
            days_back = 90
        else:
            start_date = now - timedelta(days=30)
            days_back = 30
        
        interviews = db.query(Interview).filter(
            Interview.user_id == user_id,
            Interview.completed_at >= start_date,
            Interview.status == 'completed',
            Interview.overall_score.isnot(None)
        ).order_by(Interview.completed_at).all()
        
        dates = []
        scores = []
        labels = []
        details = []
        
        if not interviews:
            for i in range(min(days_back, 10)):
                date = now - timedelta(days=i)
                dates.append(date.strftime('%m-%d'))
                score = 70 + (i * 2) + (i * 0.5)
                scores.append(round(score, 1))
                labels.append(f'ç¬¬{len(dates)}æ¬¡ç»ƒä¹ ')
                details.append({
                    'date': date.strftime('%m-%d %H:%M'),
                    'score': round(score, 1),
                    'position': 'å‰ç«¯å¼€å‘',
                    'interview_id': f'mock_{i}'
                })
            
            dates.reverse()
            scores.reverse()
            labels.reverse()
            details.reverse()
            
        else:
            for i, interview in enumerate(interviews):
                dates.append(interview.completed_at.strftime('%m-%d'))
                labels.append(f'ç¬¬{i+1}æ¬¡é¢è¯•')
                
                if dimension == 'overall':
                    score = interview.overall_score or 0
                elif dimension == 'professional':
                    score = interview.professional_score or 0
                elif dimension == 'skill_match':
                    score = interview.skill_match_score or 0
                elif dimension == 'language_expression':
                    score = interview.language_expression_score or 0
                elif dimension == 'logical_thinking':
                    score = interview.logical_thinking_score or 0
                elif dimension == 'comprehensive_quality':
                    score = interview.comprehensive_quality_score or 0
                else:
                    score = interview.overall_score or 0
                
                scores.append(round(score, 1))
                
                details.append({
                    'date': interview.completed_at.strftime('%m-%d %H:%M'),
                    'score': round(score, 1),
                    'position': interview.position or 'å‰ç«¯å¼€å‘',
                    'interview_id': interview.id
                })
        
        response = TrendDataResponse(
            dates=dates,
            scores=scores,
            labels=labels,
            details=details
        )
        
        return response
        
    except Exception:
        return TrendDataResponse(
            dates=[],
            scores=[],
            labels=[],
            details=[]
        )

def get_user_interview_history_enhanced(db: Session, user_id: int, page: int = 1, 
                                       page_size: int = 10, filters: Dict = None) -> Dict:
    """è·å–ç”¨æˆ·é¢è¯•å†å²è®°å½•"""
    try:
        interviews = db.query(Interview).filter(
            Interview.user_id == user_id
        ).order_by(desc(Interview.created_at)).limit(page_size).offset((page - 1) * page_size).all()
        
        total = db.query(Interview).filter(Interview.user_id == user_id).count()
        
        items = []
        for interview in interviews:
            items.append({
                "id": interview.id,
                "type": interview.type or "practice",
                "date": interview.created_at.strftime('%Y-%m-%d %H:%M'),
                "company": interview.company or "æ¨¡æ‹Ÿå…¬å¸", 
                "position": interview.position or "å‰ç«¯å¼€å‘",
                "round": "ä¸€é¢",
                "duration": f"{interview.actual_duration or 30}åˆ†é’Ÿ",
                "questionCount": interview.answered_questions or 5,
                "interviewer": "AIé¢è¯•å®˜",
                "rating": round((interview.overall_score or 80) / 20, 1),
                "scores": {
                    "professional": interview.professional_score or 80,
                    "expression": interview.language_expression_score or 85,
                    "logic": interview.logical_thinking_score or 82,
                    "adaptability": interview.comprehensive_quality_score or 78,
                    "attitude": interview.comprehensive_quality_score or 80
                },
                "keyFeedback": interview.key_feedback or "è¡¨ç°è‰¯å¥½",
                "status": interview.status or "completed"
            })
        
        return {
            "list": items,
            "total": total,
            "page": page,
            "page_size": page_size,
            "has_more": page * page_size < total,
            "statistics": {
                "total_count": total,
                "month_count": 0,
                "avg_score": 80,
                "total_duration": 120,
                "practice_count": total,
                "simulation_count": 0
            }
        }
    except Exception:
        return {
            "list": [],
            "total": 0,
            "page": page,
            "page_size": page_size,
            "has_more": False,
            "statistics": {
                "total_count": 0,
                "month_count": 0,
                "avg_score": 0,
                "total_duration": 0,
                "practice_count": 0,
                "simulation_count": 0
            }
        }

def generate_personal_advice(db: Session, user_id: int) -> List[Dict]:
    """ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®"""
    try:
        recent_interviews = db.query(Interview).filter(
            Interview.user_id == user_id,
            Interview.status == 'completed',
            Interview.overall_score.isnot(None)
        ).order_by(desc(Interview.completed_at)).limit(5).all()
        
        advice_list = []
        
        if not recent_interviews:
            advice_list = [
                {
                    "type": "info",
                    "title": "å¼€å§‹æ‚¨çš„é¢è¯•ç»ƒä¹ ä¹‹æ—…",
                    "content": "æ¬¢è¿ä½¿ç”¨é¢è¯•ç³»ç»Ÿï¼å»ºè®®ä»åŸºç¡€ç»ƒä¹ å¼€å§‹ï¼Œé€æ­¥æå‡é¢è¯•æŠ€èƒ½ã€‚",
                    "action": "practice",
                    "action_text": "å¼€å§‹ç»ƒä¹ ",
                    "action_data": {"type": "basic"},
                    "priority": 1
                }
            ]
        else:
            latest_interview = recent_interviews[0]
            avg_score = sum(i.overall_score or 0 for i in recent_interviews) / len(recent_interviews)
            
            if avg_score >= 85:
                advice_list.append({
                    "type": "success",
                    "title": "è¡¨ç°ä¼˜ç§€",
                    "content": f"æ‚¨çš„å¹³å‡è¡¨ç°è¾¾åˆ°{avg_score:.1f}åˆ†ï¼Œå·²ç»å…·å¤‡äº†å¾ˆå¼ºçš„é¢è¯•ç«äº‰åŠ›ï¼",
                    "action": "simulation",
                    "action_text": "æŒ‘æˆ˜æ¨¡æ‹Ÿé¢è¯•",
                    "action_data": {"type": "simulation", "difficulty": "hard"},
                    "priority": 1
                })
            elif avg_score >= 70:
                advice_list.append({
                    "type": "info",
                    "title": "ç¨³æ­¥æå‡",
                    "content": f"æ‚¨çš„å¹³å‡è¡¨ç°ä¸º{avg_score:.1f}åˆ†ï¼ŒåŸºç¡€æ‰å®ï¼Œå»ºè®®å¤šæ ·åŒ–ç»ƒä¹ æ¥å…¨é¢æå‡ã€‚",
                    "action": "practice",
                    "action_text": "å¤šæ ·åŒ–ç»ƒä¹ ",
                    "action_data": {"type": "comprehensive"},
                    "priority": 1
                })
            else:
                advice_list.append({
                    "type": "info",
                    "title": "ç³»ç»Ÿæå‡",
                    "content": f"å»ºè®®ç³»ç»Ÿæ€§åœ°ç»ƒä¹ åŸºç¡€é¢è¯•æŠ€å·§ï¼Œä»å„ä¸ªç»´åº¦æ¥æå‡é¢è¯•è¡¨ç°ã€‚",
                    "action": "learning",
                    "action_text": "å­¦ä¹ æŒ‡å—",
                    "action_data": {"resource": "basic_guide"},
                    "priority": 1
                })
        
        return advice_list
        
    except Exception:
        return [
            {
                "type": "info",
                "title": "ç»§ç»­ç»ƒä¹ ",
                "content": "å»ºè®®ç»§ç»­ç»ƒä¹ æ¥æå‡é¢è¯•æŠ€èƒ½ã€‚",
                "action": "practice",
                "action_text": "å¼€å§‹ç»ƒä¹ ",
                "action_data": {"type": "basic"},
                "priority": 1
            }
        ]

def create_targeted_practice_plan(db: Session, user_id: int, practice_request: Dict[str, Any]) -> Dict:
    """åˆ›å»ºé’ˆå¯¹æ€§ç»ƒä¹ è®¡åˆ’"""
    try:
        target_ability = practice_request.get('target_ability', 'professional')
        difficulty_level = practice_request.get('difficulty_level', 'medium')
        practice_type = practice_request.get('practice_type', 'question_bank')
        duration = practice_request.get('duration', 30)
        
        plan_id = str(uuid.uuid4())[:8]
        
        ability_mapping = {
            'professional': 'ä¸“ä¸šçŸ¥è¯†',
            'skill_match': 'æŠ€èƒ½åŒ¹é…',
            'language_expression': 'è¡¨è¾¾èƒ½åŠ›',
            'logical_thinking': 'é€»è¾‘æ€ç»´',
            'comprehensive_quality': 'ç»¼åˆç´ å…»'
        }
        
        ability_name = ability_mapping.get(target_ability, 'ç»¼åˆèƒ½åŠ›')
        
        recommended_sessions = [
            {
                "session_id": f"{plan_id}_1",
                "type": "question_practice",
                "title": f"{ability_name}ä¸“é¡¹ç»ƒä¹ ",
                "description": f"é’ˆå¯¹{ability_name}çš„ä¸“é¡¹é¢˜ç›®ç»ƒä¹ ",
                "estimated_time": duration,
                "question_count": duration // 3,
                "difficulty": difficulty_level
            }
        ]
        
        learning_path = [
            {
                "step": 1,
                "title": "ç†è®ºå­¦ä¹ ",
                "description": f"å­¦ä¹ {ability_name}ç›¸å…³çš„ç†è®ºçŸ¥è¯†",
                "estimated_time": duration * 0.2
            },
            {
                "step": 2,
                "title": "å®è·µç»ƒä¹ ",
                "description": f"é€šè¿‡é¢˜ç›®ç»ƒä¹ æ¥å·©å›º{ability_name}",
                "estimated_time": duration * 0.6
            },
            {
                "step": 3,
                "title": "æ€»ç»“åæ€",
                "description": f"æ€»ç»“ç»ƒä¹ æ•ˆæœï¼Œåˆ¶å®šä¸‹ä¸€æ­¥è®¡åˆ’",
                "estimated_time": duration * 0.2
            }
        ]
        
        expected_improvement = {
            'junior': 15.0,
            'medium': 10.0,
            'senior': 8.0
        }.get(difficulty_level, 10.0)
        
        plan = {
            "plan_id": plan_id,
            "target_ability": target_ability,
            "recommended_sessions": recommended_sessions,
            "learning_path": learning_path,
            "expected_improvement": expected_improvement,
            "estimated_time": duration / 60
        }
        
        return plan
        
    except Exception as e:
        raise Exception(f"åˆ›å»ºç»ƒä¹ è®¡åˆ’å¤±è´¥: {str(e)}")

def get_detailed_interview_analysis(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–é¢è¯•è¯¦ç»†åˆ†æ"""
    try:
        interview = db.query(Interview).filter(
            Interview.id == interview_id,
            Interview.user_id == user_id
        ).first()
        
        if not interview:
            raise ValueError("é¢è¯•ä¸å­˜åœ¨")
            
        return {
            "interview_info": {
                "id": interview_id,
                "type": interview.type or "practice",
                "position": interview.position or "å‰ç«¯å¼€å‘",
                "overall_score": interview.overall_score or 80
            },
            "ability_breakdown": {
                "professional": {"score": 85, "rank": "è‰¯å¥½"},
                "expression": {"score": 82, "rank": "è‰¯å¥½"},
                "logic": {"score": 88, "rank": "ä¼˜ç§€"},
                "comprehensive": {"score": 80, "rank": "è‰¯å¥½"}
            },
            "question_performance": [],
            "comparison_data": {
                "user_avg": 85,
                "platform_avg": 75,
                "better_than_percent": 78
            },
            "timeline_analysis": []
        }
    except Exception as e:
        raise e

def get_interview_qa_records(db: Session, interview_id: int, user_id: int) -> List[Dict]:
    """è·å–é¢è¯•é—®ç­”è®°å½•"""
    try:
        interview = db.query(Interview).filter(
            Interview.id == interview_id,
            Interview.user_id == user_id
        ).first()
        
        if not interview:
            raise ValueError("é¢è¯•ä¸å­˜åœ¨")
            
        return [
            {
                "timestamp": "00:05:30",
                "question": "è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»",
                "answer": "æˆ‘æ˜¯ä¸€åå‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ...",
                "feedback": "è¡¨è¾¾æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º",
                "score": 85
            }
        ]
    except Exception as e:
        raise e

def get_interview_replay_info(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–é¢è¯•å›æ”¾ä¿¡æ¯"""
    try:
        return {
            "video_url": None,
            "audio_url": None, 
            "transcript_url": None,
            "timestamps": [],
            "chapters": [],
            "duration": 1800
        }
    except Exception:
        return {
            "video_url": None,
            "audio_url": None,
            "transcript_url": None, 
            "timestamps": [],
            "chapters": [],
            "duration": 0
        }

# ================================================================================================
# ğŸ› ï¸ ç¬¬åäºŒéƒ¨åˆ†ï¼šè¾…åŠ©å·¥å…·å‡½æ•°
# ================================================================================================

def calculate_interview_scores_safe(db: Session, interview_id: int) -> Dict[str, float]:
    """å®‰å…¨åœ°è®¡ç®—é¢è¯•å„ç»´åº¦è¯„åˆ†"""
    try:
        answers = db.query(InterviewAnswer).filter(
            InterviewAnswer.interview_id == interview_id,
            InterviewAnswer.is_complete == True
        ).all()
        
        if not answers:
            return {
                'overall': 60.0,
                'professional': 60.0,
                'skill_match': 60.0,
                'language_expression': 60.0,
                'logical_thinking': 60.0,
                'comprehensive_quality': 60.0
            }
        
        valid_scores = [answer.score for answer in answers if answer.score is not None]
        
        if not valid_scores:
            avg_score = 70.0
        else:
            avg_score = sum(valid_scores) / len(valid_scores)
        
        scores = {
            'overall': avg_score,
            'professional': max(0, min(100, avg_score + random.uniform(-3, 3))),
            'skill_match': max(0, min(100, avg_score + random.uniform(-3, 3))),
            'language_expression': max(0, min(100, avg_score + random.uniform(-3, 3))),
            'logical_thinking': max(0, min(100, avg_score + random.uniform(-3, 3))),
            'comprehensive_quality': max(0, min(100, avg_score + random.uniform(-3, 3)))
        }
        
        return scores
        
    except Exception:
        return {
            'overall': 65.0,
            'professional': 65.0,
            'skill_match': 65.0,
            'language_expression': 65.0,
            'logical_thinking': 65.0,
            'comprehensive_quality': 65.0
        }

def calculate_simulation_scores(db: Session, interview_id: int) -> Dict[str, float]:
    """è®¡ç®—æ¨¡æ‹Ÿé¢è¯•è¯„åˆ†ï¼ˆæ¯”ç»ƒä¹ æ¨¡å¼æ›´ä¸¥æ ¼ï¼‰"""
    answers = db.query(InterviewAnswer).filter(
        InterviewAnswer.interview_id == interview_id,
        InterviewAnswer.is_complete == True
    ).all()
    
    if not answers:
        return {
            'overall': 50.0,
            'professional': 50.0,
            'skill_match': 50.0,
            'language_expression': 50.0,
            'logical_thinking': 50.0,
            'comprehensive_quality': 50.0
        }
    
    total_score = sum(answer.score or 0 for answer in answers)
    avg_score = total_score / len(answers)
    
    # æ¨¡æ‹Ÿé¢è¯•çš„è¯„åˆ†ä¼šæ¯”ç»ƒä¹ æ¨¡å¼ä½5-10åˆ†ï¼ˆæ›´çœŸå®ï¼‰
    adjustment = -8.0
    
    scores = {
        'overall': max(0, min(100, avg_score + adjustment)),
        'professional': max(0, min(100, avg_score + adjustment + random.uniform(-3, 3))),
        'skill_match': max(0, min(100, avg_score + adjustment + random.uniform(-3, 3))),
        'language_expression': max(0, min(100, avg_score + adjustment + random.uniform(-3, 3))),
        'logical_thinking': max(0, min(100, avg_score + adjustment + random.uniform(-3, 3))),
        'comprehensive_quality': max(0, min(100, avg_score + adjustment + random.uniform(-3, 3)))
    }
    
    return scores

def update_user_statistics_safe(db: Session, user_id: int, interview: Interview):
    """å®‰å…¨åœ°æ›´æ–°ç”¨æˆ·ç»Ÿè®¡æ•°æ®"""
    try:
        stats = db.query(InterviewStatistics).filter(
            InterviewStatistics.user_id == user_id
        ).first()
        
        if not stats:
            stats = InterviewStatistics(user_id=user_id)
            db.add(stats)
        
        stats.total_interviews = (stats.total_interviews or 0) + 1
        
        if interview.type == 'practice':
            stats.practice_interviews = (stats.practice_interviews or 0) + 1
        else:
            stats.simulation_interviews = (stats.simulation_interviews or 0) + 1
        
        if interview.status == 'completed':
            stats.completed_interviews = (stats.completed_interviews or 0) + 1
        
        if interview.actual_duration:
            stats.total_interview_time = (stats.total_interview_time or 0) + interview.actual_duration
            if stats.completed_interviews > 0:
                stats.avg_interview_time = stats.total_interview_time / stats.completed_interviews
        
        if interview.overall_score:
            try:
                all_scores = db.query(Interview.overall_score).filter(
                    Interview.user_id == user_id,
                    Interview.status == 'completed',
                    Interview.overall_score.isnot(None)
                ).all()
                
                scores = [score[0] for score in all_scores if score[0] is not None]
                if scores:
                    stats.avg_overall_score = sum(scores) / len(scores)
                    stats.best_overall_score = max(scores)
            except Exception:
                pass
        
        stats.last_interview_date = interview.completed_at or interview.started_at
        
        db.commit()
        
    except Exception:
        try:
            db.rollback()
        except:
            pass

def save_trend_data_safe(db: Session, interview: Interview):
    """å®‰å…¨åœ°ä¿å­˜è¶‹åŠ¿æ•°æ®"""
    try:
        if not interview.completed_at or not interview.overall_score:
            return
        
        trend_data = InterviewTrendData(
            user_id=interview.user_id,
            interview_id=interview.id,
            date=interview.completed_at,
            year_month=interview.completed_at.strftime('%Y-%m'),
            year_week=interview.completed_at.strftime('%Y-%W'),
            overall_score=interview.overall_score,
            professional_score=interview.professional_score,
            skill_match_score=interview.skill_match_score,
            language_expression_score=interview.language_expression_score,
            logical_thinking_score=interview.logical_thinking_score,
            comprehensive_quality_score=interview.comprehensive_quality_score,
            position=interview.position,
            interview_type=interview.type,
            duration=interview.actual_duration
        )
        
        db.add(trend_data)
        db.commit()
        
    except Exception:
        try:
            db.rollback()
        except:
            pass

def calculate_rank_percentile_fixed(db: Session, user_id: int, user_score: float) -> float:
    """è®¡ç®—ç”¨æˆ·æ’åç™¾åˆ†æ¯”"""
    try:
        if not user_score:
            return 0.0
        
        all_users_with_scores = db.query(Interview.user_id, Interview.overall_score).filter(
            Interview.status == 'completed',
            Interview.overall_score.isnot(None),
            Interview.overall_score > 0
        ).distinct().all()
        
        if not all_users_with_scores:
            return 50.0
        
        user_max_scores = {}
        for user_id_score, score in all_users_with_scores:
            if user_id_score not in user_max_scores:
                user_max_scores[user_id_score] = score
            else:
                user_max_scores[user_id_score] = max(user_max_scores[user_id_score], score)
        
        lower_count = sum(1 for score in user_max_scores.values() if score < user_score)
        total_count = len(user_max_scores)
        
        if total_count <= 1:
            return 50.0
        
        percentile = round((lower_count / total_count) * 100, 1)
        return min(99.0, max(1.0, percentile))
        
    except Exception:
        return 50.0

def calculate_improvement_rate_fixed(db: Session, user_id: int) -> float:
    """è®¡ç®—ç”¨æˆ·æå‡å¹…åº¦"""
    try:
        from datetime import datetime, timedelta
        
        now = datetime.utcnow()
        current_month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        last_month_start = (current_month_start - timedelta(days=1)).replace(day=1)
        
        current_month_interviews = db.query(Interview.overall_score).filter(
            Interview.user_id == user_id,
            Interview.completed_at >= current_month_start,
            Interview.status == 'completed',
            Interview.overall_score.isnot(None)
        ).all()
        
        last_month_interviews = db.query(Interview.overall_score).filter(
            Interview.user_id == user_id,
            Interview.completed_at >= last_month_start,
            Interview.completed_at < current_month_start,
            Interview.status == 'completed',
            Interview.overall_score.isnot(None)
        ).all()
        
        if not current_month_interviews or not last_month_interviews:
            recent_interviews = db.query(Interview.overall_score).filter(
                Interview.user_id == user_id,
                Interview.status == 'completed',
                Interview.overall_score.isnot(None)
            ).order_by(desc(Interview.completed_at)).limit(10).all()
            
            if len(recent_interviews) >= 3:
                scores = [score[0] for score in recent_interviews]
                recent_avg = sum(scores[:3]) / 3
                earlier_avg = sum(scores[3:]) / len(scores[3:]) if len(scores) > 3 else recent_avg
                
                if earlier_avg > 0:
                    improvement = ((recent_avg - earlier_avg) / earlier_avg) * 100
                    return round(improvement, 1)
            
            return 0.0
        
        current_avg = sum(score[0] for score in current_month_interviews) / len(current_month_interviews)
        last_avg = sum(score[0] for score in last_month_interviews) / len(last_month_interviews)
        
        if last_avg > 0:
            improvement = ((current_avg - last_avg) / last_avg) * 100
            return round(improvement, 1)
        
        return 0.0
        
    except Exception:
        return 0.0

def determine_current_phase(db: Session, interview_id: int) -> str:
    """ç¡®å®šå½“å‰é¢è¯•é˜¶æ®µ"""
    answered_count = db.query(InterviewAnswer).filter(
        InterviewAnswer.interview_id == interview_id,
        InterviewAnswer.is_complete == True
    ).count()
    
    if answered_count == 0:
        return 'intro'
    elif answered_count <= 1:
        return 'self'
    elif answered_count <= 3:
        return 'technical'
    elif answered_count <= 5:
        return 'project'
    elif answered_count <= 6:
        return 'behavioral'
    else:
        return 'questions'

def get_next_question_for_skip(db: Session, interview_id: int, current_sequence: int) -> Optional[Dict]:
    """ä¸ºè·³è¿‡åŠŸèƒ½è·å–ä¸‹ä¸€é¢˜"""
    next_question = db.query(InterviewQuestion).filter(
        and_(
            InterviewQuestion.interview_id == interview_id,
            InterviewQuestion.sequence_number > current_sequence,
            InterviewQuestion.status == 'pending'
        )
    ).order_by(InterviewQuestion.sequence_number).first()
    
    if not next_question:
        return None
    
    next_question.status = 'current'
    next_question.asked_at = datetime.utcnow()
    db.commit()
    
    return {
        'id': next_question.id,
        'text': next_question.question_text,
        'type': next_question.question_type,
        'difficulty': next_question.difficulty,
        'time_limit': next_question.time_limit,
        'allow_hints': next_question.allow_hints,
        'sequence_number': next_question.sequence_number
    }

def get_next_simulation_question(db: Session, interview_id: int, current_sequence: int) -> Optional[Dict]:
    """è·å–æ¨¡æ‹Ÿé¢è¯•çš„ä¸‹ä¸€é¢˜"""
    next_question = db.query(InterviewQuestion).filter(
        and_(
            InterviewQuestion.interview_id == interview_id,
            InterviewQuestion.sequence_number > current_sequence,
            InterviewQuestion.status == 'pending'
        )
    ).order_by(InterviewQuestion.sequence_number).first()
    
    if not next_question:
        return None
    
    next_question.status = 'current'
    next_question.asked_at = datetime.utcnow()
    
    interview = db.query(Interview).filter(
        Interview.id == interview_id
    ).first()
    if interview:
        interview.current_question_id = next_question.id
    
    db.commit()
    
    return {
        'id': next_question.id,
        'text': next_question.question_text,
        'type': next_question.question_type,
        'difficulty': next_question.difficulty,
        'time_limit': next_question.time_limit,
        'sequence_number': next_question.sequence_number,
        'category': next_question.category
    }

def get_simulation_status(db: Session, interview_id: int, user_id: int) -> Dict:
    """è·å–æ¨¡æ‹Ÿé¢è¯•å®æ—¶çŠ¶æ€"""
    interview = db.query(Interview).filter(
        Interview.id == interview_id,
        Interview.user_id == user_id
    ).first()
    
    if not interview:
        raise ValueError("é¢è¯•ä¸å­˜åœ¨")
    
    current_question = None
    if interview.current_question_id:
        current_question = db.query(InterviewQuestion).filter(
            InterviewQuestion.id == interview.current_question_id
        ).first()
    
    if not current_question:
        current_question = db.query(InterviewQuestion).filter(
            InterviewQuestion.interview_id == interview_id,
            InterviewQuestion.status.in_(['current', 'pending'])
        ).order_by(InterviewQuestion.sequence_number).first()
    
    elapsed_time = 0
    if interview.started_at:
        elapsed_time = int((datetime.utcnow() - interview.started_at).total_seconds())
    
    interviewer_status = {}
    phase_info = {}
    if interview.settings:
        try:
            settings = json.loads(interview.settings)
            interviewer_status = settings.get('interviewer_status', {})
            phase_info = settings.get('phase_info', {})
        except:
            pass
    
    return {
        "interview_id": interview_id,
        "status": interview.status,
        "is_recording": interview.is_recording or False,
        "current_phase": interview.current_phase or 'intro',
        "current_question_index": current_question.sequence_number - 1 if current_question else 0,
        "total_questions": interview.total_questions or 0,
        "elapsed_time": elapsed_time,
        "answered_questions": interview.answered_questions or 0,
        "interviewer_status": interviewer_status,
        "phase_info": phase_info,
        "current_question": {
            "id": current_question.id,
            "text": current_question.question_text,
            "type": current_question.question_type,
            "time_limit": current_question.time_limit
        } if current_question else None
    }

def generate_overall_feedback(scores: Dict[str, float]) -> str:
    """ç”Ÿæˆç»¼åˆåé¦ˆ"""
    overall = scores['overall']
    
    if overall >= 90:
        return "æ‚¨çš„é¢è¯•è¡¨ç°éå¸¸å‡ºè‰²ï¼å„æ–¹é¢èƒ½åŠ›éƒ½å¾ˆå¼ºï¼Œç»§ç»­ä¿æŒè¿™ç§çŠ¶æ€ã€‚"
    elif overall >= 80:
        return "é¢è¯•è¡¨ç°è‰¯å¥½ï¼Œå¤§éƒ¨åˆ†æ–¹é¢éƒ½åšå¾—ä¸é”™ï¼Œè¿˜æœ‰ä¸€äº›ç»†èŠ‚å¯ä»¥ä¼˜åŒ–ã€‚"
    elif overall >= 70:
        return "åŸºç¡€è¡¨ç°åˆæ ¼ï¼Œæœ‰æ˜æ˜¾çš„ä¼˜åŠ¿é¢†åŸŸï¼ŒåŒæ—¶ä¹Ÿæœ‰éœ€è¦åŠ å¼ºçš„æ–¹é¢ã€‚"
    elif overall >= 60:
        return "è¡¨ç°ä¸­ç­‰ï¼Œå»ºè®®é’ˆå¯¹è–„å¼±ç¯èŠ‚è¿›è¡Œé‡ç‚¹ç»ƒä¹ å’Œæå‡ã€‚"
    else:
        return "è¿˜æœ‰å¾ˆå¤§æå‡ç©ºé—´ï¼Œå»ºè®®ç³»ç»Ÿæ€§åœ°å­¦ä¹ å’Œç»ƒä¹ é¢è¯•æŠ€å·§ã€‚"

def generate_key_feedback(scores: Dict[str, float]) -> str:
    """ç”Ÿæˆå…³é”®åé¦ˆè¦ç‚¹"""
    score_items = [(k, v) for k, v in scores.items() if k != 'overall']
    score_items.sort(key=lambda x: x[1], reverse=True)
    
    best_aspect = score_items[0][0]
    worst_aspect = score_items[-1][0]
    
    aspect_names = {
        'professional': 'ä¸“ä¸šçŸ¥è¯†',
        'skill_match': 'æŠ€èƒ½åŒ¹é…',
        'language_expression': 'è¯­è¨€è¡¨è¾¾',
        'logical_thinking': 'é€»è¾‘æ€ç»´',
        'comprehensive_quality': 'ç»¼åˆç´ å…»'
    }
    
    return f"ä¼˜åŠ¿ï¼š{aspect_names[best_aspect]}è¡¨ç°çªå‡ºï¼›éœ€è¦åŠ å¼ºï¼š{aspect_names[worst_aspect]}æœ‰å¾…æå‡ã€‚"

def generate_improvement_suggestions(scores: Dict[str, float]) -> str:
    """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
    suggestions = []
    
    if scores['professional'] < 80:
        suggestions.append("å»ºè®®åŠ å¼ºä¸“ä¸šçŸ¥è¯†å­¦ä¹ ï¼Œæå‡ç¡¬æ€§ä¸“ä¸šæŠ€èƒ½å’Œåˆ›æ–°æ€ç»´èƒ½åŠ›")
    
    if scores['skill_match'] < 80:
        suggestions.append("ç»ƒä¹ ç›®æ ‡å²—ä½ç›¸å…³çš„å·¥å…·å’ŒæŠ€æœ¯ï¼Œæå‡æŠ€èƒ½åŒ¹é…åº¦")
    
    if scores['language_expression'] < 80:
        suggestions.append("ç»ƒä¹ æ§åˆ¶è¯­é€Ÿå’ŒéŸ³é‡ï¼Œæ³¨æ„è¡¨è¾¾æ—¶çš„æƒ…æ„Ÿä¼ é€’")
    
    if scores['logical_thinking'] < 80:
        suggestions.append("åŠ å¼ºé€»è¾‘æ€ç»´è®­ç»ƒï¼Œæ³¨æ„è¯­è¨€è¿‡æ¸¡å’Œè¡¨è¾¾é€»è¾‘")
    
    if scores['comprehensive_quality'] < 80:
        suggestions.append("æå‡ä»ªæ€è¡¨ç°ï¼ŒåŠ å¼ºæŠ—å‹èƒ½åŠ›å’Œæƒ…ç»ªæ§åˆ¶")
    
    return "; ".join(suggestions) if suggestions else "ç»§ç»­ä¿æŒå½“å‰çŠ¶æ€ï¼Œå…¨é¢å‘å±•å„é¡¹èƒ½åŠ›ã€‚"

def generate_simulation_feedback(scores: Dict[str, float], interview: Interview) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•ç»¼åˆåé¦ˆ"""
    overall = scores['overall']
    
    if overall >= 85:
        return f"æ­å–œï¼æ‚¨åœ¨æœ¬æ¬¡{get_company_full_name(interview.company)}çš„æ¨¡æ‹Ÿé¢è¯•ä¸­è¡¨ç°ä¼˜ç§€ï¼Œå„é¡¹èƒ½åŠ›å‡è¾¾åˆ°äº†å¾ˆé«˜çš„æ°´å‡†ï¼Œå…·å¤‡äº†è¾ƒå¼ºçš„é¢è¯•ç«äº‰åŠ›ã€‚"
    elif overall >= 75:
        return f"æ‚¨åœ¨æœ¬æ¬¡æ¨¡æ‹Ÿé¢è¯•ä¸­è¡¨ç°è‰¯å¥½ï¼ŒåŸºæœ¬è¾¾åˆ°äº†{get_company_full_name(interview.company)}çš„è¦æ±‚ï¼Œè¿˜æœ‰ä¸€äº›ç»†èŠ‚å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚"
    elif overall >= 65:
        return f"æ¨¡æ‹Ÿé¢è¯•è¡¨ç°ä¸­ç­‰ï¼Œæœ‰æ˜æ˜¾çš„ä¼˜åŠ¿é¢†åŸŸï¼Œä½†ä¹Ÿå­˜åœ¨éœ€è¦é‡ç‚¹æ”¹è¿›çš„æ–¹é¢ï¼Œå»ºè®®æœ‰é’ˆå¯¹æ€§åœ°è¿›è¡Œç»ƒä¹ ã€‚"
    elif overall >= 55:
        return f"æœ¬æ¬¡æ¨¡æ‹Ÿé¢è¯•æš´éœ²äº†ä¸€äº›é—®é¢˜ï¼Œå»ºè®®åœ¨æŠ€æœ¯æ·±åº¦ã€è¡¨è¾¾èƒ½åŠ›ç­‰æ–¹é¢è¿›è¡Œç³»ç»Ÿæ€§æå‡åå†å‚åŠ çœŸå®é¢è¯•ã€‚"
    else:
        return f"é¢è¯•åŸºç¡€éœ€è¦åŠ å¼ºï¼Œå»ºè®®é€šè¿‡æ›´å¤šçš„ç»ƒä¹ æ¨¡å¼æ¥æå‡å„é¡¹èƒ½åŠ›ï¼Œç„¶åå†å°è¯•æ¨¡æ‹Ÿé¢è¯•ã€‚"

def generate_simulation_key_feedback(scores: Dict[str, float]) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•å…³é”®åé¦ˆ"""
    score_items = [(k, v) for k, v in scores.items() if k != 'overall']
    score_items.sort(key=lambda x: x[1], reverse=True)
    
    best_aspect = score_items[0][0]
    worst_aspect = score_items[-1][0]
    
    aspect_names = {
        'professional': 'ä¸“ä¸šæŠ€æœ¯èƒ½åŠ›',
        'skill_match': 'æŠ€èƒ½åŒ¹é…åº¦',
        'language_expression': 'è¯­è¨€è¡¨è¾¾èƒ½åŠ›',
        'logical_thinking': 'é€»è¾‘æ€ç»´èƒ½åŠ›',
        'comprehensive_quality': 'ç»¼åˆèŒä¸šç´ å…»'
    }
    
    return f"æ ¸å¿ƒä¼˜åŠ¿ï¼š{aspect_names[best_aspect]}è¡¨ç°çªå‡ºï¼Œç»§ç»­å‘æŒ¥ï¼›ä¸»è¦çŸ­æ¿ï¼š{aspect_names[worst_aspect]}éœ€è¦é‡ç‚¹æå‡ã€‚"

def generate_simulation_improvement_suggestions(scores: Dict[str, float]) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿé¢è¯•æ”¹è¿›å»ºè®®"""
    suggestions = []
    
    if scores['professional'] < 75:
        suggestions.append("åŠ å¼ºä¸“ä¸šçŸ¥è¯†æ·±åº¦ï¼Œå…³æ³¨è¡Œä¸šå‰æ²¿æŠ€æœ¯å’Œæœ€ä½³å®è·µ")
    
    if scores['skill_match'] < 75:
        suggestions.append("æå‡ç›®æ ‡å²—ä½ç›¸å…³æŠ€èƒ½ï¼Œç†Ÿç»ƒæŒæ¡ä¸»æµå·¥å…·å’Œæ¡†æ¶")
    
    if scores['language_expression'] < 75:
        suggestions.append("æ”¹å–„è¡¨è¾¾æŠ€å·§ï¼Œæ³¨æ„è¯­é€Ÿæ§åˆ¶å’Œé€»è¾‘æ¸…æ™°åº¦")
    
    if scores['logical_thinking'] < 75:
        suggestions.append("å¼ºåŒ–é€»è¾‘æ€ç»´è®­ç»ƒï¼Œæå‡é—®é¢˜åˆ†æå’Œè§£å†³èƒ½åŠ›")
    
    if scores['comprehensive_quality'] < 75:
        suggestions.append("æå‡èŒä¸šç´ å…»ï¼ŒåŒ…æ‹¬æ²Ÿé€šåè°ƒå’ŒæŠ—å‹åº”å˜èƒ½åŠ›")
    
    if not suggestions:
        suggestions.append("å„é¡¹èƒ½åŠ›è¡¨ç°å‡è¡¡ï¼Œå»ºè®®é€šè¿‡æ›´å¤šå®æˆ˜é¡¹ç›®æ¥è¿›ä¸€æ­¥æå‡ä¸“ä¸šæ°´å¹³")
    
    return "ï¼›".join(suggestions)

def get_company_full_name(company_type: str) -> str:
    """è·å–å…¬å¸å…¨ç§°"""
    company_names = {
        'tech': 'äº’è”ç½‘ç§‘æŠ€æœ‰é™å…¬å¸',
        'foreign': 'å¤–èµ„ä¼ä¸š',
        'state': 'å›½æœ‰ä¼ä¸š',
        'startup': 'åˆ›ä¸šå…¬å¸'
    }
    return company_names.get(company_type, 'å…¬å¸')

def get_round_name(round_type: str) -> str:
    """è·å–é¢è¯•è½®æ¬¡åç§°"""
    round_names = {
        'first': 'åˆè¯•',
        'second': 'å¤è¯•',
        'final': 'ç»ˆé¢'
    }
    return round_names.get(round_type, 'é¢è¯•')